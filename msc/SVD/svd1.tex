\documentclass[10pt]{mwart}
\usepackage{polski}
\usepackage[polish]{babel}
\usepackage{amsfonts}
\usepackage{eufrak}
\usepackage{indentfirst}
\usepackage[utf8]{inputenc}
\usepackage{amsthm}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{makeidx}
\newtheorem{tw}{Twierdzenie}
\newtheorem{df}{Definicja}
\newtheorem{lm}{Lemat}
\newtheorem{wn}{Wniosek}
\newtheorem{prz}{Przykład}
\newtheorem{uw}{Uwaga}
\newtheorem{zd}{Zadanie}
\title{SVD i obcięte SVD}
\author{Grzegorz Mika}
\begin{document}
\maketitle
\section{Wstęp}
Niech $H,G$ będą przestrzeniami Hilberta, $A\colon H \to G$ niech będzie liniowym i ograniczonym operatorem między tymi przestrzeniami. Naszym zadaniem jest, mając dany $g\in G$, znaleźć taki $f\in H$, że
\begin{displaymath}
Af=g.
\end{displaymath}
W dalszym ciągu będziemy zakładać, że problem jest źle postawiony i rozwiązanie poprzez odwrócenie operatora $A$ nie jest stabilne.

\section{Operatory zwarte}
Rozważmy liniowy operator ograniczony $A$ między dwoma przestrzeniami Hilberta $H,G$. Założymy, że $D(A)=\{f\in H\colon \exists_{g\in G}\ Af=g\}=H$.

\begin{tw}
Niech $A\in L(H,G)$. Wtedy\\
%\begin{itemize}
1. $KerA=(RangeA^*)^{\perp}$ oraz $\overline{RangeA}=(KerA^*)^{\perp}$,\\
2. jeśli $A$ jest iniektywny, to $A^*A$ też,\\
3. $A^*A\in L(H)$ oraz $A^*A$ jest dodatni i samosprzężony.\\
4. $H=KerA \oplus KerA^{\perp}=KerA\oplus \overline{RangeA^*}$,\\
5. $G=\overline{RangeA}\oplus RangeA^{\perp}=\overline{RangeA}\oplus KerA^*$.
%%\end{itemize}
\end{tw}


\begin{df}
Operator $A\colon H \to G$ nazywamy zwartym (compact), jeżeli dla każdego ograniczonego zbioru w $H$, jego obraz przez operator $A$ jest względnie zwarty w $G$, czyli jego domknięcie jest zwarte w $G$. Przez $K(H,G)$ będziemy oznaczać zbiór operatorów zwartych między przestrzeniami $H$ i $G$.
\end{df}
\begin{uw}
Jeżeli $A\in K(H,G)$ oraz $dimH=\infty$ to operator $A^{-1}$ jest nieograniczony.
\end{uw}


\begin{tw}{\textbf{(Reprezentacja operatora zwartego według wartości osobliwych)}}
Niech $A\colon H\to G$ będzie operatorem zwartym na przestrzeniach Hilberta $H,G$. Wtedy istnieją skończony lub zbieżny do zera ciąg liczb dodatnich $\{b_n\}_{n\in I}$ oraz układy ortonormalne $\{v_n\}_{n\in I}\subset H,\ \{u_n\}_{n\in I}\subset G$ takie, że
\begin{itemize}
\item $KerA^{\perp}=\overline{span\{v_n,\ n\in I\}}$,
\item $\overline{RangeA}=\overline{span\{u_n,\ n\in I\}}$,
\item $Af=\sum_nb_n\langle f, v_n\rangle u_n$ oraz $A^*g=\sum_nb_n\langle g, u_n\rangle v_n$.
\end{itemize}
Ponadto $g\in RangeA$ wtedy i tylko wtedy, gdy spełniony jest tzw. warunek Picarda
\begin{displaymath} 
\sum_nb_n^{-2}|\langle g, u_n\rangle|^2< \infty\ \textrm{oraz}\ g=\sum_n\langle g, u_n\rangle u_n
\end{displaymath}
Wtedy rozwiązania równania $Af=g$ mają postać 
\begin{displaymath}
f=f_0+\sum_nb_n^{-1}\langle g, u_n\rangle v_n
\end{displaymath}
przy czym $f_0\in KerA$ jest dowolne.
\end{tw}
Układ $(u_n,v_n,b_n)$ nazywamy układem singularnym operatora $A$ a jego reprezentację w postaci $Af=\sum_n\lambda_n\langle f,v_n\rangle u_n$ nazywamy dekompozycją według wartości osobliwych (singular value decomposition-- SVD) operatora $A$.
\begin{proof}
Dowód twierdzenia opiera się na wykorzystaniu twierdzenia spektralnego do operatora $A^*A$.

Operator $A^*A$ jest samosprzężony, zwarty i dodatni, a zatem istnieją liczby $b_1^2\geq b_2^2\geq\dots\geq 0$ oraz funkcje ortonormalne $v_n$ takie, że $A^*Av_n=b_n^2v_n$. Niech $I=\{n\colon b_n>0\}$ oraz przez $u_n$ oznaczmy znormalizowane obrazy wektorów $v_n$, czyli $u_n=b_n^{-1}Av_n$ dla $n\in I$. Zauważmy, że $\langle u_k,u_l\rangle=b_k^{-1}b_l^{-1}\langle Av_k, Av_l\rangle=b_k^{-1}b_l^{-1}\langle v_k,A^*Av_l\rangle=b_k^{-1}b_l^{-1}\langle v_k,b_l^2v_l\rangle=\delta_{kl}$.

Korzystając w wykazanego wcześniej twierdzenia dostajemy, że $KerA^{\perp}=(KerA^*A)^{\perp}=\overline{RangeA^*A}=\overline{span\{v_n,\ n\in I\}}$.

Analogicznie rozpatrując operator $AA^*$ z rozkładem spektralnym $AA^*u_n=b_n^2u_n$ dostajemy, że $\overline{RangeA}=\overline{span\{u_n,\ n\in I\}}$.

Tożsamości $Af=\sum_nb_n\langle f, v_n\rangle u_n$ oraz $A^*g=\sum_nb_n\langle g, u_n\rangle v_n$ otrzymujemy, zauważając, że
$Af=\sum_n\langle Af,u_n\rangle u_n=\sum_n\langle Af, b_n^{-1}Av_n\rangle u_n=\sum_n\langle f,b_n^{-1}A^*Av_n\rangle u_n=\sum_n\langle f,b_n^{-1}b_n^2v_n\rangle u_n=\sum_n b_n\langle f,v_n\rangle u_n$ oraz drugą analogicznie.

Z nierówności Bessela dostajemy, że $\sum_n|\langle f, v_n\rangle |^2<\infty$, bo $f\in H$ a stąd
$\sum_n|\langle f,v_n\rangle|^2=\sum_nb_n^{-4}|\langle f,b_n^2v_n\rangle|^2=\sum_nb_n^{-4}|\langle f, A^*Av_n\rangle|^2=\sum_nb_n^{-4}|\langle Af,Av_n\rangle|^2=\sum_nb_n^{-2}|\langle g, b_n^{-1}Av_n\rangle|^2=\sum_nb_n^{-2}|\langle g, u_n\rangle|^2<\infty$. W drugą stronę wnioskujemy, że jeśli spełniony jest warunek Picarda to możemy wypisać jawny wzór na rozwiązanie,  gdyż odpowiedni szereg norm współczynników jest zbieżny i $g$ jest sumą swojego szeregu Fouriera..

Ostatecznie możemy wnioskować, że $f=f_0+\sum_nb_n^{-1}\langle g, u_n\rangle v_n$, gdzie $f_0\in KerA$.
\end{proof}

Udało nam się zaprezentować działanie zwartego operatora w postaci jego rozwinięcia według wartości osobliwych w postaci $Af=\sum_nb_n\langle f, v_n\rangle u_n$ oraz uzyskać postać szukanych rozwiązań w postaci $f=f_0+\sum_nb_n^{-1}\langle g, u_n\rangle v_n$. Jednak takie rozwiązanie sytuacji stawia przed nami nowe problemy. Po pierwsze zauważmy, że jeżeli tylko $g$ posiada niezerowe składowe w przestrzeni ortogonalnej do domknięcia obrazu operatora $A$ równanie $Af=g$ nie może być spełnione dokładnie. Niech $P\colon G\to \overline{RangeA}$ będzie rzutem ortogonalnym, czyli $\forall_{g\in G}\ Pg=\sum_n\langle g,u_n\rangle u_n$. Wtedy dla dowolnego elementu $f\in H$ mamy, że $||Af-g||^2=||Af-Pg||^2+||(1-P)g||^2\geq ||(1-P)g||^2$.

Drugi problem związany jest ze zbieżnością szeregu w warunku Picarda. Z twierdzenia o reprezentacji spektralnej operatora zwartego samosprzężonego wiemy, że liczby $b_n\to 0$ gdy $n\to \infty$ a zatem liczby $b_n^{-2}\to \infty$ gdy $n \to \infty$ a nie mamy żadnej gwarancji, że liczby $\langle g,u_n\rangle$ zbiegają do zera odpowiednio szybko by zrównoważyć ten przyrost szczególnie w przypadku zaburzonej wartości $y$.


\section{Stochastyczny problem odwrotny}
Powróćmy do sformułowania problemu z zaburzonymi pomiarami wyrażonymi w języku stochastyki, czyli niech $A\colon H\to G$ będzie zwartym operatorem między dwoma przestrzeniami Hilberta. Obserwując pewną zaburzoną informację $Y$ naszym zadaniem jest poznać $f\in H$ według modelu
\begin{displaymath}
Y=Af+\epsilon\xi
\end{displaymath}
gdzie $\epsilon$ oznacza wielkość szumu.

Podamy teraz założenia jakie będzie musiał spełniać losowy szum. 

\begin{df}
Stochastycznym błędem $\xi$ nazwiemy proces na przestrzeni Hilberta, czyli ograniczony liniowy operator $\xi\colon G\to L^2(\Omega, \mathcal{F},\mathbb{P})$ taki, że dla dowolnych elementów $g_1,g_2\in G$ mamy zdefiniowane zmienne losowe $\langle \xi, g_i\rangle$ takie, że $\mathbb{E}\langle \xi, g_i\rangle =0$ oraz możemy zdefiniować kowariancję $Cov_{\xi}$ jako ograniczony liniowy operator ($||Cov_{\xi}||\leq 1$) z przestrzeni $G$ w przestrzeń $G$ taki, że $ \langle Cov_{\xi}g_1,g_2\rangle=Cov(\langle \xi,g_1\rangle,\langle \xi,g_2\rangle)$.
\end{df}

Często wykorzystywanym modelem będącym idealizacją pewnych innych modeli jest model białego szumu.
\begin{df}
Powiemy, że losowy błąd $\xi$ jest białym szumem, jeśli $Cov_{\xi}=I$ oraz indukowane zmienne losowe są gaussowskie, czyli dla dowolnych elementów $g_1,g_2\in G$ mamy, że $\langle \xi,g_i\rangle\sim \mathcal{N}(0,||g_i||^2)$, $(\langle \xi,g_1\rangle ,\langle \xi,g_2\rangle ,\dots ,\langle \xi,g_k\rangle )\sim \mathcal{N}_k(0, \Sigma)$ oraz $Cov(\langle \xi,g_1\rangle , \langle \xi , g_2\rangle)=\langle g_1, g_2\rangle$.
\end{df}
\begin{lm}
Niech $\xi$ będzie białym szumem w przestrzeni $G$ oraz niech $\{u_n\}$ będzie ortonormalną bazą tej przestrzeni. Oznaczając $\xi_k=\langle \xi,u_k\rangle$ dostajemy, że $\{\xi_n\}$ niezależnymi zmiennymi losowymi o tym samym standardowym rozkładzie gaussowskim.
\end{lm}

Zauważmy, że gdy $\xi$ jest białym szumem, $Y$ nie jest elementem przestrzeni $G$ a staje się operatorem działającym na przestrzeni $G$ w następujący sposób
\begin{displaymath}
\forall_{g\in G}\ \langle Y,g\rangle =\langle Af,u_n\rangle + \epsilon\langle \xi, g\rangle
\end{displaymath}
gdzie $\langle \xi, g\rangle\sim\mathcal{N}(0,||g||^2)$.

Rozważmy teraz układ singularny $(u_n,v_n,b_n)$ operatora zwartego $A$ oraz niech $\xi$ będzie białym szumem. Możemy wtedy zapisać rozpatrując projekcję $Y$ na układ $\{u_n\}$, że
\begin{displaymath}
\langle Y,u_n\rangle=\langle Af,u_n\rangle +\epsilon\langle \xi, u_n\rangle=\langle Af,b_n^{-1}Av_n\rangle+\epsilon \xi_n=b_n^{-1}\langle A^*Af, v_n\rangle+\epsilon \xi_n=
\end{displaymath}
\begin{displaymath}
b_n^{-1}\langle \sum_kb_k^2\langle f, v_k\rangle v_k, v_n\rangle +\epsilon\xi_n=b_n\theta_n+\epsilon\xi_n
\end{displaymath}
gdzie $\theta_n=\langle f,v_n\rangle$ są współczynnikami w rozwinięciu Fouriera funkcji $f$ w bazie $\{v_n\}$. 

Oznaczając przez $y_n=\langle Y,u_n\rangle$ możemy wyjściowy problem $Y=Af+\epsilon\xi$ zapisać w równoważnej postaci sequence space model jako
\begin{displaymath}
y_n=b_n\theta_n+\epsilon\xi_n,\ n=1,2,\dots.
\end{displaymath}
W tej postaci widać dokładnie trudności związane ze stochastycznymi problemami odwrotnymi. Jako że $b_n$ są wartościami osobliwymi operatora zwartego mamy, że $b_n\to 0$ gdy $n\to \infty$, czyli widać, że wraz ze wzrostem $n$ sygnał $b_n\theta_n$ staje się coraz słabszy i coraz trudniej estymować $\theta_n$. Dodatkową trudnością jest fakt, że naszym celem jest estymacja współczynników $\theta_n$ a nie współczynników $b_n\theta_n$, dlatego możemy zapisać równoważną postać problemu
\begin{displaymath}
x_n=\theta_n+\epsilon\sigma_n\xi_n,\ n=1,2,\dots
\end{displaymath}
gdzie $x_n=y_n/b_n$ oraz $\sigma_n=b_n^{-1}$, czyli $\sigma_n\to \infty$ gdy $n\to \infty$. Widzimy zatem, że wraz ze wzrostem $n$ szum zaczyna dominować nad sygnałem czyniąc estymację $\theta_n$ trudną.


\section{Obcięte SVD}


Na początek rozważmy problem estymacji w nieparametrycznym modelu regresji
\begin{displaymath}
y_n=f(x_n)+\sigma\epsilon_n.
\end{displaymath}
Naszym celem jest znalezienie funkcji $f$. W tym celu możemy posłużyć się metodą rzutowania na pewną bazę. Funkcję $f$ możemy wtedy zapisać w postaci szeregu $f=\sum_{n=1}^{\infty}a_n\phi_n$ i wtedy zadanie estymacji sprowadzi się do znalezienia współczynników rozwinięcia $a_n$. Możemy zastosować następującą metodę: pierwsze $N$ współczynników oszacujemy na podstawie posiadanych danych natomiast pozostałe współczynniki oszacujemy przez $0$. Metoda ta znajduje swoje uzasadnienie w tym, że w przypadku gładkich funkcji $f$ o jej kształcie decydują początkowe współczynniki, natomiast pozostałe stają się zaniedbywalne. 

Podobną metodologię możemy spróbować zastosować w przypadku stochastycznych problemów odwrotnych z operatorami zwartymi posiadającymi dekompozycję według wartości osobliwych.

Rozważmy problem w postaci 
\begin{displaymath}
x_n=\theta_n+\epsilon\sigma_n\xi_n,\ n=1,2,\dots\ .
\end{displaymath}
Wtedy możemy zaproponować następujący estymator dla współczynników $\theta_n$
\begin{displaymath}
\hat{\theta}(N)=\left\{{x_k,\ k\leq N}\atop {0,\ k>N}\right. .
\end{displaymath}
Wtedy estymatorem elementu $f$ staje się $\hat{f}=\sum_{k=1}^Nx_kv_k$.

Problemem jaki pozostał jest dobranie odpowiedniego poziomu obcięcia $k$.

W celu oceny jakości estymatora posłużymy się błędem średniokwadratowym, czyli $R(f,\hat{f})=\mathbb{E}(||f-\hat{f}||^2)$. Mając do dyspozycji układ wartości osobliwych możemy zapisać estymator uzyskany metodą TSVD w postaci $\hat{f}=\sum_{n=1}^kx_nv_n$. Dzięki temu możemy zauważyć, że jest to estymator liniowy z wektorem wag posiadających jedynki na pierwszych $k$ pozycjach i zerach na pozostałych. Ryzyko estymatora możemy wtedy zapisać jako $R(f,\hat{f})=\mathbb{E}(||f-\hat{f}||^2)=\mathbb{E}(\sum_n(\hat{f}_k-f_k)^2)=\sum_{n=k+1}^{\infty}\theta_n^2+\sum_{n=1}^k\epsilon^2\sigma_n^2$, czyli ryzyko estymatora TSVD wyraża się w bardzo prosty sposób.

Możemy teraz zastanowić się jak wybór $k$ będzie wpływał na ryzyko estymatora TSVD
\begin{displaymath}
R(f,\hat{f})=\sum_{n=k+1}^{\infty}\theta_n^2+\sum_{n=1}^k\epsilon\sigma_n.
\end{displaymath}
Z uzyskanego wzoru widzimy, że wraz ze wzrostem $k$ zmniejsza się się obciążenie estymatora (ubywa pominiętych współrzędnych), ale rośnie wariancja, odwrotny skutek obserwujemy zmniejszając $k$- rośnie obciążenie, ale maleje wariancja. Optymalny wybór $k$ powinien prowadzić do zbalansowania tych dwóch przeciwstawnych tendencji. Ogólnie wiadomo jednak, że wybór optymalnego poziomu odcięcia wymaga znajomości pewnych parametrów poszukiwanej funkcji (gładkość).

\begin{thebibliography}{4}
\bibitem{cavalier}
L. Cavalier, \emph{Inverse Problems in Ststistics} in P. Alquier et al., \emph{Inverse problems and high- dimensional estimation}, Springer, 2011,
\bibitem{kaipo}
J. Kaipo, E. Somersalo, \emph{Statistical and computational inverse problems}, Springer, 2004,
\bibitem{szkutnik}
Z. Szkutnik, \emph{Statystyczne problemy odwrotne}, notatki do wykładu,
\bibitem{wasserman}
L. Wasserman, \emph{All of nonparmetric statistics}, Springer, 2006.
\end{thebibliography}
\end{document}