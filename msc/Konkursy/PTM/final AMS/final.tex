\documentclass[man,mfiu]{mgrwms}
\usepackage{polski}
\usepackage[utf8]{inputenc}    
\usepackage{amsthm}
\usepackage{amsmath}           
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{enumerate}
\usepackage[T1]{fontenc}  
\usepackage{lmodern}
\usepackage{fancyhdr}
\usepackage{indentfirst}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{bbm}
\usepackage{mathrsfs}
\usepackage{array}
\usepackage{eqnarray}
%\usepackage{hyperref}  %odsyłacze
\usepackage{multicol}
\usepackage{url}

\usepackage{listings}
 
\usepackage{xcolor}
\usepackage{epstopdf}
\usepackage{sidecap}
\usepackage{wrapfig}
\usepackage{subfig}
\usepackage{float}
\usepackage{bbm}
%\usepackage[a4paper, left=3.2cm, right=2.5cm, top=1.75cm, bottom=2.2cm]{geometry}
\newcommand{\slfrac}[2]{\left.#1\middle/#2\right.}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}



\usepackage{hyperref} % pakiet pozwalający na odwołania w postaci linków

\usepackage{cleveref}
%\usepackage{amsmath,times,latexsym}           % łatwiejszy skład matematyki

\usepackage{multicol}

\usepackage{multirow}
\usepackage{pgf,tikz}
\usepackage{mathrsfs}
\usepackage{extarrows}
\usepackage{hyphenat} % dzielenie wyrazów
%\hypersetup{pdfpagemode=FullScreen} % wyświetla pdf w pełnym ekranie





\lstset{
	%basicstyle=\footnotesize,      
 	numbers=left,                   
  	numberstyle=\tiny\color{gray},  
 	stepnumber=1,                  
    numbersep=10pt,                 
 	frame=single,  
 	lineskip=2pt            
} 
\DeclareMathOperator{\sgn}{sgn}
\renewcommand\arraystretch{1.5}



\newtheorem{tw}{Twierdzenie}[chapter]
\newtheorem{df}{Definicja}[chapter]
\newtheorem{np}{Przykład}[chapter]
\newtheorem{uw}{Uwaga}[chapter]
\newtheorem{lm}{Lemat}[chapter]
\newtheorem{wn}{Wniosek}[chapter]
\newtheorem{za}{Założenie}[chapter]

\begin{document}


\title{Nierówności wyrocznie dla problemów odwrotnych}
\author{Grzegorz Mika}
\promotor{prof. dr hab. inż. Zbigniew Szkutnik}
\nralbumu{267543}
\slowakluczowe{statystyczne problemy odwrotne, nierówności wyrocznie,operatory zwarte, operatory niezwarte, minimalizacja ryzyka empirycznego\\
	{\it Klasyfikacja tematyczna AMS 2000:  	62G05, 62G20,  	62M15, 62M30,  	62P99}}
\keywords{statistical inverse problems, oracle inequalities, compact operators, non-- compact operators, empirical risk minimization\\
{\it AMS 2000 Subject Classification:  	62G05, 62G20,  	62M15, 62M30,  	62P99}}

\maketitle
\newpage
\begin{minipage}[t]{0.5\textwidth}
 %Pierwsza kolumna
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
 %Druga kolumna
\end{minipage}
\begin{flushright}
\vfill
\textit{Składam serdeczne podziękowania mojemu Promotorowi prof. dr hab. inż. Zbigniewowi Szkutnikowi za wskazanie mi drogi, wszelką pomoc  i cierpliwość.}
\end{flushright}
\tableofcontents
\begin{streszczenie}
W pracy rozważany jest problem estymacji nieznanego elementu $f$ na podstawie niebezpośrednich i zaburzonych obserwacji. Niech $\Lambda$ będzie skończonym zbiorem estymatorów liniowych. Celem jest konstrukcja metody wyboru estymatora z rodziny $\Lambda$ naśladującego estymator o minimalnym ryzyku w tej klasie. Okazuje się, że można to osiągnąć poprzez minimalizację odpowiedniego wyrażenia związanego z ryzykiem empirycznym. W pierwszej części pracy przedstawione zostały wyniki dotyczące operatorów zwartych. W drugiej części zaprezentowano uogólnienie tych wyników  na przypadek dowolnych operatorów liniowych i ograniczonych. Głównym wynikiem pracy jest zaprezentowanie odpowiednich nieasymptotycznych nierówności wyroczni w obu przypadkach.
\end{streszczenie}

\begin{abstract}
This thesis concerns the problem of estimation of an unknown element $f$ on the basis of indirect and noisy observations. Let $\Lambda$ be a finite set of possible linear estimators. The aim is to construct a method of selection of an estimator from a family $\Lambda$ that mimics the estimator with the smallest risk in this set. It is demonstrated that this can be achieved by minimization of an adequate expression connected with the empirical risk. The results related to compact operators are presented in the first part of the work. In the second part the findings are generalized to any linear bounded operator. It is exhibited that in both cases non--asymptotic oracle inequalities can be constructed.

\end{abstract}


\begin{wstep}
Statystyczne problemy odwrotne są zagadnieniem występującym w wielu dziedzinach takich, jak geofizyka, obrazowanie medyczne czy astrofizyka. Za każdym razem celem jest rekonstrukcja sygnału, który nie może być jednak obserwowany bezpośrednio. Dodatkowo tak przekształcony sygnał może być zniekształcony przez pewne losowe zaburzenie. Tak postawione zagadnienie może zostać ujęte w matematycznym opisie jako
\begin{displaymath}
Y=Af+\epsilon,
\end{displaymath}
gdzie $f$ jest poszukiwanym sygnałem, operator $A$ modeluje transformację jakiej poddany został sygnał, natomiast $\epsilon$ jest pewnym zaburzeniem, którego źródłem może być przykładowo niedokładność aparatury pomiarowej. Najprostszym sposobem "odzyskania" elementu $f$ mogłaby się wydawać konstrukcja estymatora $Af$ i następnie poddanie go działaniu operatora odwrotnego $A^{-1}$. Jednak w większości przypadków okazuje się, że takie podejście prowadzi do nadmiernego zwiększenia błędu estymacji z uwagi na nieograniczoność operatora odwrotnego $A^{-1}$. Celem poradzenia sobie z tym problemem zaproponowano w literaturze szereg metod mających na celu niedopuszczenie do eksplozji błędu poprzez zastosowanie tak zwanej regularyzacji (\cite{engl}) pozwalającej na kontrolowanie zachowania odwrotności operatora. Metody te wymagają jednak najczęściej ustalenia pewnego parametru, kluczowego dla ich zachowania. Stąd pojawiła się konieczność konstrukcji odpowiednich procedur wyboru tych parametrów na podstawie danych dla skończonych prób. W tej pracy omawiana jest jedna z takich procedur, wybierająca estymator $\theta^*$ ze skończonej rodziny, naśladujący ryzyko najlepszego estymatora w tej rodzinie, polegająca na minimalizacji odpowiedniego wyrażenia związanego z ryzykiem empirycznym. W przypadku, gdy rozważany operator jest operatorem zwartym wyrażenie to jest nieobciążonym estymatorem ryzyka, natomiast w przypadku ogólnym dla operatorów liniowych i ograniczonych jest to estymator pewnego górnego oszacowania na ryzyko rozważanego estymatora elementu $f$. W obu przypadkach udaje się skonstruować nieasymptotyczne nierówności wyrocznie postaci 
\begin{displaymath}
\mathcal{R}(\theta^*,\theta)\leq C_1 \inf_{\hat{\theta} \in \Lambda}\mathcal{R}(\hat{\theta},\theta)+C_2(\Lambda,n),
\end{displaymath}
gdzie $\Lambda$ jest rozważaną rodziną estymatorów. Pozwalają one w sposób systematyczny wybierać i oceniać ryzyko estymatora z pewnej skończonej rodziny. W literaturze opisano także inne metody wyboru (przykładowo \cite{cavalier3}), jednak zaprezentowana tutaj metoda charakteryzuje się dużą intuicyjnością.\\
\indent Praca zorganizowana jest w następujący sposób. W rozdziale \ref{PW} zaprezentowane są podstawowe pojęcia wykorzystywane w pracy oraz wprowadzenie do pojęcia wyroczni, rozdziały \ref{G1} i \ref{G2} prezentują uzyskane rezultaty dla odpowiednio przypadku operatorów zwartych i dowolnych operatorów ograniczonych i liniowych, w rozdziale \ref{przyklad} zamieszczono przykład zastosowania uzyskanych wyników dla problemu dekonwolucji na prostej rzeczywistej, natomiast rozdział \ref{lematy} zawiera dowody wszystkich lematów użytych do dowodzenia głównych rezultatów. Rozdział \ref{G1} jest prezentacją wyników uzyskanych w pracy \cite{cavalier1} z pewnymi niewielkimi poprawkami, natomiast rozdział \ref{G2} został napisany w oparciu o pracę \cite{cavalier2} z szerokimi zmianami i poprawkami wprowadzonymi przez autora.
\end{wstep}
\chapter{Pojęcia wstępne}\label{PW}
Na początek wprowadzimy potrzebną notację i oznaczenia oraz opiszemy model, w którym będziemy pracować w dalszej części. 
Niech $H$ oraz $G$ będą dwoma ośrodkowymi przestrzeniami Hilberta z iloczynem skalarnym oznaczanym odpowiednio $\langle \cdot,\cdot \rangle_H$ oraz $\langle \cdot,\cdot \rangle_G$ (lub gdy nie prowadzi to do nieporozumień krótko $\langle \cdot,\cdot \rangle$), natomiast $A$ niech będzie liniowym i ograniczonym operatorem między tymi przestrzeniami. Naszym celem jest znalezienie takiego $f\in H$, by mając dany $g\in G$, spełnić równanie
\begin{displaymath}
Af=g.
\end{displaymath}
\begin{df}[\cite{szkutnik}, str. 1] Problem nazwiemy dobrze postawionym w sensie Hadamarda, gdy:
\begin{itemize}
\item dla dowolnego $g\in G$ istnieje $f\in H$ spełniający zadane równanie,
\item rozwiązanie jest jedyne,
\item rozwiązanie jest stabilne, czyli zależy w sposób ciągły od prawej strony równania.
\end{itemize}
\end{df}
Jeżeli choć jeden z warunków powyższej definicji nie jest spełniony, problem nazywamy źle postawionym. W przypadku braku stabilności, operator odwrotny $A^{-1}$ jest nieograniczony, co może prowadzić do eksplozji rozwiązania nawet w przypadku niewielkiego zaburzenia wartości $g$.\\
\indent W dalszej części obserwacje będą zaburzone przez pewien losowy szum. Będziemy pracować z następującym modelem 
\begin{equation}\label{Af}
Y=Af+\epsilon\xi,
\end{equation}
w którym celem jest odzyskanie informacji na temat elementu $f$ na bazie zakłóconych obserwacji $Y$. Przez $\xi$ rozumieć będziemy odpowiednio zdefiniowany poniżej stochastyczny szum, natomiast przez $\epsilon>0$ jego poziom.
\begin{df}[\cite{iphde}, str. 7]\label{szum} Stochastycznym błędem $\xi$ nazwiemy proces na przestrzeni Hilberta G, czyli ograniczony liniowy operator $\xi\colon G\to L_2(\Omega, \mathcal{F},\mathbb{P})$ taki, że dla dowolnych elementów $g_1,g_2\in G$ mamy zdefiniowane zmienne losowe $\langle \xi, g_i\rangle$ takie, że $\mathbb{E}\langle \xi, g_i\rangle =0$. Operator kowariancji $\textbf{Cov}_{\xi}$ określony jest jako ograniczony liniowy operator ($||\textbf{Cov}_{\xi}||\leq 1$) z przestrzeni $G$ w przestrzeń $G$ taki, że $ \langle \textbf{Cov}_{\xi}g_1,g_2\rangle=\textbf{Cov}(\langle \xi,g_1\rangle,\langle \xi,g_2\rangle)$. Przestrzeń $(\Omega, \mathcal{F},\mathbb{P})$ jest podstawową przestrzenią probabilistyczną, natomiast  $L_2(\cdot)$ jest przestrzenią wszystkich funkcji całkowalnych z kwadratem na zadanej przestrzeni z miarą.
\end{df}

\begin{df}[\cite{iphde}, str. 8] Powiemy, że losowy błąd $\xi$ jest gaussowskim białym szumem, jeśli $\textbf{Cov}_{\xi}=I$ oraz indukowane zmienne losowe są gaussowskie, czyli dla dowolnych elementów $g_1,g_2,\dots,g_k\in G$ i dla dowolnego $k\in \mathbb{N}$ mamy, że \\$(\langle \xi,g_1\rangle,\langle \xi,g_2\rangle,\dots,\langle \xi,g_k\rangle)\sim\mathcal{N}_k(\pmb{0},\pmb{\Sigma})$ oraz $\textbf{Cov}(\langle \xi,g_i\rangle , \langle \xi , g_j\rangle)=\langle g_i, g_j\rangle$.
\end{df}
\begin{lm}[\cite{iphde}, str. 8]\label{lemat1}
Niech $\xi$ będzie białym szumem w przestrzeni $G$ oraz niech $\{u_i\}_{i\in I}$ będzie bazą ortonormalną tej przestrzeni i niech $\xi_i=\langle \xi,u_i\rangle$. Wtedy $\{\xi_i\}_{i\in I}$ są niezależnymi zmiennymi losowymi o tym samym standardowym rozkładzie gaussowskim.
\end{lm}
\begin{proof}
Z definicji $\xi_k=\langle \xi,u_k\rangle\sim \mathcal{N}(0,||u_k||^2)=\mathcal{N}(0,1)$ oraz $\textbf{Cov}(\langle \xi, u_n\rangle,\langle \xi, u_k\rangle)=\langle u_n,u_k\rangle=\delta_{nk}$, gdzie $\delta_{nk}$ oznacza symbol Kroneckera, co wraz z założeniem o łącznym rozkładzie gaussowskim kończy dowód.
\end{proof}

Zauważmy, że gdy $\xi$ jest białym szumem, to $Y$ nie jest elementem przestrzeni $G$, a staje się operatorem działającym na przestrzeni $G$ w następujący sposób
\begin{displaymath}
\forall {g\in G}\ \langle Y,g\rangle =\langle Af,g\rangle + \epsilon\langle \xi, g\rangle
\end{displaymath}
gdzie $\langle \xi, g\rangle\sim\mathcal{N}(0,||g||^2)$.\\

Wprowadzimy teraz kilka faktów dotyczących operatorów liniowych na przestrzeniach Hilberta.

Rozważmy element $A\in L(H,G)$  przestrzeni ograniczonych operatorów liniowych między dwoma przestrzeniami Hilberta $H,G$. Założymy, że $D(A)=\{f\in H\colon \exists_{g\in G}\ Af=g\}=H$.

Operatorem sprzężonym do operatora $A$ nazywamy operator $A^*$ taki, że\\ $\forall_{f\in H}\forall_{g\in G}\ \langle Af,g\rangle=\langle f,A^*g\rangle$, natomiast operator, który jest swoim własnym sprzężeniem nazwiemy samosprzężonym.


Operator $A\colon H\to H$ jest nieujemny, gdy $\forall_{f\in H}\ \langle Af,f\rangle\geq 0$ oraz dodatni, gdy $\forall_{f\in H\setminus \{0\}}\ \langle Af,f\rangle> 0$.

Operator $A\colon H\to G$ jest operatorem śladowym, jeśli istnieje baza $\{x_i\}_i$ przestrzeni $H$ taka, że $\sum_i\langle (A^*A)^{1/2}x_i,x_i\rangle <\infty$ (\cite{hindus}, str. 285).

Estymatorem liniowym elementu $f$ w modelu (\ref{Af}) nazywamy estymator postaci $TY$, gdzie $T$ jest pewnym operatorem z przestrzeni $L(G,H)$, a działanie operatora $T$ na proces $Y$ zdefiniowane jest warunkiem $\langle TY,h\rangle =\langle Y,T^*h\rangle$ dla dowolnego elementu $h\in H$. Jeżeli błąd estymacji ma być mierzony w normie przestrzeni $H$, to trzeba zapewnić, że $TY$ jest losowym elementem $H$, czyli procesem o trajektoriach w $H$, a nie tylko procesem na przestrzeni $H$ w sensie definicji \ref{szum}. Będzie tak, gdy operator kowariancji $TY$ jest operatorem śladowym.


Poniższe twierdzenie pokazuje bardzo użyteczną możliwość rozkładu odpowiednich przestrzeni na pewne składowe wzajemnie ortogonalne.

\begin{tw}[\cite{iphde}, str. 9, \cite{kaipo}, str. 10] Niech $A\in L(H,G)$. Wtedy
\begin{itemize}
\vspace{2mm}
\item $KerA=(RangeA^*)^{\perp}$ oraz $\overline{RangeA}=(KerA^*)^{\perp}$,
\vspace{2mm}
\item jeśli $A$ jest iniektywny, to $A^*A$ też,
\vspace{2mm}
\item $A^*A\in L(H)$ oraz $A^*A$ jest dodatni i samosprzężony.
\vspace{2mm}
\end{itemize}
\end{tw}
\begin{proof}
Zauważmy, że $RangeA^{\perp}=\{g\in G\colon \langle Af,g\rangle =0\ \forall f\in H\}$. Wtedy dla dowolnych $f\in KerA$ i $g\in G$ mamy, że $0=\langle Af,g\rangle=\langle f,A^*g\rangle$, a stąd $KerA=(RangeA^*)^{\perp}$. Zamieniając $A$ z $A^*$ otrzymujemy, że $KerA^*=RangeA^{\perp}$, czyli $(KerA^*)^{\perp}=(RangeA^{\perp})^{\perp}=\overline{RangeA}$, gdyż dla dowolnej przestrzeni Hilberta $H$ i dla dowolnej podprzestrzeni $A$ tej przestrzeni zachodzi, że $(A^{\perp})^{\perp}=\overline{A}$, ponieważ dopełnienie ortogonalne $A^{\perp}$ jest zbiorem domkniętym, co pokażemy korzystając z ciągłości iloczynu skalarnego. Niech $\{x_n\}$ będzie ciągiem Cauchy'ego elementów zbioru $A^{\perp}$ o granicy $x\in H$. Wtedy dla dowolnego elementu $y\in A$ zachodzi $\langle x,y\rangle=\langle x-x_n,y\rangle + \langle x_n,y\rangle=\langle x-x_n,y\rangle + 0\to 0$, gdy $n\to \infty$ co dowodzi, że $x\in A^{\perp}$.

Korzystając z równości $\langle A^*Af,f\rangle=\langle Af,Af\rangle=||Af||^2$, widzimy, że $KerA=KerA^*A$.

Analogicznie otrzymujemy, że $\langle A^*Af,f\rangle=\langle Af,Af\rangle=\langle f, A^*Af\rangle$ oraz $\langle A^*Af, f\rangle=||Af||^2\geq 0$, zatem operator $A^*A$ jest samosprzężony i nieujemny.
\end{proof}
\begin{wn}Dla liniowego operatora $A\colon H \to G$ zachodzi
\begin{itemize}
\vspace{2mm}
\item $H=KerA \oplus KerA^{\perp}=KerA\oplus \overline{RangeA^*}$,
\vspace{2mm}
\item $G=\overline{RangeA}\oplus RangeA^{\perp}=\overline{RangeA}\oplus KerA^*$.
\vspace{2mm}
\end{itemize}
\end{wn}

W pierwszej części pracy ograniczymy się do rozważania tylko zwartych operatorów liniowych, jednak dzięki temu uda się uzyskać dającą szerokie możliwości reprezentację według wartości singularnych. Założenie o zwartości badanego operatora jest naturalnym i często pojawiającym się założeniem w kontekście badania problemów odwrotnych w statystyce z uwagi na częste występowanie operatorów z tej klasy w praktycznych problemach, a także z uwagi na ich bardzo wygodną reprezentację. 

\begin{df}[\cite{hindus}, str. 264]
Operator $A\colon H \to G$ nazywamy zwartym, jeżeli dla każdego ograniczonego zbioru w $H$, jego obraz przez operator $A$ jest względnie zwarty w $G$, czyli jego domknięcie jest zwarte w $G$. Przez $K(H,G)$ będziemy oznaczać zbiór operatorów zwartych między przestrzeniami $H$ i $G$.
\end{df}

Przykładem operatorów zwartych są operatory całkowe postaci $\left(Ku\right)(x)=$\\$=\int_a^bK(x,y)u(y)dy$, $x\in [a,b],\ u\in C([a,b])$, gdzie jądro $K(x,y)$ jest takie, że $\int_a^b\int_a^b|K(x,y)|^2dxdy<+\infty$ lub słabo osobliwe, czyli postaci $\frac{\mathcal{H}(x,y)}{|x-y|^{\alpha}}$, gdzie $\alpha\in (0,1)$ a funkcja $\mathcal{H}$ jest funkcją mierzalną i ograniczoną na odcinku $[a,b]$.

Konsekwencją braku zwartości kuli jednostkowej w przestrzeniach nieskończenie wymiarowych jest bardzo istotna z punktu widzenia stabilności rozwiązania następująca uwaga.
\begin{uw}
Jeżeli $A\in K(H,G)$ oraz $dimH=\infty$ to operator $A^{-1}$ jest nieograniczony, o ile istnieje.
\end{uw}
Fakt ten powoduje, że dla dowolnego zwartego operatora na przestrzeni nieskończenie wymiarowej, każdy związany z nim problem odwrotny jest źle postawiony.

Poniżej bez dowodu przytaczamy znane twierdzenie dotyczące reprezentacji spektralnej dla operatorów zwartych i samosprzężonych potrzebne do wykazania istnienia reprezentacji według wartości singularnych dla operatorów zwartych, ale już niekoniecznie samosprzężonych.

\begin{tw}[Reprezentacja spektralna]
Niech $A$ będzie samosprzężonym operatorem zwartym na przestrzeni Hilberta $H$. Wtedy istnieje zupełny układ ortonormalnych wektorów własnych $E=\{f_j,j\in I\}\subset H$. Niech $J=\{j\in I\colon\lambda_j\neq 0\}$ oznacza zbiór tych indeksów dla których odpowiednie wartości własne są niezerowe, wtedy zbiór $J$ jest przeliczalny oraz 
\begin{displaymath}
\forall f\in H\ Af=\sum_{j\in J}\lambda_j\langle f,f_j\rangle f_j.
\end{displaymath}
Ponadto dla każdego $\delta>0$ zbiór $J_{\delta}=\{j\in I\colon |\lambda_j|\geq \delta\}$ jest skończony, czyli jedynym możliwym punktem skupienia zbioru wartości własnych jest zero.
\end{tw}
\begin{proof}
Dowód w \cite{iphde}, str. 11.
\end{proof}

Możemy teraz wprowadzić reprezentację według wartości singularnych dla operatora zwartego.

\begin{tw}[Reprezentacja według wartości singularnych]
Niech $A\colon H\to G$ będzie operatorem zwartym między przestrzeniami Hilberta $H$ i $G$. Wtedy istnieją skończony lub zbieżny do zera ciąg liczb dodatnich $\{b_n\}_{n\in I}$ oraz układy ortonormalne $\{v_n\}_{n\in I}\subset H,\ \{u_n\}_{n\in I}\subset G$ takie, że zachodzi
\begin{itemize}
\vspace{2mm}
\item $KerA^{\perp}=\overline{span\{v_n,\ n\in I\}}$,
\vspace{2mm}
\item $\overline{RangeA}=\overline{span\{u_n,\ n\in I\}}$,
\vspace{2mm}
\item $Af=\sum_nb_n\langle f, v_n\rangle u_n$ oraz $A^*g=\sum_nb_n\langle g, u_n\rangle v_n$.
\vspace{2mm}
\end{itemize}
Ponadto $g\in RangeA$ wtedy i tylko wtedy, gdy $g=\sum_n\langle g, u_n\rangle u_n$ oraz spełniony jest tzw. warunek Picarda
\begin{displaymath} 
\sum_nb_n^{-2}|\langle g, u_n\rangle|^2< \infty .
\end{displaymath}
Wtedy rozwiązania równania $Af=g$ mają postać 
\begin{displaymath}
f=f_0+\sum_nb_n^{-1}\langle g, u_n\rangle v_n
\end{displaymath}
przy czym $f_0\in KerA$ jest dowolne.
\end{tw}
Układ $(u_n,v_n,b_n)$ nazywamy układem singularnym operatora $A$ a jego reprezentację w postaci $Af=\sum_n\lambda_n\langle f,v_n\rangle u_n$ nazywamy dekompozycją według wartości singularnych operatora $A$.
\begin{proof}(\cite{kaipo}, str. 11, \cite{szkutnik}, str. 10) Dowód twierdzenia opiera się na wykorzystaniu twierdzenia spektralnego do operatora $A^*A$. Operator $A^*A$ jest samosprzężony, zwarty i nieujemny, a zatem istnieją liczby $b_1^2\geq b_2^2\geq\dots\geq 0$ oraz wektory ortonormalne $v_n$ takie, że $A^*Av_n=b_n^2v_n$. Niech $I=\{n\colon b_n>0\}$ oraz przez $u_n$ oznaczmy znormalizowane obrazy wektorów $v_n$, czyli $u_n=b_n^{-1}Av_n$ dla $n\in I$. Zauważmy, że $\langle u_k,u_l\rangle=b_k^{-1}b_l^{-1}\langle Av_k, Av_l\rangle=b_k^{-1}b_l^{-1}\langle v_k,A^*Av_l\rangle=b_k^{-1}b_l^{-1}\langle v_k,b_l^2v_l\rangle=\delta_{kl}$.

Korzystając w wykazanego wcześniej twierdzenia dostajemy, że $KerA^{\perp}=(KerA^*A)^{\perp}=\overline{RangeA^*A}=\overline{span\{v_n,\ n\in I\}}$.

Analogicznie rozpatrując operator $AA^*$ z rozkładem spektralnym $AA^*u_n=b_n^2u_n$ dostajemy, że $\overline{RangeA}=\overline{span\{u_n,\ n\in I\}}$.

Tożsamości $Af=\sum_nb_n\langle f, v_n\rangle u_n$ oraz $A^*g=\sum_nb_n\langle g, u_n\rangle v_n$ otrzymujemy, zauważając
\begin{displaymath}
\begin{split}
Af&=\sum_n\langle Af,u_n\rangle u_n=\sum_n\langle Af, b_n^{-1}Av_n\rangle u_n= \sum_n\langle f,b_n^{-1}A^*Av_n\rangle u_n\\ &=\sum_n\langle f,b_n^{-1}b_n^2v_n\rangle u_n=\sum_n b_n\langle f,v_n\rangle u_n
\end{split}
\end{displaymath} oraz równość drugą analogicznie.

Z nierówności Bessela dostajemy, że $\sum_n|\langle f, v_n\rangle |^2<\infty$, bo $f\in H$ a stąd
\begin{displaymath}
\begin{split}
\sum_n|\langle f,v_n\rangle|^2&=\sum_nb_n^{-4}|\langle f,b_n^2v_n\rangle|^2=\sum_nb_n^{-4}|\langle f, A^*Av_n\rangle|^2=\sum_nb_n^{-4}|\langle Af,Av_n\rangle|^2\\
&=\sum_nb_n^{-2}|\langle g, b_n^{-1}Av_n\rangle|^2=\sum_nb_n^{-2}|\langle g, u_n\rangle|^2<\infty.
\end{split}
\end{displaymath}
W drugą stronę wnioskujemy, że jeśli spełniony jest warunek Picarda to możemy wypisać jawny wzór na rozwiązanie,  gdyż odpowiedni szereg norm współczynników jest zbieżny i $g$ jest sumą swojego szeregu Fouriera.

Ostatecznie możemy wnioskować, że $f=f_0+\sum_nb_n^{-1}\langle g, u_n\rangle v_n$, gdzie $f_0\in KerA$ jest rozwiązaniem, gdyż na mocy powyższych faktów mamy
\begin{displaymath}
\begin{split}
Af=A(f_0+\sum_nb_n^{-1}\langle g, u_n\rangle v_n)=\sum_n\langle g, u_n\rangle b_n^{-1}Av_n=g.
\end{split}
\end{displaymath}
Z drugiej strony, jeżeli $Af=g$, to mamy, że $g=\sum_n\langle g, u_n\rangle u_n$ oraz $Af=\sum_n b_n\langle f, v_n\rangle u_n$ zatem musi zachodzić, że $b_n\langle f, v_n\rangle = \langle g,u_n\rangle $ dla każdego $n\in \mathbb{N}$, czyli $f=\sum_n b_n^{-1}\langle g,u_n\rangle +f_0$, gdzie $f_0\in KerA$.
\end{proof}

Udało nam się zaprezentować działanie operatora zwartego w postaci jego rozwinięcia według wartości singularnych w postaci $Af=\sum_nb_n\langle f, v_n\rangle u_n$ oraz uzyskać postać szukanych rozwiązań w postaci $f=f_0+\sum_nb_n^{-1}\langle g, u_n\rangle v_n$. Jednak takie rozwiązanie sytuacji stawia przed nami nowe problemy, gdy $g$ jest znane tylko w przybliżeniu. Po pierwsze zauważmy, że jeżeli tylko $g$ posiada niezerowe składowe w przestrzeni ortogonalnej do domknięcia obrazu operatora $A$ równanie $Af=g$ nie może być spełnione dokładnie. Niech $P\colon G\to \overline{RangeA}$ będzie rzutem ortogonalnym, czyli $\forall_{g\in G}\ Pg=\sum_n\langle g,u_n\rangle u_n$. Wtedy dla dowolnego elementu $f\in H$ mamy, że $||Af-g||^2=||Af-Pg||^2+||(1-P)g||^2\geq ||(1-P)g||^2$.

Drugi problem związany jest ze zbieżnością szeregu w warunku Picarda. Z twierdzenia o reprezentacji spektralnej operatora zwartego samosprzężonego wiemy, że liczby $b_n\to 0$, gdy $n\to \infty$, a zatem liczby $b_n^{-2}\to \infty$, gdy $n \to \infty$, a nie mamy żadnej gwarancji, że liczby $\langle g,u_n\rangle$ zbiegają do zera odpowiednio szybko by zrównoważyć ten przyrost w przypadku zaburzonej wartości $g$.


W kolejnym kroku ograniczając się do badania operatorów zwartych w modelu białego szumu wprowadzimy równoważną formę wyjściowego zagadnienia 
\begin{displaymath}
Y=Af+\epsilon\xi
\end{displaymath}
w postaci tak zwanego modelu ciągowego.\\

Rozważmy układ singularny $(u_n,v_n,b_n)$ operatora zwartego $A$ oraz niech $\xi$ będzie białym szumem. Możemy wtedy zapisać, rozpatrując działanie $Y$ na układ $\{u_n\}$, że
\begin{displaymath}
\begin{split}
\langle Y,u_n\rangle &=\langle Af,u_n\rangle +\epsilon\langle \xi, u_n\rangle=\langle Af,b_n^{-1}Av_n\rangle+\epsilon \xi_n=b_n^{-1}\langle A^*Af, v_n\rangle+\epsilon \xi_n\\
&=b_n^{-1}\langle \sum_kb_k^2\langle f, v_k\rangle v_k, v_n\rangle +\epsilon\xi_n=b_n\theta_n+\epsilon\xi_n,
\end{split}
\end{displaymath}
gdzie $\theta_n=\langle f,v_n\rangle$ są współczynnikami w rozwinięciu Fouriera funkcji $f$ w bazie $\{v_n\}$,a $\xi_n=\langle \xi, u_n\rangle$ są zgodnie z lematem \ref{lemat1} niezależnymi zmiennymi losowymi o standardowym rozkładzie normalnym.

Oznaczając $y_n=\langle Y,u_n\rangle$ możemy wyjściowy problem $Y=Af+\epsilon\xi$ zapisać w równoważnej postaci modelu ciągowego jako
\begin{displaymath}
y_n=b_n\theta_n+\epsilon\xi_n,\ n=1,2,\dots.
\end{displaymath}
W tej postaci widać dokładnie trudności związane ze stochastycznymi problemami odwrotnymi. Jako że $b_n$ są wartościami singularnymi operatora zwartego mamy, że $b_n\to 0$, gdy $n\to \infty$, czyli widać, że wraz ze wzrostem $n$ sygnał $b_n\theta_n$ staje się coraz słabszy i coraz trudniej estymować $\theta_n$. Dodatkową trudnością jest fakt, że naszym celem jest estymacja współczynników $\theta_n$ a nie współczynników $b_n\theta_n$, dlatego możemy zapisać równoważną postać problemu
\begin{equation}\label{ssm}
x_n=\theta_n+\epsilon\sigma_n\xi_n,\ n=1,2,\dots
\end{equation}
gdzie $x_n=y_n/b_n$ oraz $\sigma_n=b_n^{-1}$, czyli $\sigma_n\to \infty$ gdy $n\to \infty$. \\

Korzystając z powyższego modelu wprowadzimy notację i pojęcia związane z konstrukcją rozważanych estymatorów i ich własnościami.\\
Mając pełną i niezaburzoną informację o współczynnikach $\theta_n,\ n=1,2,\dots$ można by uzyskać pełną informację o poszukiwanym elemencie $f$ z dokładnością do składowej znajdującej się w jądrze operatora $A$ kładąc $f=\sum_n\theta_nv_n$. W naturalny sposób można by zatem estymować współczynniki $\theta_n$ przez odpowiednie zaobserwowane wartości $x_n$, gdyż $\mathbb{E}_f(x_n)=\theta_n$. Uzasadnione może jednak być estymowanie współczynników rozwinięcia nie bezpośrednio przez zaobserwowane wartości, a przez przeskalowane w pewien sposób wartości, aby uwzględnić różne poziomy szumu. 
\begin{df}
Niech $\lambda=(\lambda_1,\lambda_2,\dots)$ będzie nielosowym ciągiem liczbowym. Estymatorem liniowym współczynników $\theta_n$ w modelu (\ref{ssm}) nazwiemy estymator $\hat{\theta}(\lambda)=(\hat{\theta}_1,\hat{\theta}_2,\dots)$, gdzie
\begin{displaymath}
\hat{\theta}_i=\lambda_ix_i,\ i=1,2,\dots.
\end{displaymath}
Ciąg $\lambda$ nazywać będziemy filtrem lub wagami.
\end{df}
Powyższa definicja jest przeformułowaniem ogólnej definicji estymatora liniowego w modelu (\ref{Af}) obserwacji z szumem. 
Przykładowo estymatory rzutowe estymujące poszukiwany element $f$ przez początkowe $N$ składników w rozwinięciu w szereg Fouriera ze współczynnikami równymi zaobserwowanym wartościom odpowiadają filtrom $\lambda=(\lambda_1,\lambda_2,\dots)$, w których $\lambda_i=\pmb{1}_{\{i\leq N\}}$, gdzie $\pmb{1}_A$ oznacza indykator zbioru $A$. Innymi często stosowanymi wagami są wagi Tichonowa-- Phillipsa postaci $\lambda_i=\frac{1}{1+(i/w)^a}$, $w>0,\ a>0$ lub Pinskera postaci $\lambda_i=\max\{0,1-(i/w)^a\}$, $w>0,\ a>0$. \\

Jakość estymatora $\hat{f}$ elementu $f$ mierzona będzie przy pomocy scałkowanego ryzyka średniokwadratowego.
\begin{df}
Scałkowanym ryzykiem średniokwadratowym estymatora $\hat{f}$ elementu $f$ nazywamy wyrażenie
\begin{displaymath}
\mathcal{R}(\hat{f},f)=\mathbb{E}_f||f-\hat{f}||^2.
\end{displaymath}
\end{df}
W przypadku modelu (\ref{ssm}) estymator $\hat{f}$ możemy zapisać w postaci $\hat{f}=\sum_n\hat{\theta}_nv_n$. Wtedy dostajemy, że 
\begin{displaymath}
\mathcal{R}(\hat{f},f)=\mathbb{E}_f||f-\hat{f}||^2=\mathbb{E}_{\theta}\sum_n\left(\theta_n-\hat{\theta}_n\right)^2=\mathbb{E}_{\theta}||\theta-\hat{\theta}||^2,
\end{displaymath}
gdzie druga równość wynika z tożsamości Parsevala, a norma $||\cdot ||$ rozumiana jest odpowiednio w przestrzeni $L_2$ lub $l^2$, natomiast wartość oczekiwana jest liczona odpowiednio względem $Y$ lub $X=(x_1,x_2,\dots)$, w zależności od przyjętego modelu obserwacji. Zatem w przypadku modelu (\ref{ssm}) analiza ryzyka $\mathcal{R}(\hat{f},f)$ jest równoważna analizie ryzyka $\mathcal{R}(\hat{\theta},\theta)=\mathbb{E}_{\theta}||\theta-\hat{\theta}||^2$. W przypadku estymatorów liniowych wyrażenie na ryzyko estymatora przyjmuje postać 
\begin{equation}\label{risk}
\begin{split}
\mathbb{E}_{\theta}||\theta-\hat{\theta}||^2&=\mathbb{E}_{\theta}\sum_{n=1}^{\infty}\left(\theta_n-\hat{\theta}_n(\lambda)\right)^2=\mathbb{E}_{\theta}\sum_{n=1}^{\infty}\left(\theta_n-\lambda_nx_n\right)^2\\
&=\sum_{n=1}^{\infty}(1-\lambda_n)^2\theta_n^2+\epsilon^2\sum_{n=1}^{\infty}\sigma_n^2\lambda_n^2.
\end{split}
\end{equation}
Pierwszy składnik odpowiada za obciążenie estymatora, natomiast drugi za jego wariancję.\\
\begin{df}[\cite{iphde}, str. 28] Ryzykiem minimaksowym w klasie funkcji $\mathcal{F}$ nazywamy wyrażenie 
\begin{displaymath}
r(\mathcal{F})=\inf_{\hat{f}}\sup_{f\in \mathcal{F}}\mathcal{R}(\hat{f},f),
\end{displaymath}
gdzie $\inf_{\hat{f}}$ wzięte jest po wszystkich możliwych estymatorach elementu $f$.
\end{df}
W przypadku nieparametrycznego podejścia do estymacji, wyznaczenie estymatora realizującego ryzyko minimaksowe jest zwykle niemożliwe, dlatego poszukiwać będziemy estymatora asymptotycznie minimaksowego. 
\begin{df}[\cite{iphde}, str. 28] Przypuśćmy, że istnieje estymator $\tilde{f}$, taki, że istnieją stałe $0<C_1\leq C_2<\infty$ takie, że gdy $\epsilon\to 0$, to zachodzi 
\begin{displaymath}
\sup_{f\in \mathcal{F}}\mathcal{R}(\tilde{f},f)\leq C_2a_{\epsilon}
\end{displaymath}
\begin{displaymath}
\inf_{\hat{f}}\sup_{f\in \mathcal{F}}\mathcal{R}(\hat{f},f)\geq C_1a_{\epsilon},
\end{displaymath}
gdzie ciąg nieujemnych wartości $a_{\epsilon}$ jest taki, że $a_{\epsilon}\to 0$, gdy $\epsilon\to 0$.
Mówimy wtedy, że estymator $\tilde{f}$ jest optymalny lub osiąga optymalne tempo zbieżności na klasie $\mathcal{F}$. W przypadku gdy $C_1=C_2$, mówimy, że estymator $\tilde{f}$ jest asymptotycznie minimaksowy.
\end{df}

W ostatniej części tego rozdziału wprowadzone zostanie pojęcie wyroczni. Przypuśćmy przez chwilę, że zajmujemy się estymacją współczynników $\theta_i$ w następującym modelu 
\begin{displaymath}
x_i=\theta_i+\sigma\epsilon_i,\ i=1,2,\dots,n,
\end{displaymath}
gdzie $\sigma$ jest stała dla wszystkich obserwacji, a $\epsilon_i$ są niezależnymi zmiennymi losowymi o standardowym rozkładzie normalnym. Będziemy je estymować przy pomocy estymatorów liniowych ze stałymi wagami, czyli postaci $\lambda X=(\lambda x_1,\lambda x_2,\dots, \lambda x_n)$. W takim przypadku ryzyko takiego estymatora wynosi 
\begin{displaymath}
\mathcal{R}(\hat{\theta},\theta)=(1-\lambda)^2||\theta||^2_n+n\lambda^2\sigma^2,
\end{displaymath}
gdzie $||\theta||_n^2=\sum_{i=1}^n\theta_i^2$. Ryzyko to jest minimalizowane przez zadanie wag postaci
\begin{displaymath}
\tilde{\lambda}=\frac{||\theta||^2_n`}{n\sigma^2+||\theta||^2_n}.
\end{displaymath}
Wtedy estymator $\tilde{\lambda}X$ osiąga minimalne ryzyko w rozważanej klasie estymatorów równe
\begin{displaymath}
\mathcal{R}(\tilde{\lambda}X,\theta)=\frac{||\theta||^2_n`}{n\sigma^2+||\theta||^2_n}=\inf_{\hat{\theta} \in \Lambda}\mathcal{R}(\hat{\theta},\theta),
\end{displaymath}
gdzie $\Lambda=\{\lambda X\colon \lambda\in [0,1]\}$ jest rozważaną klasą estymatorów, w której wystarczy ograniczyć się do rozważania wag z przedziału $[0,1]$, gdyż wagi spoza tego przedziału prowadzą do estymatorów niedopuszczalnych. Zauważmy jednak, że nie możemy zastosować tak wyznaczonego estymatora, gdyż korzysta on z niedostępnej dla nas informacji o estymowanym elemencie poprzez $||\theta||_n^2$. Minimalne ryzyko może zostać osiągnięte jedynie przez wyrocznię, która zna estymowany element. Naszym celem byłaby konstrukcja takiej metody wyznaczania wagi $\lambda$, która korzystając jedynie z informacji zawartej w obserwowanej próbie starałaby się naśladować zachowanie wyroczni w kontekście osiąganego ryzyka. Tak postawione zagadnienie rozwiązywane jest przez znalezienie estymatora $\theta^*$, którego ryzyko daje się kontrolować przez nieasymptotyczne nierówności wyrocznie postaci 
\begin{equation}\label{oracle}
\mathcal{R}(\theta^*,\theta)\leq C_1 \inf_{\hat{\theta} \in \Lambda}\mathcal{R}(\hat{\theta},\theta)+C_2(\Lambda,\sigma), 
\end{equation}
gdzie stałe $C_1,C_2(\Lambda,n)$ nie zależą od estymowanego elementu, jednak stała $C_2(\Lambda,n)$ może zależeć od liczności rodziny $\Lambda$ bądź od jej odpowiednio zdefiniowanej złożoności, gdy jest ona nieskończona oraz od poziomu szumu $\sigma$ (\cite{mitchell}, str. 177). Dodatkowo pożądaną własnością takiego estymatora jest, by powyższa nierówność wyrocznia prowadziła do dokładnych nierówności postaci
\begin{equation}\label{aoracle}
\mathcal{R}(\theta^*,\theta)\leq(1+o(1))\inf_{\hat{\theta} \in \Lambda}\mathcal{R}(\hat{\theta},\theta)
\end{equation}
gdy $\sigma\to 0$. W przypadku rozważanego na początku rozdziału problemu poszukiwanym estymatorem naśladującym wyrocznię jest estymator Jamesa-- Steina z wagą
\begin{displaymath}
\lambda^*=1-\frac{(n-2)\sigma^2}{\sum_{i=1}^nx_i^2}
\end{displaymath}
spełniający nierówność wyrocznię postaci
\begin{displaymath}
\mathcal{R}(\lambda^*X,\theta)\leq 2\sigma^2+\mathcal{R}(\tilde{\lambda} X,\theta).
\end{displaymath}
Szczegółowe uzasadnienie można znaleźć w \cite{wasserman}, str. 156.

W badanym w pracy zagadnieniu zaprezentowane zostaną analogiczne nierówności wyrocznie postaci (\ref{oracle}) i (\ref{aoracle}) dla wszystkich badanych klas operatorów. Mając je do dyspozycji można uzasadnić optymalny wybór parametrów wygładzających w przypadku na przykład estymatorów typu rzutowego, Tichonowa-- Phillipsa czy Pinskera.\\

\chapter{Nierówności wyrocznie w modelu z operatorem zawartym}\label{G1}
Rezultaty opisane w tym rozdziale są rezultatami uzyskanymi w pracy \cite{cavalier1} z kilkoma modyfikacjami.\\
\indent Przypuśćmy, że dysponujemy skończonym zbiorem filtrów $\Lambda=(\lambda^1,\dots, \lambda^N)$ i związanych z nimi estymatorów liniowych, gdzie $\lambda^i=(\lambda^i_1,\lambda^i_2,\dots),\ i=1,2,\dots, N$. Naszym celem będzie konstrukcja filtra opartego na obserwacjach $\lambda^*(X)=(\lambda^*_1,\lambda^*_2,\dots)$ o wartościach w zbiorze $\Lambda$ o asymptotycznie minimalnym ryzyku przy prawdziwej wartości $\theta$, który równocześnie naśladuje ryzyko najlepszego estymatora w tej klasie w każdej skończonej próbie. Okaże się, że filtr ten może zostać zdefiniowany jako element minimalizujący względem $\lambda \in \Lambda$ nieobciążony estymator ryzyka. Zgodnie z (\ref{risk}) ryzyko estymatora liniowego wyraża się wzorem
\begin{displaymath}
\mathcal{R}(\hat{\theta},\theta)=\sum_{n=1}^{\infty}(1-\lambda_n)^2\theta_n^2+\epsilon^2\sum_{n=1}^{\infty}\sigma_n^2\lambda_n^2.
\end{displaymath}
Aby uzyskać skończone ryzyko, trzeba dobierać filtry tak, by drugi człon był skończony.
\begin{za}
\begin{displaymath}\label{ass1}
\forall_{\lambda\in \Lambda}\ 0<\sum_{n=1}^{\infty}\sigma_n^2\lambda_n^2<\infty
\end{displaymath}
\end{za}
Ponadto założenie o dodatniości powyższej sumy implikuje, że żaden z rozważanych filtrów nie może być tożsamościowo równy zeru.
Dodatkowo z postaci wyrażenia na ryzyko widać, że wystarczy ograniczyć się do rozpatrywania wag takich, że $\forall_{\lambda\in \Lambda}\forall_i\ \lambda_i\in [0,1]$, gdyż w przeciwnym wypadku uzyskane estymatory stają się niedopuszczalne. Mimo tego narzucimy na rozważane wagi nieco słabsze wymagania, aby rozszerzyć zakres stosowalności wyników.
\begin{za}
\begin{displaymath}\label{ass2}
\max_{\lambda\in \Lambda}\sup_i|\lambda_i|\leq 1
\end{displaymath}
\end{za}
\indent Ponadto będziemy zakładać skończoność poniższej sumy, by występujące później wyrażenia były skończone. Założenie to nie jest jawnie sformułowane w pracy \cite{cavalier1}.
\begin{za}\label{ass3}
\begin{displaymath}
\forall_{\lambda\in \Lambda}\ \sum_{n=1}^{\infty}\lambda_n\sigma_n^2<\infty.
\end{displaymath}
\end{za}
Z założenia \ref{ass2} wynika następująca nierówność
\begin{displaymath}
\sum_{k=1}^{\infty}\sigma_k^4\lambda_k^4\leq\sum_{k=1}^{\infty}\sigma_k^4\lambda_k^2.
\end{displaymath}
Dodatkowo wymagać będziemy istnienia następującej stałej, której istnienie implikuje, że obie te sumy są tego samego rzędu
\begin{za}
\begin{displaymath}\label{ass5}
\exists_{C_1>0}\forall_{\lambda\in \Lambda}\ \sum_{k=1}^{\infty}\sigma_k^4\lambda_k^2\leq C_1\sum_{k=1}^{\infty}\sigma_k^4\lambda_k^4.
\end{displaymath}
\end{za}
\indent Kolejnym krokiem jest wyznaczenie nieobciążonego estymatora wyrażenia (\ref{risk}). W dalszym ciągu rozważań założymy, że poziom szumu $\epsilon$ jest znany, natomiast czynniki $\sigma_n$ związane są z rozważanym operatorem, którego pełna znajomość także jest zakładana. Pozostaje znalezienie nieobciążonego estymatora dla składników $\theta_n^2$. Zgodnie z modelem (\ref{ssm}) estymatorem takim jest $x_n^2-\sigma_n^2\epsilon^2$, gdyż $x_n\sim \mathcal{N}(\theta_n,\sigma_n^2\epsilon^2)$. Wstawiając to wyrażenie do wzoru opisującego ryzyko estymatora liniowego dostajemy
\begin{displaymath}
\begin{split}
\sum_{n=1}^{\infty}(1-\lambda_n)^2&(x_n^2-\sigma_n^2\epsilon^2)+\epsilon^2\sum_{n=1}^{\infty}\sigma_n^2\lambda_n^2\\& =\sum_{n=1}^{\infty}(x_n^2-\sigma_n^2\epsilon^2)+ \sum_{n=1}^{\infty}(\lambda_n^2-2\lambda_n)(x_n^2-\sigma_n^2\epsilon^2) +\epsilon^2\sum_{n=1}^{\infty}\sigma_n^2\lambda_n^2\\&  = \sum_{n=1}^{\infty}(x_n^2-\sigma_n^2\epsilon^2)+\sum_{n=1}^{\infty}(\lambda_n^2-2\lambda_n)x_n^2+2\epsilon^2\sum_{n=1}^{\infty}\lambda_n\sigma_n^2.
\end{split}
\end{displaymath}
Jest to nieobciążony estymator ryzyka. Naszym celem jest jednak minimalizacja tego estymatora ze względu na wagi $\lambda_i$, stąd wystarczy ograniczyć się do rozpatrywania wyrażenia 
\begin{equation}\label{ure}
U(\lambda,X)=\sum_{n=1}^{\infty}(\lambda_n^2-2\lambda_n)x_n^2+2\epsilon^2\sum_{n=1}^{\infty}\lambda_n\sigma_n^2
\end{equation}
będącego nieobciążonym estymatorem $\mathcal{R}(\hat{\theta},\theta)-\sum_{n=1}^{\infty}\theta_n^2$. Wyrażenie to jest skończone gdyż, dla dowolnego $\theta=\{\theta_i\}_{i=1}^{\infty}\in l^2$ i $\lambda$ spełniającego założenia \ref{ass1}-- \ref{ass3} oraz ciągu zmiennych losowych określonych jako $\sqrt{\lambda_i^2-2\lambda_i}x_i$ o rozkładzie $\mathcal{N}(\sqrt{\lambda_i^2-2\lambda_i}\theta_i,(\lambda_i^2-2\lambda_i)\sigma_i^2\epsilon^2)$ mamy
\begin{displaymath}
\sum_{i=1}^{\infty}(\lambda_i^2-2\lambda_i)\theta_i^2\leq 3\sum_{i=1}^{\infty}\theta_i^2<\infty,
\end{displaymath}
\begin{displaymath}
\sum_{i=1}^{\infty}(\lambda_i^2-2\lambda_i)\sigma_i^2\epsilon^2=\epsilon^2\sum_{i=1}^{\infty}\lambda_i^2\sigma_i^2-2\epsilon^2\sum_{i=1}^{\infty}\lambda_i\sigma_i^2<\infty,
\end{displaymath}
co na mocy lematu \ref{druga} implikuje zbieżność $U(\lambda,X)$ w normie $L_2$.
\begin{uw}
Wariancja funkcjonału $U(\lambda,X)$ wyraża się wzorem
\begin{displaymath}
\begin{split}
\textbf{Var}\  U(\lambda,X)&=2\epsilon^4\sum_{n=1}^{\infty}\lambda_n^4\sigma_n^4-\sum_{n=1}^{\infty}\lambda_n^4\theta_n^4-2\epsilon^2\sum_{n=1}^{\infty}\theta_n^2\sigma_n^2\lambda_n^4\\
&+8\epsilon^4\sum_{n=1}^{\infty}\sigma_n^4\lambda_n^2-4\sum_{n=1}^{\infty}\lambda_n^2\theta_n^4-8\epsilon^2\sum_{n=1}^{\infty}\lambda_n^2\sigma_n^2\theta_n^2-8\epsilon^4\sum_{n=1}^{\infty}\lambda_n^3\sigma_n^4\\
&+4\sum_{n=1}^{\infty}\lambda_n^3\theta_n^4+8\epsilon^2\sum_{n=1}^{\infty}\theta_n^2\sigma_n^2\lambda_n^3 \leq 2\epsilon^4\sum_{n=1}^{\infty}\lambda_n^4\sigma_n^4+8\epsilon^4\sum_{n=1}^{\infty}\sigma_n^4\lambda_n^2.
\end{split}
\end{displaymath}
\end{uw}
Wariancja ta jest skończona na mocy wcześniejszych założeń \ref{ass1}, \ref{ass2} i \ref{ass5}.

Mając do dyspozycji odpowiednie wyrażenie związane z estymatorem ryzyka, możemy zdefiniować poszukiwany filtr wzorem
\begin{equation}\label{estimator}
\lambda^*=\arg\min_{\lambda\in \Lambda}U(\lambda,X).
\end{equation}
Dla tak zdefiniowanej metody wyboru wag pokazane i udowodnione zostaną nierówności wyrocznie.\\
\indent Wprowadzimy następujące oznaczenia na występujące w późniejszych rozważaniach wielkości
\begin{displaymath}
\begin{split}
&\rho(\lambda)=\sup_n\sigma_n^2|\lambda_n|\left[\sum_{k=1}^{\infty}\sigma_k^4\lambda_k^4\right]^{-1/2},\\
&\rho=\max_{\lambda\in \Lambda}\rho(\lambda),\\
&S=\frac{\max_{\lambda\in\Lambda}\sup_n\sigma_n^2\lambda_n^2}{\min_{\lambda\in \Lambda}\sup_n\sigma_n^2\lambda_n^2},\\
&M=\sum_{\lambda\in \Lambda}\exp\left(\frac{-1}{\rho(\lambda)}\right),\\
&L_{\lambda}=\ln(NS)+\rho^2\ln^2(MS).
\end{split}
\end{displaymath}
Wielkość $\rho(\lambda)$ jest pewnym sposobem mierzenia wielkości poszczególnych filtrów biorącym pod uwagę zarówno tempo znikania dalekich wyrazów poprzez $\left[\sum_{k=1}^{\infty}\sigma_k^4\lambda_k^4\right]^{-1/2}$ jak i rozrzut wokół zera poprzez $\sup_n\sigma_n^2|\lambda_n|$. Parametry $S$ i $M$ mierzą natomiast zachowanie rodziny wag $\Lambda$. Liczbę $S$ można interpretować jako rozrzut bądź zmienność w rodzinie $\Lambda$ natomiast $M$ jest czynnikiem kontrolującym masywność tej rodziny (dalszy komentarz na temat znaczenia parametru $M$ można znaleźć w pracy \cite{birge}). Zauważmy ponadto, że na mocy założeń \ref{ass1} i \ref{ass3} wszystkie te wartości są liczbami skończonymi.\\
\indent Jak widzieliśmy z postaci wariancji funkcjonału $U(\lambda, X)$ sumy $\epsilon^4\sum_{k=1}^{\infty}\sigma_k^4\lambda_k^4$ i $\epsilon^4\sum_{k=1}^{\infty}\sigma_k^4\lambda_k^2$ są głównymi jej składnikami. Z drugiej strony ze wzoru \ref{risk} mamy, że $\mathcal{R}(\hat{\theta},\theta)\geq \epsilon^2\sum_{k=1}^{\infty}\sigma_k^2\lambda_k^2$ oraz 
\begin{equation}\label{rho}
\frac{\left(\epsilon^4\sum_{k=1}^{\infty}\sigma_k^4\lambda_k^4\right)^{1/2}}{\epsilon^2\sum_{k=1}^{\infty}\sigma_k^2\lambda_k^2}\leq \rho,
\end{equation}
ponieważ z uwagi na założenie \ref{ass2}
\begin{displaymath}
\sum_{k=1}^{\infty}\sigma_k^4\lambda_k^4\leq \sum_{k=1}^{\infty}\sigma_k^4|\lambda_k|^3=\sum_{k=1}^{\infty}\sigma_k^2\lambda_k^2\cdot \sigma_k^2|\lambda_k|\leq \sup_k\sigma_k^2|\lambda_k|\leq\sum_{k=1}^{\infty}\sigma_k^2\lambda_k^2,
\end{displaymath}
a stąd i z definicji $\rho(\lambda)$ dostajemy, że dla dowolnego $\lambda\in \Lambda$
\begin{displaymath}
\frac{\left(\epsilon^4\sum_{k=1}^{\infty}\sigma_k^4\lambda_k^4\right)^{1/2}}{\epsilon^2\sum_{k=1}^{\infty}\sigma_k^2\lambda_k^2}\leq \rho(\lambda)\leq\rho.
\end{displaymath}
Zatem parametr $\rho$ pozwala kontrolować wielkość stosunku odchylenia standardowego do wartości oczekiwanej funkcjonału $U(\lambda,X)$, czyli $\textbf{Var}^{1/2}U(\lambda,X)/\mathcal{R}(\hat{\theta},\theta)$ jednostajnie względem $\lambda$ i $\theta$. Dodatkowo z 
\begin{displaymath}
\forall_{\lambda\in \Lambda}\ \rho(\lambda)\leq \sqrt{C_1}.
\end{displaymath}
Przed wypowiedzeniem głównego twierdzenia zauważmy jeszcze, że zawsze zachodzi związek
\begin{displaymath}
M\leq N,
\end{displaymath}
gdzie $N$ oznacza liczność rodziny $\Lambda$.\\
\indent W poniższych dwóch twierdzeniach zebrane są główne wyniki otrzymane dla rozważanych problemów odwrotnych z operatorami zwartymi.
\begin{tw}\label{glowny1}
Niech spełnione będą założenia \ref{ass1}-- \ref{ass5}. Wtedy dla dowolnego $\theta\in l^2$, dla dowolnego $B>B_0$ i dla estymatora liniowego $\theta^*$ z filtrem wybranym zgodnie z (\ref{estimator}) zachodzi
\begin{displaymath}
\mathbb{E}_{\theta}\norm{\theta^*-\theta}^2\leq (1+\gamma_1B^{-1})\min_{\lambda\in \Lambda}\mathcal{R}(\hat{\theta},\theta)+\gamma_2B\epsilon^2L_{\Lambda}\omega(B^2L_{\Lambda}),
\end{displaymath}
gdzie stałe $B_0>0,\gamma_1>0,\gamma_2>0$ zależą tylko od stałej $C_1$, wyrażenie $\min_{\lambda\in \Lambda}\mathcal{R}(\hat{\theta},\theta)$ rozumiane jest jako minimum wzięte po wszystkich estymatorach $\hat{\theta}$ postaci $\lambda X,\ \lambda\in \Lambda$, a funkcja $\omega(x)$ jest postaci
\begin{displaymath}
\omega(x)=\max_{\lambda\in \Lambda}\sup_k\left[\sigma_k^2\lambda_k^2\pmb{1}\left(\sum_{n=1}^{\infty}\sigma_n^2\lambda_n^2\leq x \sup_k\sigma_k^2\lambda_k^2\right)\right],\ x>0.
\end{displaymath}
\end{tw}
\begin{tw}\label{glowny2}
Niech spełnione będą założenia \ref{ass1}-- \ref{ass5}. Wtedy istnieją stałe $\gamma_3>0,\gamma_4>0$ zależące tylko od $C_1$, takie że dla dowolnego $\theta\in l^2$ i dla estymatora liniowego $\theta^*$ z filtrem wybranym zgodnie z (\ref{estimator}) zachodzi
\begin{displaymath}
\mathbb{E}_{\theta}\norm{\theta^*-\theta}^2\leq (1+\gamma_3\rho\sqrt{L_{\Lambda}})\min_{\lambda\in \Lambda}\mathcal{R}(\hat{\theta},\theta),
\end{displaymath}
o ile $\rho\sqrt{L_{\Lambda}}<\gamma_4$, a minimum rozumiane jest jak w poprzednim twierdzeniu.
\end{tw}
Zanim przejdziemy do dowodu powyższych twierdzeń podamy wniosek z twierdzenia \ref{glowny2}, który pozwoli wnioskować o asymptotycznej dokładności podanych nierówności wyroczni postaci (\ref{aoracle}).
\begin{wn}
Niech spełnione będą założenia \ref{ass1}-- \ref{ass5}. Ponadto niech zachodzi \\$\lim_{\epsilon\to 0}\rho^2\ln(NS)=0$. Wtedy istnieją stałe $\mathbb{C}_2>0,\mathbb{C}_3>0$ zależące tylko od stałej $C_1$ takie, że dla $\rho^2\ln(NS)<\mathbb{C}_2$ i dla dowolnego $\theta\in l^2$ zachodzi
\begin{displaymath}
\mathbb{E}_{\theta}\norm{\hat{\theta}-\theta}^2\leq \left(1+\mathbb{C}_3\rho\sqrt{ln(NS)}\right)\min_{\lambda\in \Lambda}\mathcal{R}(\hat{\theta},\theta),
\end{displaymath}
gdzie estymator $\tilde{\theta}$ i minimum rozumiane są jak poprzednio.
\end{wn}
\begin{proof}
Skoro zachodzi $\lim_{\epsilon\to 0}\rho^2\ln(NS)=0$, to ciąg ten jest ograniczony przez pewną stałą zależną tylko od $C_1$. Z twierdzenia $5$ mamy, że stała $\gamma_3$ zależy tylko od stałej $C_1$. Wystarczy zatem pokazać, że $L_{\Lambda}<C\ln(NS)$. 
\begin{displaymath}
L_{\Lambda}=\ln(NS)+\rho^2\ln^2(MS)\leq \ln(NS)+\rho^2\ln^2(NS)\leq (1+C_2)\ln(NS),
\end{displaymath}
gdyż $M\leq N$.
\end{proof}
$\ $\\
Zatem warunek $\lim_{\epsilon\to 0}\rho^2\ln(NS)=0$ jest warunkiem wystarczającym do otrzymania dokładnych asymptotycznie nierówności wyroczni postaci (\ref{aoracle}).\\
\indent Zanim przejdziemy do dowodu twierdzeń \ref{glowny1} i \ref{glowny2} podamy trzy lematy z których będziemy korzystać, a których dowody znajdują się w rozdziale \ref{lematy}.
\begin{lm}\label{lem1}
Niech $\{\xi_i\}_{i=1}^{\infty}$ będzie ciągiem niezależnych zmiennych losowych o tym samym standardowym rozkładzie normalnym i niech $v=\{v_i\}_{i=1}^{\infty}\in l^2$ będzie losowym ciągiem takim, że przyjmuje on wartości w skończonym zbiorze $V\subset l^2$ o liczności $N>1$. Wtedy dla dowolnego $K\geq 1$ zachodzi
\begin{displaymath}
\mathbb{E}\left|\sum_{k=1}^{\infty}v_k\xi_k\right|\leq \sqrt{2\ln (NK)}\left(\mathbb{E}||v||+\sqrt{2\mathbb{E}||v||^2/K}\right).
\end{displaymath}
\end{lm}

\begin{lm}\label{lem2}
Niech $\{\xi_i\}_{i=1}^{\infty}$ będzie ciągiem niezależnych zmiennych losowych o tym samym standardowym rozkładzie normalnym i niech $v=\{v_i\}_{i=1}^{\infty}\in l^2$ będzie losowym ciągiem takim, że przyjmuje on wartości w skończonym zbiorze $V\subset l^2$ o liczności $N>1$. Niech ponadto $v\neq 0$ dla każdego $v\in V$. Oznaczmy przez $m(v)=\sup_i |v_i|/||v||$, $m_V=\max_{v\in V}m(v)$ oraz 
\begin{displaymath}
M(q)=\sum_{v\in V}\exp (-q/m(v)),\ q>0.
\end{displaymath}
Wtedy istnieje stała $D$ zależna tylko od $q$, taka, że dla dowolnego $K\geq 1$ zachodzi
\begin{displaymath}
\mathbb{E}\left|\sum_{k=1}^{\infty}v_k(\xi_k^2-1)\right|\leq D\left(\sqrt{\ln (NK)}+m_V\ln (M(q)K)\right)\left(\mathbb{E}||v||+\sqrt{\mathbb{E}||v||^2/K}\right).
\end{displaymath}
\end{lm}

\begin{lm}\label{lem3}
Niech $\hat{\theta}_i=\hat{\lambda}_i(X)X_i$ będzie estymatorem liniowym z wagami z przedziału $[-1,1]$ przyjmującymi wartości w zbiorze $\Lambda$. Oznaczmy  
\begin{displaymath}
\Delta^{\epsilon}[\lambda]=\epsilon^2L_{\Lambda}\sup_i\sigma_i^2\lambda_i^2,\ \lambda\in \Lambda.
\end{displaymath}
Wtedy istnieje absolutna stała $C>0$ taka, że dla dowolnego $B>0$ zachodzi
\begin{displaymath}
\mathbb{E}_{\theta}\norm{\hat{\theta}-\theta}^2\leq (1+4B^{-1})\mathbb{E}_{\theta}\mathcal{R}(\hat{\theta},\theta)+CB\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda (X)].
\end{displaymath}
\end{lm}
Różnica w stałej $1+4B^{-1}$ w porównaniu do pracy \cite{cavalier1} jest wynikiem innego doboru stałych w dowodzie twierdzeń \ref{glowny1} i \ref{glowny2} z uwagi na niewłaściwe dobraną stałą w pracy \cite{cavalier1} w nierówności (\ref{blad}), gdzie z prawej strony stała przyjmowała wartość $2$ zamiast $4$, jednak w takim przypadku, z uwagi na dopuszczenie ujemnych wartości dla filtrów $\lambda$, nierówność ta nie byłaby prawdziwa. Różnica ta nie ma wpływu na ostateczny wydźwięk tych twierdzeń i wnioski z nich.\\
\indent Przejdziemy teraz do dowodu twierdzenia \ref{glowny1}, a później do dowodu twierdzenia \ref{glowny2}.
\begin{proof}[Dowód twierdzenia \ref{glowny1}]
Niech $\lambda^{\cdot},\ \lambda^*\in \Lambda$. Wtedy korzystając ze wzoru na różnicę kwadratów i szacowania $(a+b)^2\leq 2(a^2+b^2)$, można pokazać, że
\begin{equation}\label{blad}
[(1-\lambda_i^{\cdot})^2-(1-\lambda_i^*)^2]^2\leq 4[(1-\lambda_i^{\cdot})^2+(1-\lambda_i^*)^2][\lambda_i^{\cdot 2}+\lambda_i^{*2}].
\end{equation}
Niech teraz $\tilde{\lambda}\in \Lambda$ będzie takim filtrem, że związany z nim estymator jest wyrocznią, czyli $\tilde{\theta}=\arg \min_{\lambda\in \Lambda}\mathcal{R}(\hat{\theta},\theta)$, natomiast przez $\lambda^*$ oznaczmy filtr definiowany przez (\ref{estimator}) i konsekwentnie związany z nim estymator przez $\theta^*$. W rozpatrywanym modelu (\ref{ssm}) $x_i=\theta_i+\epsilon\sigma_i\xi_i$, zatem $x_i^2=\theta_i^2+\epsilon^2\sigma_i^2\xi_i^2+2\epsilon\sigma_i\theta_i\xi_i$.Wstawiając to wyrażenie do wzoru na nieobciążony estymator ryzyka (\ref{ure}) mamy
\begin{displaymath}
\begin{split}
U[\lambda^*,X]&=\sum_{i=1}^{\infty}(\lambda_i^{*2}-2\lambda_i^*)(x_i^2-\epsilon^2\sigma_i^2)+\epsilon^2\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^{*2}\\
&=\sum_{i=1}^{\infty}(\lambda_i^{*2}-2\lambda_i^*)(\theta_i^2+\epsilon^2\sigma_i^2\xi_i^2+2\epsilon\sigma_i\theta_i\xi_i-\epsilon^2\sigma_i^2)+\epsilon^2\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^{*2}\\
&=2\epsilon\sum_{i=1}^{\infty}(\lambda_i^{*2}-2\lambda_i^*)\sigma_i\theta_i\xi_i+\sum_{i=1}^{\infty}(\lambda_i^{*2}-2\lambda_i^*)(\theta_i^2+\epsilon^2\sigma_i^2\xi_i^2-\epsilon^2\sigma_i^2)+\epsilon^2\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^{*2}\\
&=2\epsilon\sum_{i=1}^{\infty}(\lambda_i^{*2}-2\lambda_i^*)\sigma_i\theta_i\xi_i+\epsilon^2\sum_{i=1}^{\infty}(\lambda_i^{*2}-2\lambda_i^*)\sigma_i^2(\xi_i^2-1)-\sum_{i=1}^{\infty}\theta_i^2\\
&\hspace{4mm}+\left[\sum_{i=1}^{\infty}(\lambda_i^{*2}-2\lambda_i^*)\theta_i^2+\epsilon^2\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^{*2}+\sum_{i=1}^{\infty}\theta_i^2\right]=2\epsilon\sum_{i=1}^{\infty}(1-\lambda_i^*)^2\sigma_i\theta_i\xi_i\\
&\hspace{4mm}-2\epsilon\sum_{i=1}^{\infty}\sigma_i\theta_i\xi_i-\sum_{i=1}^{\infty}\theta_i^2+\epsilon^2\sum_{i=1}^{\infty}(\lambda_i^{*2}-2\lambda_i^*)\sigma_i^2(\xi_i^2-1)+\mathcal{R}(\theta^*,\theta).
\end{split}
\end{displaymath}
Obliczając wartość oczekiwaną powyższego wyrażenia dostajemy
\begin{equation}\label{ryzyko}
\mathbb{E}_{\theta}U[\lambda^*,X]=\mathbb{E}_{\theta}\mathcal{R}(\theta^*,\theta)-\sum_{i=1}^{\infty}\theta_i^2+2\epsilon\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(1-\lambda_i^*)^2\sigma_i\theta_i\xi_i+\epsilon^2\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(\lambda_i^{*2}-2\lambda_i^*)\sigma_i^2(\xi_i^2-1).
\end{equation}

Znajdziemy teraz dolne oszacowania na dwa ostatnie składniki powyższego wyrażenia. Zauważmy, że 
\begin{displaymath}
\begin{split}
\epsilon\mathbb{E}_{\theta}\sum_{i=1}^{\infty}&(1-\lambda_i^*)^2\sigma_i\theta_i\xi_i=\epsilon\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(1-\lambda_i^*)^2\sigma_i\theta_i\xi_i-0\\
&=\epsilon\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(1-\lambda_i^*)^2\sigma_i\theta_i\xi_i-\epsilon\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(1-\tilde{\lambda_i})^2\sigma_i\theta_i\xi_i\\
&=\epsilon\mathbb{E}_{\theta}\sum_{i=1}^{\infty}[(1-\lambda_i^*)^2-(1-\tilde{\lambda_i})^2]\sigma_i\theta_i\xi_i\\
&\geq -\epsilon\mathbb{E}_{\theta}\left|\sum_{i=1}^{\infty}[(1-\lambda_i^*)^2-(1-\tilde{\lambda_i})^2]\sigma_i\theta_i\xi_i\right|.
\end{split}
\end{displaymath}
Korzystając z lematu \ref{lem1} z $K=S$ i $v_i=[(1-\lambda_i^*)^2-(1-\tilde{\lambda_i})^2]\sigma_i\theta_i$ dostajemy
\begin{displaymath}
\begin{split}
-\epsilon\mathbb{E}_{\theta}&\left|\sum_{i=1}^{\infty}[(1-\lambda_i^*)^2-(1-\tilde{\lambda_i})^2]\sigma_i\theta_i\xi_i\right|\\
&\geq -\epsilon\sqrt{2\ln (NS)}\mathbb{E}_{\theta}\left(\sum_{i=1}^{\infty}[(1-\lambda_i^*)^2-(1-\tilde{\lambda_i})^2]^2\sigma_i^2\theta_i^2\right)^{1/2}\\
&\hspace{4mm}-2\epsilon\sqrt{\ln (NS)/S}\left(\mathbb{E}_{\theta}\sum_{i=1}^{\infty}[(1-\lambda_i^*)^2-(1-\tilde{\lambda_i})^2]^2\sigma_i^2\theta_i^2\right)^{1/2}.
\end{split}
\end{displaymath}
Następnie korzystając z nierówności wskazanej na początku dowodu dostajemy dolne oszacowanie postaci
\begin{displaymath}
\begin{split}
&-2\epsilon\sqrt{2\ln (NS)}\mathbb{E}_{\theta}\left(\sum_{i=1}^{\infty}[(1-\lambda_i^*)^2+(1-\tilde{\lambda_i})^2](\lambda_i^{*2}+\tilde{\lambda_i^2})\theta_i^2\sigma_i^2\right)^{1/2}\\
&-4\epsilon\sqrt{\ln (NS)/S}\left(\mathbb{E}_{\theta}\sum_{i=1}^{\infty}[(1-\lambda_i^*)^2+(1-\tilde{\lambda_i})^2](\lambda_i^{*2}+\tilde{\lambda_i^2})\theta_i^2\sigma_i^2\right)^{1/2}.
\end{split}
\end{displaymath}
W kolejnym kroku będziemy korzystać z nierówności $2ab\leq B^{-1}a^2+Bb^2$ zachodzącej dla dowolnego $B>0$ i najpierw oszacujemy pierwszy składnik powyższego wyrażenia.
\begin{displaymath}
\begin{split}
2\epsilon&\sqrt{2\ln (NS)}\mathbb{E}_{\theta}\left(\sum_{i=1}^{\infty}[(1-\lambda_i^*)^2+(1-\tilde{\lambda_i})^2](\lambda_i^{*2}+\tilde{\lambda_i^2})\theta_i^2\sigma_i^2\right)^{1/2}\\
&\leq 2\epsilon\sqrt{2\ln (NS)}\mathbb{E}_{\theta}\left\{\sup_i\left\{(\lambda_i^{*2}+\tilde{\lambda_i^2})\sigma_i^2\right\} \sum_{i=1}^{\infty}[(1-\lambda_i^*)^2+(1-\tilde{\lambda_i})^2]\theta_i^2\right)^{1/2}\\
&=\mathbb{E}_{\theta}2\epsilon\sqrt{2\ln (NS)\sup_i\left\{(\lambda_i^{*2}+\tilde{\lambda_i^2})\sigma_i^2\right\}}\left(\sum_{i=1}^{\infty}[(1-\lambda_i^*)^2+(1-\tilde{\lambda_i})^2]\theta_i^2\right)^{1/2}\\
&\leq 2B\epsilon^2 \ln (NS)\mathbb{E}_{\theta}\sup_i\left\{(\lambda_i^{*2}+\tilde{\lambda_i^2})\sigma_i^2\right\}+B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}[(1-\lambda_i^*)^2+(1-\tilde{\lambda_i})^2]\theta_i^2\\
&\leq 2B\epsilon^2 \ln (NS)\mathbb{E}_{\theta}\left(\sup_i\lambda_i^{*2}\sigma_i^2+\sup_i\tilde{\lambda_i^2}\sigma_i^2\right)+B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}[(1-\lambda_i^*)^2+(1-\tilde{\lambda_i})^2]\theta_i^2.
\end{split}
\end{displaymath}
Analogicznie postępując z drugim wyrażeniem dostajemy
\begin{displaymath}
\begin{split}
4\epsilon&\sqrt{\ln (NS)/S}\left(\mathbb{E}_{\theta}\sum_{i=1}^{\infty}[(1-\lambda_i^*)^2+(1-\tilde{\lambda_i})^2](\lambda_i^{*2}+\tilde{\lambda_i^2})\theta_i^2\sigma_i^2\right)^{1/2}\\
&\leq 4\epsilon\sqrt{\ln (NS)/S}\left(\mathbb{E}_{\theta}\sup_i\left\{(\lambda_i^{*2}+\tilde{\lambda_i^2})\sigma_i^2\right\}\sum_{i=1}^{\infty}[(1-\lambda_i^*)^2+(1-\tilde{\lambda_i})^2]\theta_i^2\right)^{1/2}\\
&\leq 2\cdot 2\epsilon\sqrt{\ln (NS)/S} \left(\max_{\lambda\in \Lambda}\sup_i\left\{(\lambda_i^{2}+\tilde{\lambda_i^2})\sigma_i^2\right\}\right)^{1/2}\left(\mathbb{E}_{\theta}\sum_{i=1}^{\infty}[(1-\lambda_i^*)^2+(1-\tilde{\lambda_i})^2]\theta_i^2\right)^{1/2}\\
&\leq 4B\epsilon^2\ln (NS)/S\max_{\lambda\in \Lambda}\sup_i\left\{(\lambda_i^{2}+\tilde{\lambda_i^2})\sigma_i^2\right\}+B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}[(1-\lambda_i^*)^2+(1-\tilde{\lambda_i})^2]\theta_i^2.
\end{split}
\end{displaymath}
Zauważmy, że skoro
\begin{displaymath}
S=\frac{\max_{\lambda\in\Lambda}\sup_i\sigma_i^2\lambda_i^2}{\min_{\lambda\in\Lambda}\sup_i\sigma_i^2\lambda_i^2}
\end{displaymath}
to wyrażenie $\max_{\lambda\in \Lambda}\sup_i\left\{(\lambda_i^{2}+\tilde{\lambda_i^2})\sigma_i^2\right\}/S$ można oszacować przez
\begin{displaymath}
\begin{split}
\max_{\lambda\in \Lambda}&\sup_i\left\{(\lambda_i^{2}+\tilde{\lambda_i^2})\sigma_i^2\right\}/S=\frac{\min_{\lambda\in\Lambda}\sup_i\sigma_i^2\lambda_i^2}{\max_{\lambda\in\Lambda}\sup_i\sigma_i^2\lambda_i^2}\max_{\lambda\in \Lambda}\sup_i\left\{(\lambda_i^{2}+\tilde{\lambda_i^2})\sigma_i^2\right\}\\
&\leq \frac{\min_{\lambda\in\Lambda}\sup_i\sigma_i^2\lambda_i^2\cdot \max_{\lambda\in\Lambda}\sup_i\sigma_i^2\lambda_i^2}{\max_{\lambda\in\Lambda}\sup_i\sigma_i^2\lambda_i^2}+\frac{\min_{\lambda\in\Lambda}\sup_i\sigma_i^2\lambda_i^2\cdot \sup_i\tilde{\lambda_i^2}\sigma_i^2}{\max_{\lambda\in\Lambda}\sup_i\sigma_i^2\lambda_i^2}\\
&=\min_{\lambda\in\Lambda}\sup_i\sigma_i^2\lambda_i^2+\frac{1}{S}\sup_i\tilde{\lambda_i^2}\sigma_i^2\leq\sup_i\lambda_i^{*2}\sigma_i^2+\sup_i\tilde{\lambda_i^2}\sigma_i^2,
\end{split}
\end{displaymath}
a więc także przez wartość oczekiwaną ostatniego wyrażenia. Zatem dostajemy oszacowanie postaci
\begin{displaymath}
\begin{split}
4\epsilon&\sqrt{\ln (NS)/S}\left(\mathbb{E}_{\theta}\sum_{i=1}^{\infty}[(1-\lambda_i^*)^2+(1-\tilde{\lambda_i})^2](\lambda_i^{*2}+\tilde{\lambda_i^2})\theta_i^2\sigma_i^2\right)^{1/2}\\
&\leq 4B\epsilon^2 \ln (NS)\mathbb{E}_{\theta}\left(\sup_i\lambda_i^{*2}\sigma_i^2+\sup_i\tilde{\lambda_i^2}\sigma_i^2\right)+B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}[(1-\lambda_i^*)^2+(1-\tilde{\lambda_i})^2]\theta_i^2,
\end{split}
\end{displaymath}
czyli takie samo z dokładnością do stałych jak dla czynnika pierwszego. Zatem możemy napisać, że 
\begin{displaymath}
\begin{split}
\epsilon\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(1-\lambda_i^*)^2&\sigma_i\theta_i\xi_i
\geq -6B\epsilon^2 \ln (NS)\mathbb{E}_{\theta}\left(\sup_i\lambda_i^{*2}\sigma_i^2+\sup_i\tilde{\lambda_i^2}\sigma_i^2\right)\\&-2B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}[(1-\lambda_i^*)^2+(1-\tilde{\lambda_i})^2]\theta_i^2
\end{split}
\end{displaymath}
Zachodzi również
\begin{displaymath}
\sum_{i=1}^{\infty}(1-\lambda_i^{*})^2\theta_i^2\leq \mathcal{R}(\theta^*,\theta)\ \textrm{oraz} \ln (NS)\leq L_{\Lambda}.
\end{displaymath}
Przy oznaczeniu $\Delta^{\epsilon}[\lambda]=\epsilon^2L_{\Lambda}\sup_i\sigma_i^2\lambda_i^2$ jak w lemacie \ref{lem3} prowadzi to do oszacowania postaci
\begin{equation}
\begin{split}\label{szacowanie1}
-6B\epsilon^2 &\ln (NS)\mathbb{E}_{\theta}\left(\sup_i\lambda_i^{*2}\sigma_i^2+\sup_i\tilde{\lambda_i^2}\sigma_i^2\right)-2B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}[(1-\lambda_i^*)^2+(1-\tilde{\lambda_i})^2]\theta_i^2\\
&\geq -6B\epsilon^2 \ln (NS)\mathbb{E}_{\theta}\left(\sup_i\lambda_i^{*2}\sigma_i^2+\sup_i\tilde{\lambda_i^2}\sigma_i^2\right)-2B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(1-\lambda_i^*)^2\theta_i^2\\
&\hspace{4mm}-2B^{-1}\sum_{i=1}^{\infty}(1-\tilde{\lambda_i})^2\theta_i^2\geq -2B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(1-\lambda_i^*)^2\theta_i^2-2B^{-1}\mathcal{R}(\tilde{\theta},\theta)\\
&\hspace{4mm}-6B\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]-6B\mathbb{E}_{\theta}\Delta^{\epsilon}[\tilde{\lambda}].
\end{split}
\end{equation}

Znajdziemy teraz oszacowanie dla składnika $\epsilon^2\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(\lambda_i^{*2}-2\lambda_i^*)\sigma_i^2(\xi_i^2-1)$. Zauważmy na początek, że z uwagi na to, że $|\lambda_i|\leq 1$ dla dowolnego $\lambda\in \Lambda$ z założenia \ref{ass2}, zachodzi $\lambda_i^2\leq (\lambda_i^2-2\lambda_i)^2\leq 9\lambda_i^2$. Do oszacowania analizowanego wyrażenia posłużymy się lematem \ref{lem2} z $K=S$, $q=3$ i $v_i=(\lambda_i^{*2}-2\lambda_i^*)\sigma_i^2$. Zatem
\begin{displaymath}
\epsilon^2\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(\lambda_i^{*2}-2\lambda_i^*)\sigma_i^2(\xi_i^2-1)\leq \epsilon^2\mathbb{E}_{\theta}\left|\sum_{i=1}^{\infty}(\lambda_i^{*2}-2\lambda_i^*)\sigma_i^2(\xi_i^2-1)\right|
\end{displaymath}
\begin{displaymath}
\leq \epsilon^2D\left(\sqrt{\ln (NS)}+m_V\ln (SM(3))\right)\left(\mathbb{E}_{\theta}||v||+\sqrt{\mathbb{E}_{\theta}||v||^2/S}\right).
\end{displaymath}
Oszacujemy teraz niektóre z elementów pojawiających się powyżej:
\begin{displaymath}
m(v)=\sup_i|v_i|/||v||=\frac{\sup_i|\lambda_i^{*2}-2\lambda_i^*|\sigma_i^2}{\sqrt{\sum_{i=1}^{\infty}(\lambda_i^{*2}-2\lambda_i^*)^2\sigma_i^4}}\leq \frac{3\sup_i|\lambda_i|\sigma_i^2}{\sqrt{\sum_{i=1}^{\infty}\lambda_i^{*4}\sigma_i^4}}\leq 3\rho (\lambda),
\end{displaymath}
\begin{displaymath}
M(3)=\sum_{v}\exp (-3/m(v))=\sum_{\lambda\in \Lambda}\exp (-3/m(v))\leq \sum_{\lambda\in \Lambda}\exp (-1/\rho(\lambda))=M,
\end{displaymath}
\begin{displaymath}
m_V=\max_{v}m(v)\leq 3\rho=3\max_{\lambda\in \Lambda}\rho(\lambda).
\end{displaymath}
Stąd dostajemy, że 
\begin{displaymath}
\left(\sqrt{\ln (NS)}+m_V\ln (SM(3))\right)^2\leq \left(\sqrt{\ln (NS)}+3\rho\ln (MS)\right)^2 
\end{displaymath}
\begin{displaymath}
\leq 2\ln (NS)+6\rho^2\ln^2 (MS)\leq 6(\ln (NS)+\rho^2\ln^2 (MS)),
\end{displaymath}
a stąd
\begin{displaymath}
\sqrt{\ln (NS)}+m_V\ln (SM(3))\leq C\sqrt{L_{\Lambda}},
\end{displaymath}
gdzie $C$ jest pewną stałą. W dalszym ciągu rozważań wszystkie stałe generyczne zależne tylko od $C_1$ oznaczać będziemy przez $C$. Pozwala nam to oszacować badane wyrażenie od dołu przez
\begin{displaymath}
\begin{split}
\epsilon^2\mathbb{E}_{\theta}&\sum_{i=1}^{\infty}(\lambda_i^{*2}-2\lambda_i^*)\sigma_i^2(\xi_i^2-1)\\
&\geq  -\epsilon^2D\left(\sqrt{\ln (NS)}+m_V\ln (SM(3))\right)\left(\mathbb{E}_{\theta}||v||+\sqrt{\mathbb{E}_{\theta}||v||^2/S}\right)\\
&\geq -\epsilon^2C\sqrt{L_{\Lambda}}\mathbb{E}_{\theta}\left(\sum_{i=1}^{\infty}(\lambda_i^{*2}-2\lambda_i^*)^2\sigma_i^4\right)^{1/2}-\epsilon^2C\sqrt{L_{\Lambda}}S^{-1/2}\left(\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(\lambda_i^{*2}-2\lambda_i^*)^2\sigma_i^4\right)^{1/2}\\
&\geq -\epsilon^23C\sqrt{L_{\Lambda}}\mathbb{E}_{\theta}\left(\sum_{i=1}^{\infty}\lambda_i^{*2}\sigma_i^4\right)^{1/2}-\epsilon^23C\sqrt{L_{\Lambda}}S^{-1/2}\left(\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\lambda_i^{*2}\sigma_i^4\right)^{1/2}\\
&\geq -\epsilon^2C\sqrt{C_1}\sqrt{L_{\Lambda}}\mathbb{E}_{\theta}\left(\sum_{i=1}^{\infty}\lambda_i^{*4}\sigma_i^4\right)^{1/2}-\epsilon^2C\sqrt{C_1}\sqrt{L_{\Lambda}}S^{-1/2}\left(\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\lambda_i^{*4}\sigma_i^4\right)^{1/2},
\end{split}
\end{displaymath}
z uwagi na to, że $(\lambda_i^{*2}-2\lambda_i^*)^2\leq 9\lambda_i^{*2}$ oraz założenie \ref{ass5}.\\
\indent W dalszej części skorzystamy z faktu, że $\forall_{\omega\in \Omega}\ \min_{\lambda\in \Lambda}\sup_i \lambda_i^2\sigma_i^2\leq \sup_i\lambda_i^{*2}\sigma_i^2=\sup_i\lambda_i^{*2}(\omega)\sigma_i^2$, a stąd $\min_{\lambda\in \Lambda}\sup_i \lambda_i^2\sigma_i^2\leq \mathbb{E}_{\theta}\sup_i\lambda_i^{*2}\sigma_i^2$. Analogicznie jak poprzednio
\begin{displaymath}
\begin{split}
S^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\sigma_i^4\lambda_i^{*4}&\leq \frac{\min_{\lambda\in \Lambda}\sup_i \lambda_i^2\sigma_i^2}{\max_{\lambda\in \Lambda}\sup_i \lambda_i^2\sigma_i^2}\mathbb{E}_{\theta}\sup_i\sigma_i^2\lambda_i^{*2}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^{*2}\\
&\leq \frac{\min_{\lambda\in \Lambda}\sup_i \lambda_i^2\sigma_i^2}{\max_{\lambda\in \Lambda}\sup_i \lambda_i^2\sigma_i^2}\max_{\lambda\in \Lambda}\sup_i \lambda_i^2\sigma_i^2\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^{*2}\\
&\leq \mathbb{E}_{\theta}\sup_i\sigma_i^2\lambda_i^{*2}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^{*2}.
\end{split}
\end{displaymath}
Podobnie dla drugiego wyrażenia
\begin{displaymath}
\mathbb{E}_{\theta}\left(\sum_{i=1}^{\infty}\sigma_i^4\lambda_i^{*4}\right)^{1/2}\leq \mathbb{E}_{\theta}\left(\sup_i\sigma_i^2\lambda_i^{*2}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^{*2}\right)^{1/2}.
\end{displaymath}
Ponownie korzystając z nierówności $2ab\leq B^{-1}a^2+Bb^2$ dostajemy
\begin{displaymath}
C\sqrt{L_{\Lambda}}\mathbb{E}_{\theta}\left(\sup_i\sigma_i^2\lambda_i^{*2}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^{*2}\right)^{1/2}=\mathbb{E}_{\theta}\left(2C\sqrt{L_{\Lambda}\sup_i\sigma_i^2\lambda_i^{*2}}\left(2\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^{*2}\right)^{1/2}\right)
\end{displaymath}
\begin{displaymath}
\leq B\mathbb{E}_{\theta}C^2L_{\Lambda}\sup_i\sigma_i^2\lambda_i^{*2}+2B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^{*2}.
\end{displaymath}
Podobnie dla drugiego wyrażenia
\begin{displaymath}
C\sqrt{L_{\Lambda}}\left(\mathbb{E}_{\theta}\sup_i\sigma_i^2\lambda_i^{*2}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^{*2}\right)^{1/2}=2\left(\mathbb{E}_{\theta}CL_{\Lambda}\sup_i\sigma_i^2\lambda_i^{*2}\right)^{1/2}\left(2\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^{*2}\right)^{1/2}
\end{displaymath}
\begin{displaymath}
\leq B\mathbb{E}_{\theta}CL_{\Lambda}\sup_i\sigma_i^2\lambda_i^{*2}+2B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^{*2}.
\end{displaymath}
Łącząc oba oszacowania oraz wykorzystując oznaczenie $\Delta^{\epsilon}[\lambda]=\epsilon^2L_{\Lambda}\sup_i\sigma_i^2\lambda_i^2$ dostajemy
\begin{equation}\label{szacowanie2}
\begin{split}
\epsilon\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(\lambda_i^{*2}-2\lambda_i^*)\sigma_i^2(\xi_i^2-1)
&\geq C\epsilon^2 B\mathbb{E}_{\theta}L_{\Lambda}\sup_i\sigma_i^2\lambda_i^{*2}-4\epsilon^2B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^{*2}\\
&=-CB\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]-4\epsilon^2B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^{*2}.
\end{split}
\end{equation}
Łącząc wyrażenia (\ref{szacowanie1}) oraz (\ref{szacowanie2}) dostajemy
\begin{equation}\label{szacowanie3}
\begin{split}
2\epsilon&\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(1-\lambda_i^*)^2\sigma_i\theta_i\xi_i+\epsilon^2\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(\lambda_i^{*2}-2\lambda_i^*)\sigma_i^2(\xi_i^2-1)\geq -4B^{-1}\mathcal{R}(\tilde{\theta},\theta)\\
&\hspace{4mm}-4B^{-1}\mathbb{E}_{\theta}\left[\sum_{i=1}^{\infty}(1-\lambda_i^*)^2\theta_i^2+\epsilon^2\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^{*2}\right]-12B\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]-12B\Delta^{\epsilon}[\tilde{\lambda}]\\
&=-4B^{-1}\mathbb{E}_{\theta}\mathcal{R}(\theta^*,\theta)-4B^{-1}\mathcal{R}(\tilde{\theta},\theta)-CB\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]-CB\Delta^{\epsilon}[\tilde{\lambda}].
\end{split}
\end{equation}
Możemy teraz przejść do ostatecznego szacowania ryzyka badanego estymatora. Zgodnie z (\ref{ryzyko}) mamy wykorzystując oszacowania (\ref{szacowanie1}) i (\ref{szacowanie2}) (bądź od razu (\ref{szacowanie3}))
\begin{displaymath}
\begin{split}
\mathbb{E}_{\theta}U&[\lambda^*,X]=\mathbb{E}_{\theta}\mathcal{R}(\theta^*,\theta)-\sum_{i=1}^{\infty}\theta_i^2+\epsilon^2\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(\lambda_i^{*2}-2\lambda_i^*)\sigma_i^2(\xi_i^2-1)\\
&+2\epsilon\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(1-\lambda_i^*)^2\sigma_i\theta_i\xi_i \geq \mathbb{E}_{\theta}\mathcal{R}(\theta^*,\theta)-\sum_{i=1}^{\infty}\theta_i^2-4B^{-1}\mathbb{E}_{\theta}\mathcal{R}(\theta^*,\theta)\\&-4B^{-1}\mathcal{R}(\tilde{\theta},\theta)-CB\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]-CB\Delta^{\epsilon}[\tilde{\lambda}].
\end{split}
\end{displaymath}
Zatem zachodzi
\begin{displaymath}
(1-4B^{-1})\mathbb{E}_{\theta}\mathcal{R}(\theta^*,\theta)\leq \mathbb{E}_{\theta}U[\lambda^*,X]+\sum_{i=1}^{\infty}\theta_i^2+4B^{-1}\mathcal{R}(\tilde{\theta},\theta)+CB\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]+CB\Delta^{\epsilon}[\tilde{\lambda}].
\end{displaymath}
Jednak, jako że filtr $\lambda^*$ był zdefiniowany w (\ref{estimator}) jako argument minimalizujący nieobciążony estymator ryzyka (\ref{ure}), musi zachodzić
\begin{displaymath}
\mathbb{E}_{\theta}U[\lambda^*,X]\leq \mathbb{E}_{\theta}U[\tilde{\lambda},X]=\mathcal{R}(\tilde{\theta},\theta)-\sum_{i=1}^{\infty}\theta_i^2.
\end{displaymath}
Dochodzimy zatem do oszacowania postaci 
\begin{equation}\label{szacowanie4}
(1-4B^{-1})\mathbb{E}_{\theta}\mathcal{R}(\theta^*,\theta)\leq (1+4B^{-1})\mathcal{R}(\tilde{\theta},\theta)+CB\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]+CB\Delta^{\epsilon}[\tilde{\lambda}].
\end{equation}
Zauważmy, że dla dowolnego $x>0$ zachodzi następujące oszacowanie
\begin{displaymath}
\begin{split}
\sup_i\sigma_i^2\lambda_i^2&=\sup_i\sigma_i^2\lambda_i^2\pmb{1}\left\{x\sup_i\sigma_i^2\lambda_i^2<\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^2\right\}+\sup_i\sigma_i^2\lambda_i^2\pmb{1}\left\{x\sup_i\sigma_i^2\lambda_i^2\geq \sum_{i=1}^{\infty}\sigma_i^2\lambda_i^2\right\}\\
&\leq \frac{1}{x}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^2+\max_{\lambda\in \Lambda}\sup_i\sigma_i^2\lambda_i^2\pmb{1}\left\{x\sup_i\sigma_i^2\lambda_i^2\geq \sum_{i=1}^{\infty}\sigma_i^2\lambda_i^2\right\}\\
&\leq \frac{1}{x}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^2+\omega (x)\leq \frac{1}{x\epsilon^2}\mathcal{R}(\hat{\theta},\theta)+\omega (x)\ \forall_{\lambda\in \Lambda}.
\end{split}
\end{displaymath}
Stąd dostajemy oszacowanie na składnik
\begin{displaymath}
\Delta^{\epsilon}[\lambda]=\epsilon^2 L_{\Lambda}\sup_i\sigma_i^2\lambda_i^2\leq \frac{L_{\Lambda}}{x}\mathcal{R}(\hat{\theta},\theta)+\epsilon^2L_{\Lambda}\omega (x).
\end{displaymath}
Wykorzystamy teraz powyższe nierówności dla nierówności (\ref{szacowanie4}).
\begin{displaymath}
\begin{split}
(1-4B^{-1})\mathbb{E}_{\theta}&\mathcal{R}(\theta^*,\theta)\leq (1+4B^{-1})\mathcal{R}(\tilde{\theta},\theta)+CB\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]+CB\Delta^{\epsilon}[\tilde{\lambda}]\\
&\leq CB\frac{L_{\Lambda}}{x}\mathbb{E}_{\theta}\mathcal{R}(\theta^*,\theta)+CB\epsilon^2L_{\Lambda}\omega (x)
+CB\epsilon^2L_{\Lambda}\omega (x)\\
&\hspace{4mm}+CB\frac{L_{\Lambda}}{x}\mathcal{R}(\tilde{\theta},\theta)+(1+4B^{-1})\mathcal{R}(\tilde{\theta},\theta)
=CB\frac{L_{\Lambda}}{x}\mathbb{E}_{\theta}\mathcal{R}(\theta^*,\theta)\\
&\hspace{4mm}+CB\epsilon^2L_{\Lambda}\omega (x)+\left(CB\frac{L_{\Lambda}}{x}+1+4B^{-1}\right)\mathcal{R}(\tilde{\theta},\theta).
\end{split}
\end{displaymath}
Mamy stąd
\begin{displaymath}
\mathbb{E}_{\theta}\mathcal{R}(\theta^*,\theta)\leq \frac{CB\epsilon^2L_{\Lambda}\omega (x)}{1-4B^{-1}-CB\frac{L_{\Lambda}}{x}}+\frac{CB\frac{L_{\Lambda}}{x}+1+4B^{-1}}{1-4B^{-1}-CB\frac{L_{\Lambda}}{x}}\mathcal{R}(\tilde{\theta},\theta).
\end{displaymath}
Korzystając z lematu \ref{lem3} mamy ponadto
\begin{displaymath}
\begin{split}
\mathbb{E}_{\theta}||\theta^*-\theta||^2&\leq (1+4B^{-1})\mathbb{E}_{\theta}\mathcal{R}(\theta^*,\theta)+CB\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]\\
&\leq (1+4B^{-1}+CB\frac{L_{\Lambda}}{x})\mathbb{E}_{\theta}\mathcal{R}(\theta^*,\theta)+CB\epsilon^2L_{\Lambda}\omega (x).
\end{split}
\end{displaymath}
Niech teraz $x=B^2L_{\Lambda}$ oraz $\gamma=4+C$. Wtedy z powyższych nierówności dostajemy 
\begin{displaymath}
\begin{split}
\mathbb{E}_{\theta}&||\theta^*-\theta||^2\leq (1+\gamma B^{-1})\mathbb{E}_{\theta}\mathcal{R}(\theta^*,\theta)+CB\epsilon^2L_{\Lambda}\omega (B^2L_{\Lambda})\\
&\leq \frac{1+\gamma B^{-1}}{1-\gamma B^{-1}}CB\epsilon^2L_{\Lambda}\omega (B^2L_{\Lambda})+CB\epsilon^2L_{\Lambda}\omega (B^2L_{\Lambda})+\frac{(1+\gamma B^{-1})^2}{1-\gamma B^{-1}}\mathcal{R}(\tilde{\theta},\theta).
\end{split}
\end{displaymath}
Zauważmy następnie, że z uwagi na fakt, że $\lim_{x\to \infty}\frac{x+\gamma}{x-\gamma}=1$, mamy 
$B\frac{1+\gamma B^{-1}}{1-\gamma B^{-1}}=C'B$ dla pewnej stałej $C'$ zależnej tylko od $C_1$ (poprzez $\gamma$) o ile tylko $B>B_0$ dla pewnego $B_0>\gamma$. Analogicznie widzimy, że  $\frac{(1+\gamma B^{-1})^2}{1-\gamma B^{-1}}=(1+\gamma B^{-1})\cdot C''$ o ile znowu $B>B_0$. Zwiększając stałą $\gamma$ i oznaczając ją przez $\gamma_1$ dostajemy, że $\frac{(1+\gamma B^{-1})^2}{1-\gamma B^{-1}}=1+\gamma_1B^{-1}$. Ostatecznie prowadzi nas do nierówności 
\begin{displaymath}
\mathbb{E}_{\theta}||\theta^*-\theta||^2\leq (1+\gamma_1B^{-1})\mathcal{R}(\tilde{\theta},\theta)+\gamma_2B\epsilon^2L_{\Lambda}\omega (B^2L_{\Lambda}).
\end{displaymath}
Nierówność ta kończy dowód twierdzenia \ref{glowny1}.
\end{proof}

\begin{proof}[Dowód twierdzenia \ref{glowny2}]
Będziemy stosować te same oznaczenia na estymator i wyrocznię jak w dowodzie twierdzenia \ref{glowny1}. Zauważmy na początek, że z uwagi (\ref{rho}) mamy 
\begin{displaymath}
\frac{\left(\sum_{k=1}^{\infty}\sigma_k^4\lambda_k^4\right)^{1/2}}{\sum_{k=1}^{\infty}\sigma_k^2\lambda_k^2}\leq \rho \Longrightarrow \frac{1}{\sum_{k=1}^{\infty}\sigma_k^2\lambda_k^2}\leq \frac{\rho}{\left(\sum_{k=1}^{\infty}\sigma_k^4\lambda_k^4\right)^{1/2}}.
\end{displaymath}
Zatem możemy oszacować wyrażenie $\frac{\sup_i \sigma_i^2\lambda_i^2}{\sum_{k=1}^{\infty}\sigma_k^2\lambda_k^2}$ w następujący sposób
\begin{displaymath}
\frac{\sup_i \sigma_i^2\lambda_i^2}{\sum_{k=1}^{\infty}\sigma_k^2\lambda_k^2}\leq \rho \frac{\sup_i \sigma_i^2\lambda_i^2}{\left(\sum_{k=1}^{\infty}\sigma_k^4\lambda_k^4\right)^{1/2}}\leq \rho^2
\end{displaymath}
korzystając z definicji $\rho$. Zauważmy ponadto, że dla dowolnego $\lambda\in \Lambda$ zachodzi
\begin{displaymath}
\mathcal{R}(\hat{\theta},\theta)=\sum_{i=1}^{\infty}(1-\lambda_i)\theta^2_i+\epsilon^2\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^2\geq \epsilon^2\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^2.
\end{displaymath}
Łącząc te dwie nierówności dostajemy
\begin{displaymath}
\epsilon^2\sup_i \sigma_i^2\lambda_i^2\leq \epsilon^2\rho^2\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^2\leq \rho^2\mathcal{R}(\hat{\theta},\theta).
\end{displaymath}
Pozwala nam to oszacować wyrażenie $\Delta^{\epsilon}[\lambda]$ dla dowolnego $\lambda\in \Lambda$ i dowolnego $\theta\in l^2$ przez
\begin{displaymath}
\Delta^{\epsilon}[\lambda]=\epsilon^2L_{\Lambda}\sup_i \sigma_i^2\lambda_i^2\leq \rho^2L_{\Lambda}\mathcal{R}(\hat{\theta},\theta).
\end{displaymath}
Następnie analogicznie jak w dowodzie twierdzenia \ref{glowny1} możemy dostać nierówność postaci (oszacowanie (\ref{szacowanie4}))
\begin{displaymath}
(1-4B^{-1})\mathbb{E}_{\theta}\mathcal{R}(\theta^*,\theta)\leq (1+4B^{-1})\mathcal{R}(\tilde{\theta},\theta)+CB\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]+CB\Delta^{\epsilon}[\tilde{\lambda}].
\end{displaymath}
To prowadzi do nierówności
\begin{displaymath}
(1-4B^{-1})\mathbb{E}_{\theta}\mathcal{R}(\theta^*,\theta)\leq (1+4B^{-1})\mathcal{R}(\tilde{\theta},\theta)+CB\rho^2L_{\Lambda}\mathbb{E}_{\theta}\mathcal{R}(\theta^*,\theta)+CB\rho^2L_{\Lambda}\mathcal{R}(\tilde{\theta},\theta),
\end{displaymath}
a stąd dostajemy
\begin{displaymath}
\mathbb{E}_{\theta}\mathcal{R}(\theta^*,\theta)\leq\frac{1+4B^{-1}+CB\rho^2L_{\Lambda}}{1-4B^{-1}-CB\rho^2L_{\Lambda}}\mathcal{R}(\tilde{\theta},\theta).
\end{displaymath}
Ponownie korzystając z lematu \ref{lem3} dostajemy
\begin{displaymath}
\mathbb{E}_{\theta}||\theta^*-\theta||^2\leq (1+4B^{-1})\mathbb{E}_{\theta}\mathcal{R}(\theta^*,\theta)+CB\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]
\end{displaymath}
\begin{displaymath}
\leq (1+4B^{-1}+CB\rho^2L_{\Lambda})\mathcal{R}(\tilde{\theta},\theta).
\end{displaymath}
Łącząc te dwie nierówności mamy
\begin{displaymath}
\mathbb{E}_{\theta}||\theta^*-\theta||^2\leq \frac{(1+4B^{-1}+CB\rho^2L_{\Lambda})^2}{1-4B^{-1}-CB\rho^2L_{\Lambda}}\mathcal{R}(\tilde{\theta},\theta).
\end{displaymath}
Zauważmy, że istnieje taka stała $\gamma_4>0$, że jeśli tylko zachodzi $\rho^2L_{\Lambda}\leq \gamma_4$, to wybór $B$ jako $(\rho^2L_{\Lambda})^{-1/2}$ prowadzi do nierówności $4B^{-1}+CB\rho^2L_{\Lambda}<1/2$, a stąd $1-4B^{-1}-CB\rho^2L_{\Lambda}\geq 1/2$. czyli jest odcięte od zera. Wtedy wybór $B=(\rho^2L_{\Lambda})^{-1/2}$ prowadzi do nierówności
\begin{displaymath}
\mathbb{E}_{\theta}||\theta^*-\theta||^2\leq \frac{(1+(4+C)\rho\sqrt{L_{\Lambda}})^2}{1-(4+C)\rho\sqrt{L_{\Lambda}}}\mathcal{R}(\tilde{\theta},\theta),
\end{displaymath}
co, rozumując analogicznie do dowodu twierdzenia \ref{glowny2}, prowadzi do nierówności
\begin{displaymath}
\mathcal{R}(\tilde{\theta},\theta)\leq (1+\gamma_3\rho\sqrt{L_{\Lambda}})\mathcal{R}(\tilde{\theta},\theta),
\end{displaymath}
która kończy dowód.
\end{proof}


\chapter{Nierówności wyrocznie w ogólnym modelu}\label{G2}
Rezultaty zaprezentowane w tym rozdziale są modyfikacjami rezultatów uzyskanych w pracy \cite{cavalier2}. Podejmiemy próbę zbudowania analogicznych jak w rozdziale poprzednim nierówności wyroczni w przypadku, gdy w rozważanym problemie
\begin{displaymath}
Y=Af+\epsilon\xi
\end{displaymath}
operator $A$ jest dowolnym operatorem liniowym i ograniczonym, ale niekoniecznie zwartym.\\

Będziemy potrzebowali pojęcia operatora unitarnego.
\begin{df}
Niech $H,G$ będą ośrodkowymi przestrzeniami Hilberta. Operator $U\colon H\to G$ nazwiemy operatorem unitarnym, jeżeli jest ciągły, liniowy, bijektywny i zachodzi $U^*=U^{-1}$.
\end{df}
\begin{uw}
Zauważmy, że jeżeli operator $U$ jest unitarny, to zachowuje on iloczyn skalarny, ponieważ dla dowolnych $f,g\in H$ zachodzi
\begin{displaymath}
\langle f,g\rangle =\langle U^{-1}Uf,g\rangle =\langle U^*Uf,g\rangle =\langle Uf,Ug\rangle.
\end{displaymath}
\end{uw}
Jeżeli $\xi$ jest szumem na przestrzeni $H$, natomiast operator $T$ jest określony na tej samej przestrzeni, to możemy, tak jak w rozdziale \ref{PW}, zdefiniować działanie operatora $T$ na $\xi$ w następujący sposób
\begin{displaymath}
\langle T\xi , f\rangle=\langle \xi, T^* f\rangle,\ \forall f\in TH.
\end{displaymath}
Ponadto, jeżeli operator kowariancji $\xi$ oznaczymy przez $\textbf{Cov}_{\xi}$, to operator kowariancji $T\xi$ jest postaci $\textbf{Cov}_{T\xi}=T\textbf{Cov}_{\xi}T^*$ (\cite{bissantz}, str. 2615). Wprowadźmy także następujące definicje
\begin{df}[\cite{typek}, str. 102] Niech $\xi\colon H\to L_2(\Omega, \mathcal{F}, \mathbb{P})$ będzie losowym szumem. Powiemy, że $\xi$ ma skończony słaby drugi moment, jeżeli dla dowolnego $f\in H$ zachodzi $\int_W |\langle \xi, f\rangle |^2d\mathbb{P} <\infty$. Ponadto jeżeli $\xi$ ma trajektorie w przestrzeni $H$ to powiemy, że $\xi$ ma skończony silny drugi moment, jeżeli $\int_W\norm{\xi}^2d\mathbb{P}<\infty$. Jeżeli proces posiada silny drugi moment, to  posiada także słaby drugi moment.
\end{df}
Poniżej przypomnimy definicję operatora śladowego wprowadzoną w rozdziale \ref{PW}. Jeżeli operator kowariancji procesu jest operatorem śladowym, to wtedy proces ten posiada trajektorie w przestrzeni (\cite{typek}, str. 175).
\begin{df}[\cite{hindus}, str. 285] Operator $T\colon H\to H$  nazwiemy operatorem śladowym na przestrzeni Hilberta $H$ z miarą $\mu$, jeżeli istnieje baza $\{x_j\}_{j\in J}$ przestrzeni $H$ taka, że zachodzi
\begin{displaymath}
\sum_{j\in J}\langle (T^*T)^{1/2}x_j,x_j\rangle <\infty.
\end{displaymath}
\end{df}
Niech $T\colon H\to H$ będzie liniowym i ograniczonym operatorem na przestrzeni $H$. Możemy wprowadzić wtedy następującą wielkość nazywaną śladem operatora $T$ 
\begin{displaymath}
TrT=\sum_{j\in J}\langle Tx_j,x_j\rangle.
\end{displaymath} 
Na mocy Propozycji 4.7.6 z \cite{hindus}, str. 289, mamy że jeżeli $T$ jest operatorem śladowym, to $TrT<\infty$. Niech teraz $T$ będzie ponadto samosprzężony i nieujemny i taki, że jego ślad jest skończony. Wtedy $T=(T^2)^{1/2}=(T^*T)^{1/2}$ oraz 
\begin{displaymath}
TrT=\sum_{j\in J}\langle Tx_j,x_j\rangle=\sum_{j\in J}\langle (T^*T)^{1/2}x_j,x_j\rangle <\infty	,
\end{displaymath}
czyli operator ten jest operatorem śladowym.\\
\indent Okazuje się, że dla operatorów samosprzężonych można uogólnić twierdzenie o reprezentacji według wartości singularnych do następującej postaci (\cite{taylor}, str. 97)
\begin{tw}\label{spectral}
Niech $A$ będzie operatorem samosprzężonym na ośrodkowej przestrzeni Hilberta $H$. Wtedy istnieją $\sigma$-- zwarta przestrzeń mierzalna $(S,\mathcal{S},\mu )$ z miarą Radona $\mu$, rzeczywista funkcja mierzalna $b$ określona na $S$ i operator unitarny $U\colon H\to L_2(S,\mathcal{S},\mu )$, takie, że 
\begin{displaymath}
A=U^{-1}M_bU,
\end{displaymath}
gdzie $M_b$ jest operatorem mnożenia przez funkcję $b$ zdefiniowanym jako $(M_bg)(x)=b(x)g(x)$.
\end{tw}
Zauważmy, że samosprzężone operatory zwarte i ich reprezentacja według wartości singularnych jest specjalnym przypadkiem powyższego twierdzenia, gdzie $S=\mathbb{N}$, $L_2(S,\mathcal{S},\mu) =l^2(\mathbb{N},2^{\mathbb{N}},\mu )$ z $\mu$ jako miarą liczącą, funkcją $b$ taką, że $b(k)=b_k$ oraz operatorem $U$ przeprowadzającym funkcję $f$ w ciąg jej współczynników Fouriera względem bazy wektorów własnych.\\
\indent Pierwszym krokiem jaki wykonamy przed dalszą analizą, będzie prekondycjonowanie problemu $Y=Af+\epsilon \xi$, czyli przekształcenie go do postaci 
\begin{equation}\label{condition}
A^*Y=A^*Af+\epsilon A^*\xi.
\end{equation} 
Podstawową korzyścią z takiego przekształcenia jest to, że w dalszej części możemy zajmować się wyłącznie operatorami samosprzężonymi i dodatnimi. Fakt, że operator $A^*A$ jest dodatni implikuje, że funkcja $b$ z twierdzenia \ref{spectral} jest dodatnia $\mu$--prawie wszędzie, a zatem operator mnożenia $M_b$ jest odwracalny i jego odwrotność ma postać $(M_b)^{-1}=M_{b^{-1}}$. Z drugiej strony wiadomo, że $f$ jest najlepszym rozwiązaniem w sensie minimalizacji kwadratu normy różnicy wyrażenia $Af-g$ wtedy i tylko wtedy, gdy zachodzi $A^*Af=A^*g$ (\cite{iphde}, str. 13).\\
\indent Korzystając z twierdzenia spektralnego \ref{spectral} możemy rozważany model (\ref{condition})
\begin{displaymath}
A^*Y=A^*Af+\epsilon A^*\xi=U^{-1}M_bUf+\epsilon A^* \xi
\end{displaymath} przekształcić do następującej postaci stosując operator $U$
\begin{displaymath}
UA^*Y=U(U^{-1}M_bU)f+\epsilon UA^*\xi,
\end{displaymath}
co można zapisać jako
\begin{equation}\label{zb}
Z=b\theta+\epsilon \eta,
\end{equation}
gdzie $Z=UA^*Y$, $\theta =Uf$ oraz $\eta =UA^*\xi$. Podobnie jak w przypadku operatorów zwartych możemy zapisać to wyrażenie w postaci analogicznej do (\ref{ssm})
\begin{equation}\label{ssmg}
X=\theta +\epsilon\sigma\eta,
\end{equation}
gdzie $\sigma\eta$ oznacza $M_{b^{-1}}UA^*\xi$. Przejście z równości (\ref{zb}) do równości (\ref{ssmg}) rozumiane jest jako następujące przekształcenie równania operatorowego. Skoro (\ref{zb}) jest postaci $UA^*Y=M_bUf+\epsilon UA^*\xi$ , zatem działając lewostronnie na to równanie operatorem $M_{b^{-1}}$ dostajemy równanie $M_{b^{-1}}UA^*Y=M_{b^{-1}}M_bUf+\epsilon M_{b^{-1}}UA^*\xi$, co po oznaczeniu przez $X=M_{b^{-1}}UA^*Y$ prowadzi do równania (\ref{ssmg}), gdyż $M_{b^{-1}}M_b$ jest operatorem identycznościowym. Natomiast równanie (\ref{ssmg}) rozumiane jest tak, że dla dowolnego elementu $g\in L_2(S,\mathcal{S},\mu )$ obserwowana jest zmienna losowa $\langle X,g\rangle = \langle \theta,g\rangle +\epsilon \langle \eta, b^{-1}g\rangle$, gdzie z kolei $\langle \eta,  b^{-1}g\rangle$ jest zmienną losową z przestrzeni $L_2(\Omega,\mathcal{F},\mathbb{P})$.\\
\indent Twierdzenie \ref{spectral} mówi tylko, że funkcja $b$ jest mierzalną funkcją rzeczywistą nie mówiąc nic więcej o jej zachowaniu. O źle postawionym problemie będziemy mogli mówić tylko wtedy, gdy $b\to 0$ w jakimś sensie.\\
\indent Przed dalszym rozumowaniem, udowodnimy czym jest $\eta$. Okazuje się, że gdy $\xi$ jest gaussowskim białym szumem na $H$, to $\eta$ jest gaussowskim kolorowym szumem na przestrzeni $L_2(S,\mathcal{S},\mu )=UH$.
\begin{tw}\label{whitenoise}
Niech $\eta$ będzie określona jako $\eta=UA^*\xi$ i niech $\xi$ będzie gaussowskim białym szumem na przestrzeni $H$. Wtedy $\sqrt{\sigma} \eta$  jest gaussowskim białym szumem na przestrzeni $L_2(S,\mathcal{S},\mu ) =UH$.
\end{tw}
\begin{proof}
Niech $f\in H$ będzie dowolnym elementem. Oznaczmy przez $\theta=Uf$. Wtedy 
\begin{displaymath}
\langle \sqrt{\sigma}\eta,\theta\rangle=\langle \xi, AU^{-1}\sqrt{\sigma}Uf\rangle\sim \mathcal{N}\left(0, \norm{AU^{-1}\sqrt{\sigma}Uf}^2\right),
\end{displaymath}
ponieważ $\sigma$ jest dodatnią funkcją rzeczywistą. Ponadto zachodzi
\begin{displaymath}
\begin{split}
\norm{AU^{-1}\sqrt{\sigma}Uf}^2&=\norm{A(A^*A)^{-1/2}f}^2=\langle A(A^*A)^{-1/2}f,A(A^*A)^{-1/2}f\rangle\\
&=\langle (A^*A)^{1/2}f,(A^*A)^{-1/2}f\rangle=\langle (A^*A)^{-1/2}(A^*A)^{1/2}f,f\rangle =\norm{f}^2.
\end{split}
\end{displaymath}
Zatem $\langle \sqrt{\sigma}\eta,\theta\rangle\sim \mathcal{N}(0,\norm{f}^2)$. Niech teraz dodatkowo $\nu=Uh, \ h\in H$. Wtedy
\begin{displaymath}
\begin{split}
\mathbb{E}\left(\langle\sqrt{\sigma}\eta,\theta\rangle,\langle\sqrt{\sigma}\eta,\nu\rangle\right)&=\mathbb{E}\left(\langle\xi,AU^{-1}\sqrt{\sigma}Uf \rangle\langle\xi,AU^{-1}\sqrt{\sigma}Uh\rangle\right)\\
&=\langle AU^{-1}\sqrt{\sigma}Uf,AU^{-1}\sqrt{\sigma}Uh\rangle=\langle f,h\rangle =\langle\theta,\nu\rangle.
\end{split}
\end{displaymath}
Pokazuje to, że $\sqrt{\sigma}\eta=\sqrt{\sigma}UA^*\xi$ jest gaussowskim białym szumem na przestrzeni $UH=L_2(S,\mathcal{S},\mu )$.
\end{proof}
Niech teraz $\hat{\theta}$ oznacza estymator elementu $\theta$ w modelu (\ref{ssmg}) na podstawie obserwacji $X$. Wtedy estymatorem poszukiwanego elementu $f$ jest $U^{-1}\hat{\theta}=\hat{f}$ i możemy wyrazić ryzyko tego estymatora w następujący sposób
\begin{displaymath}
\mathcal{R}(\hat{f},f)=\mathbb{E}_f||\hat{f}-f||_H^2=\mathbb{E}_{\theta}||\hat{\theta}-\theta||_S^2=\mathbb{E}_{\theta}\int_S|\hat{\theta}-\theta |^2d\mu ,
\end{displaymath}
gdzie w drugiej równości skorzystaliśmy z faktu, że $U$ jest liniowym operatorem unitarnym, czyli zachowuje normę elementu.\\
\indent W pracy \cite{cavalier2} pracowano przy założeniu, że obserwacje zaburzone są przez błąd pochodzący z białego szumu. Jednak z uwagi na to, że w przestrzeni nieskończenie wymiarowej operator identycznościowy, będący operatorem kowariancji dla białego szumu, nie jest operatorem zwartym, czyli nie może być operatorem śladowym, a więc nie może mieć skończonego silnego drugiego momentu. Z drugiej strony, jeżeli operator kowariancji pewnego szumu jest operatorem śladowym, to wtedy szum ten posiada silny drugi moment (\cite{typek}, str. 175) i w konsekwencji ma też trajektorie w rozważanej przestrzeni. Dlatego za \cite{bissantz} i korzystając ze wcześniejszego prekondycjonowania będziemy zakładać o operatorze $A$ i szumie $\xi$, że zachodzą następujące warunki gwarantujące skończoność drugich momentów regularyzowanego rozwiązania
\begin{equation}\label{warunki}
\forall g\in G\hspace{0.5cm}  \mathbb{E}\langle \xi, g\rangle =0\textrm{ oraz }\norm{\textbf{Cov}_{\xi}}\leq 1,
\end{equation}
\begin{displaymath}
\mathbb{E}\norm{A^*\xi}^2<\infty.
\end{displaymath}
Jeżeli spełnione są powyższe dwa warunki, możliwe jest takie dobranie miary $\mu$ i  operatora $U$ w twierdzeniu \ref{spectral}, by zachodziło
\begin{equation}\label{variance}
\forall s\in S\hspace{0.5cm} \textbf{Var}(UA^*\xi (s))\leq b(s)
\end{equation}
oraz $b\in L_1(S,\mathcal{S},\mu)$ (\cite{bissantz}, str. 2616).W pozostałej części pracy będziemy zakładać, że miara $\mu$ i operator $U$ zostały dobrane w taki właśnie sposób. Przykłady modeli spełniających powyższe warunki znajdują sie w rozdziale \ref{przyklad} oraz w \cite{bissantz}, str. 2620-- 2624.\\
W ogólnym przypadku w związku ze złym uwarunkowaniem problemu $Z=Th+\epsilon\xi$ rozważane są estymatory elementu $h$  postaci 
\begin{displaymath}
\hat{h}_{\alpha}=\Phi_{\alpha}(T^*T)T^*Y,
\end{displaymath}
gdzie funkcja $\Phi_{\alpha}$ ma następujące własności (\cite{bissantz}, str. 2613, \cite{mair}, str. 1426)
\begin{displaymath}
\sup_{t\geq 0}\Phi_{\alpha}(t)<\infty\ \forall \alpha>0,
\end{displaymath}
\begin{displaymath}
\sup_{\alpha>0,t\geq 0}t\Phi_{\alpha}(t)<\infty,
\end{displaymath}
\begin{displaymath}
\Phi_{\alpha}(t)\to t^{-1},\ gdy\  \alpha\to 0,\ \forall t>0.
\end{displaymath}
W rozważanym przez nas problemie możemy rozważyć estymator liniowy elementu $\theta$ w postaci zaproponowanej powyżej, gdzie celem zachowania spójności z wcześniejszymi oznaczeniami będziemy dalej pisać, że jest on postaci
\begin{equation}\label{est}
\hat{\theta}=\lambda X,
\end{equation}
gdzie $\lambda=\Phi_{\alpha}(A^*A)U^*M_b$ jest pewną nielosową funkcją, a funkcja $\Phi_{\alpha}$ zależy od konkretnego wyboru estymatora. Przykładowo dla estymatorów typu obcięcia spektralnego funkcja $\Phi_{\alpha}$ przyjmuje postać
\begin{displaymath}
\Phi_{\alpha}(t)=\frac{1}{t}\pmb{1}_{[\alpha,\infty)}.
\end{displaymath}
Funkcję $\lambda$ będziemy nazywać wagą lub filtrem. W dalszej części ograniczymy się tylko do rozważania rzeczywistych filtrów i przestrzeni. Możemy teraz wyznaczyć górne oszacowanie ryzyka estymatora postaci (\ref{est}). Warunki (\ref{warunki}) narzucone na postać szumu i operator $A$ gwarantują  skończoność ryzyka.
\begin{displaymath}
\begin{split}
\mathcal{R}(\hat{\theta},\theta )&= \mathbb{E}_{\theta}||\hat{\theta}-\theta||_2^2=\mathbb{E}_{\theta}\norm{\lambda\theta+\epsilon\lambda\sigma\eta-\theta}^2_2\\
&=\mathbb{E}_{\theta}\norm{\lambda\theta-\theta}^2_2+\mathbb{E}_{\theta}\norm{\epsilon\lambda\sigma\eta}^2_2=\norm{(1-\lambda)\theta}_2^2+\epsilon^2\mathbb{E}_{\theta}\norm{\lambda\sigma\eta}_2^2\\
&=\norm{(1-\lambda)\theta}_2^2+\epsilon^2\mathbb{E}_{\theta}\int_S\left(\lambda(s)\sigma(s)\eta(s)\right)^2d\mu\\
&=\norm{(1-\lambda)\theta}_2^2+\epsilon^2\int_S\lambda^2(s)\sigma^2(s)\mathbb{E}_{\theta}\eta^2(s)d\mu\\
&\leq \norm{(1-\lambda)\theta}_2^2+\epsilon^2\int_S\lambda^2(s)\sigma(s)d\mu\\
&=\int_S(1-\lambda(s))^2\theta^2(s)d\mu+\epsilon^2\int_S\lambda^2(s)\sigma(s)d\mu.
\end{split}
\end{displaymath}
W dalszej części będziemy omijać argumenty w funkcjach podcałkowych. Warto zauważyć, że w powyższym wyrażeniu w składniku $\epsilon^2\int_S\lambda^2\sigma d\mu$ czynnik $\sigma$ związany ze złym uwarunkowaniem problemu występuje w potędze o jeden niższej niż w analogicznym wyrażeniu (\ref{risk}), jednak trzeba zauważyć, że oba modele różnią się charakterem szumu.\\
\indent Wprowadzimy następujące oznaczenie 
\begin{equation}\label{Psi}
\Psi(\lambda,\theta)=\int_S(1-\lambda)^2\theta^2d\mu+\epsilon^2\int_S\lambda^2\sigma d\mu
\end{equation}
na wyrażenie będące odpowiednikiem wyrażenia (\ref{risk}) w modelu rozważanym w rozdziale \ref{G1}.

Zauważmy, że z uwagi na to, że dysponujemy jedynie oszacowaniem na wariancję szumu $\eta$ postaci (\ref{variance}) nie jest możliwe znalezienie nieobciążonego estymatora ryzyka jak w rozważanym wcześniej problemie z operatorem zwartym. Możliwe jest jednak wskazanie pewnego oszacowania. Z uwagi na (\ref{ssmg}) i (\ref{variance}) zachodzi
\begin{displaymath}
\begin{split}
\mathbb{E}\left(X^2-\epsilon^2\sigma\right)&=\mathbb{E}\left(\theta^2+2\epsilon\sigma\theta\eta+\epsilon^2\sigma^2\eta^2-\epsilon^2\sigma\right)\\
&=\theta^2+\epsilon^2\sigma^2\mathbb{E}\eta^2-\epsilon^2\sigma\leq \theta^2.
\end{split}
\end{displaymath} 
We wzorze (\ref{Psi}) zastąpimy więc $\theta^2$ przez $X^2 -\epsilon^2 \sigma$. W konsekwencji zamiast $\Psi(\lambda,\theta)$ będziemy rozważać jego przybliżenie postaci 
\begin{equation}\label{ure1}
\psi(\lambda,X)=\int_S(\lambda^2-2\lambda)X^2 d\mu+ 2\epsilon^2\int_S\lambda\sigma d\mu.
\end{equation}
Powyższa wartość jest skończona przy założeniu (\ref{assbig}). Wartość oczekiwana wyrażenia $\psi(\lambda,X)$ jest dolnym oszacowaniem na wyrażenie $\Psi(\lambda,\theta)-\int_S\theta^2d\mu $, czyli dla dowolnego filtru $\lambda$ zachodzi 
\begin{displaymath}
\mathbb{E}\psi (\lambda,X)\leq \Psi(\lambda,\theta)-\int_S\theta^2d\mu.
\end{displaymath}

Niech teraz badane filtry należą do pewnej skończonej rodziny $\Lambda=\{\lambda^1,\dots ,\lambda^N\}$. Naszym celem będzie wybór na podstawie obserwacji takiego filtra z tej rodziny, by związany z nim estymator naśladował ryzyko najlepszego estymatora w $\Lambda$.\\
Analogicznie do rozważanego wcześniej przypadku wymagać będziemy, by odpowiednie człony występujące w wyrażeniu na $\Psi(\lambda,\theta)$  oraz jego oszacowanie $\psi(\lambda, X)$ były skończone. Założymy także skończoność wyrażeń występujących później w nierównościach wyroczniach dla badanych wyrażeń.
\begin{za}\label{assbig}
Załóżmy, że
\begin{displaymath}
\forall\ \lambda \in \Lambda\ 0<\int_S\sigma^2\lambda^2d\mu <\infty,
\end{displaymath}
\begin{displaymath}
\max_{\lambda \in \Lambda}\norm{\lambda}_{\infty}\leq 1,
\end{displaymath}
\begin{displaymath}
\forall\ \lambda \in \Lambda\ \int_S\lambda\sigma^2d\mu <\infty,
\end{displaymath}
\begin{displaymath}
\forall\ \lambda \in \Lambda\ \int_S\sigma\lambda^2d\mu<\infty
\end{displaymath}
\begin{displaymath}
\forall\ \lambda \in \Lambda\ \int_S\sigma\lambda d\mu<\infty
\end{displaymath}
\begin{displaymath}
\exists\ C_1>0\ \forall\ \lambda \in \Lambda\ \int_S \sigma^4\lambda^2 d\mu \leq C_1\int_S\sigma^3\lambda^4d\mu,
\end{displaymath}
\begin{displaymath}
\exists\ C_2>0\ \forall\ \lambda \in \Lambda\ \int_S \sigma^2|\lambda| d\mu \leq C_2\int_S\sigma\lambda^2d\mu,
\end{displaymath}
\begin{displaymath}
\exists\ C_3>0\ \forall\ \lambda \in \Lambda\ \int_S \sigma|\lambda| d\mu \leq C_3\int_S\sigma^2\lambda^2d\mu,
\end{displaymath}
\end{za}
Powyższe założenia są odpowiednimi modyfikacjami założeń występujących w rozdziale \ref{G1}. Różnice wynikają z postaci górnego oszacowania na ryzyko estymatora w obecnie rozważanym modelu, gdzie rząd $\sigma$ jest o jeden niższy w porównaniu do \ref{risk}.\\
Wprowadzimy także potrzebne oznaczenia
\begin{displaymath}
\begin{split}
&\rho(\lambda)=\norm{\sigma\lambda}_{\infty}\left[\int_S\sigma^4\lambda^4d\mu\right]^{-1/2},\\
&\rho=\max_{\lambda\in \Lambda}\rho(\lambda),\\
&S=\frac{\max_{\lambda\in\Lambda}\norm{\sigma^2\lambda^2}_{\infty}}{\min_{\lambda\in \Lambda}\norm{\sigma^2\lambda^2}_{\infty}},\\
&M=\sum_{\lambda\in \Lambda}\exp\left(\frac{-1}{\rho(\lambda)}\right),\\
&L_{\lambda}=\ln(NS)+\rho^2\ln^2(MS).
\end{split}
\end{displaymath}
Interpretacje powyższych wyrażeń przenoszą się z rozważanego wcześniej przypadku z operatorem zwartym. Zauważmy teraz, że zachodzą następujące związki
\begin{displaymath}
\int_S\sigma^4\lambda^4d\mu\leq C_2\norm{\sigma\lambda}_{\infty}\int_S\sigma^2\lambda^2\mu
\end{displaymath}
skąd mamy
\begin{displaymath}
\frac{\left(\int_S\sigma^4\lambda^4d\mu\right)^{1/2}}{\int_S\sigma^2\lambda^2d\mu}\leq C_2\rho (\lambda)\leq C_2\rho.
\end{displaymath}
Mamy także
\begin{displaymath}
\forall\ \lambda\in \Lambda\ \rho (\lambda)=\frac{\norm{\sigma\lambda}_{\infty}}{\left(\int_S\sigma^4\lambda^4d\mu\right)^{1/2}}\leq \frac{\left(\int_S\sigma^2\lambda^2d\mu\right)^{1/2}}{\left(\int_S\sigma^4\lambda^4d\mu\right)^{1/2}}\leq C_3.
\end{displaymath}
Mając już odpowiednie założenia możemy zdefiniować poszukiwany estymator naśladujący ryzyko najlepszego estymatora w klasie $\Lambda$. Ponownie wykorzystamy w tym celu zdefiniowane wcześniej wyrażenie $\psi(\lambda,X)$, które w pewien sposób przybliża górne ograniczenie na  ryzyko, które chcielibyśmy zminimalizować.
\begin{df}
Niech funkcjonał $\psi(\lambda,X)$ będzie zdefiniowany jak w (\ref{ure1}). Poszukiwanym filtrem jest element minimalizujący względem $\lambda\in \Lambda$ funkcjonał $\psi(\lambda,X)$, czyli
\begin{equation}\label{estimator1}
\lambda^*=\arg\min_{\lambda\in \Lambda}\psi(\lambda,X).
\end{equation}
\end{df}
Przedstawimy teraz uogólnione wersje lematów \ref{lem1}, \ref{lem2} i \ref{lem3} na rozważany obecnie przypadek. Dowody znajdują się w części \ref{lematy}.
\begin{lm}\label{lem4}
Niech $\eta$ będzie gaussowskim szumem na przestrzeni Hilberta $L_2(S,\mathcal{S},\mu)$ z operatorem kowariancji postaci $TT^*$ dla pewnego ograniczonego operatora $T$ i o skończonym silnym drugim momencie i niech $v\in L_2(S,\mathcal{S},\mu)$ będzie losowym elementem tej przestrzeni ze skończonego zbioru $V\subset L_2(S,\mathcal{S},\mu)$ o liczności $N>1$. Niech ponadto dla dowolnego elementu $v\in V$ zachodzi $\norm{T^*v}_2\neq 0$. Wtedy dla dowolnego $K\geq 1$ zachodzi
\begin{displaymath}
\mathbb{E}\left|\langle \eta, v\rangle\right|\leq \norm{T} \sqrt{2\ln (NK)}\left(\mathbb{E}||v||_2+\sqrt{2\mathbb{E}||v||_2^2/K}\right).
\end{displaymath}
\end{lm}

\begin{lm}\label{lem5}
Niech $\eta$ będzie gaussowskim  szumem na przestrzeni Hilberta $L_2(S,\mathcal{S},\mu)$ z operatorem kowariancji postaci $TT^*$ dla pewnego ograniczonego operatora $T$ i o skończonym co najmniej słabym drugim momencie i niech $v\in L_2(S,\mathcal{S},\mu)$ będzie losowym elementem tej przestrzeni ze skończonego zbioru $V\subset L_2(S,\mathcal{S},\mu)$ o liczności $N>1$. Niech ponadto $v\neq 0$ dla dowolnego $v\in V$. Oznaczmy przez $m(v)=\norm{v}_{\infty}/||v||_2$, $m_V=\max_{v\in V}m(v)$ oraz 
\begin{displaymath}
M(q)=\sum_{v\in V}\exp (-q/m(v)),\ q>0.
\end{displaymath}
Wtedy istnieje stała $D$ zależna tylko od $q$ i operatora $T$, taka, że dla dowolnego $K\geq 1$ zachodzi
\begin{displaymath}
\mathbb{E}\left|\langle \eta^2-1, v\rangle\right|\leq D\norm{T}^2\left(\sqrt{\ln (NK)}+m_V\ln (M(q)K)\right)\left(\mathbb{E}||v||+\sqrt{\mathbb{E}||v||^2/K}\right).
\end{displaymath}
\end{lm}
\begin{lm}\label{lem6}
Niech $\eta$ będzie gaussowskim  szumem na przestrzeni Hilberta $L_2(S,\mathcal{S},\mu)$ z operatorem kowariancji postaci $TT^*$ dla pewnego ograniczonego operatora $T$ i o skończonym co najmniej słabym drugim momencie. Niech ponadto $\hat{\theta}=\hat{\lambda}(X)X$ będzie liniowym estymatorem z wagą z wartościami z przedziału $[-1,1]$ przyjmującym wartości w zbiorze $\Lambda$. Oznaczmy  
\begin{displaymath}
\Delta^{\epsilon}[\lambda]=\epsilon^2L_{\Lambda}\norm{\sigma^2\lambda^2}_{\infty},\ \lambda\in \Lambda.
\end{displaymath}
Wtedy istnieje stała $C>0$ zależna tylko od operatora $T$ taka, że dla dowolnego $B>0$ zachodzi
\begin{displaymath}
\mathbb{E}_{\theta}\norm{\hat{\theta}-\theta}_2^2\leq \max\{1,C_2\}(1+4B^{-1}\max\{1,\norm{T}^2\})\mathbb{E}_{\theta}\Psi(\hat{\lambda},\theta)+CB\norm{T}^2\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda (X)].
\end{displaymath}
\end{lm}

Możemy teraz przejść do wypowiedzenia dwóch twierdzeń będących zarazem głównym wynikiem tego rozdziału i uogólnieniem twierdzeń \ref{glowny1} i \ref{glowny2} na przypadek, gdy badany problem może być modelowany jako (\ref{condition}). 


\begin{tw}\label{glowny3}
Niech będzie spełnione założenie \ref{assbig}. Wtedy dla dowolnego $\theta\in L_2(S,\mathcal{S},\mu)$, dla dowolnego $B>B_0$ i dla estymatora liniowego $\theta^*$ z filtrem wybranym zgodnie z (\ref{estimator1}) zachodzi
\begin{displaymath}
\begin{split}
\mathbb{E}_{\theta}\norm{\theta^*-\theta}^2 \leq \max \{1,C_2\}&(1+\gamma_1B^{-1}\max\{1,\norm{A}^2\})\min_{\lambda\in \Lambda}\Psi(\lambda,\theta)\\
 & + \max \{1,C_2\}\gamma_2B\max\{1,\norm{A}^2\}\epsilon^2L_{\Lambda}\omega(B^2L_{\Lambda}),
\end{split}
\end{displaymath}
gdzie stałe $B_0>0,\gamma_1>0,\gamma_2>0$ zależą tylko od stałej $C_1$ i operatora $A$, wyrażenie $\min_{\lambda\in \Lambda}\Psi(\lambda,\theta)$ rozumiane jest jako minimum wzięte po wszystkich estymatorach $\hat{\theta}$ postaci $\lambda X,\ \lambda\in \Lambda$, a funkcja $\omega(x)$ jest postaci
\begin{displaymath}
\omega(x)=\max_{\lambda\in \Lambda}\norm{\sigma^2\lambda^2\pmb{1}\left(\int_S\sigma\lambda^2d\mu\leq x \norm{\sigma^2\lambda^2}_{\infty}\right)}_{\infty},\ x>0.
\end{displaymath}
\end{tw}
\begin{tw}\label{glowny4}
Niech będzie spełnione założenie \ref{assbig}. Wtedy istnieją stałe $\gamma_3>0,\gamma_4>0$ zależące tylko od $C_1$, takie że dla dowolnego $\theta\in L_2(S,\mathcal{S},\mu)$ i dla estymatora liniowego $\theta^*$ z filtrem wybranym zgodnie z (\ref{estimator1}) zachodzi
\begin{displaymath}
\mathbb{E}_{\theta}\norm{\theta^*-\theta}^2\leq \max \{1,C_2\}(1+\gamma_3\max\{1,\norm{A}^2\}\sqrt{ \rho L_{\Lambda}})\min_{\lambda\in \Lambda}\Psi(\lambda,\theta),
\end{displaymath}
o ile $\rho\sqrt{L_{\Lambda}}<\gamma_4$, a minimum rozumiane jest jak w poprzednim twierdzeniu.
\end{tw}

Zanim udowodnimy powyższe twierdzenia, zauważmy, że nierówność występująca w tezie twierdzenia \ref{glowny3} możemy zapisać w postaci
\begin{displaymath}
\mathbb{E}_{\theta}\norm{\theta^*-\theta}^2\leq C'(1+\gamma_1B^{-1})\min_{\lambda\in \Lambda}\left(\mathbb{E}_{\theta}\norm{\lambda X-\theta}^2+pen_A(\lambda)\right)+\gamma_2B\norm{A}^2\epsilon^2L_{\Lambda}\omega(B^2L_{\Lambda})
\end{displaymath}
dla pewnej funkcji $pen_A\colon \Lambda \to \mathbb{R}_+$, która może być interpretowana jako funkcja kary w badanym problemie pojawiająca się w związku z brakiem zwartości ('skomplikowaniem') operatora $A$. Takie przedstawienie uzyskanego wyniku jest podobne do wyników uzyskanych w innych modelach (por. \cite{barron}, str. 378, \cite{loubes}, str. 181, \cite{loubes}, str. 668, \cite{giraud}, str. 37).


\begin{proof}[Dowód twierdzenia \ref{glowny3}]
Niech $T=UA^*$, wtedy $TT^*$ jest operatorem kowariancji szumu $\eta$. Niech $\tilde{\lambda}\in \Lambda$ będzie takim filtrem, że związany z nim estymator jest wyrocznią, czyli $\tilde{\theta}=\arg \min_{\lambda\in \Lambda}\Psi(\lambda,\theta)$, natomiast przez $\lambda^*$ oznaczmy filtr definiowany przez (\ref{estimator1}) i związany z nim estymator przez $\theta^*$. Oznaczmy ponadto $\max\{1,C_2\}=C'$ oraz $\max\{1,\norm{T}^2\}=C''$.
W rozpatrywanym modelu (\ref{ssmg}) $X=\theta+\epsilon\sigma\eta$. Dostajemy stąd
\begin{displaymath}
\begin{split}
\psi(\lambda^*,X)&=\int_S(\lambda^{*2}-2\lambda^*)X^2d\mu+2\epsilon^2\int_S\lambda^*\sigma d\mu\\
&=\int_S(\lambda^{*2}-2\lambda^*)(X^2-\epsilon^2\sigma)d\mu+\epsilon^2\int_S\lambda^{*2}\sigma d\mu\\
&=\int_S(\lambda^{*2}-2\lambda^*)(\theta^2+2\epsilon\theta\sigma\eta+\epsilon^2\sigma^2\eta^2-\epsilon^2\sigma)d\mu+\epsilon^2\int_S\lambda^{*2}\sigma d\mu\\
&=2\epsilon\int_S(\lambda^{*2}-2\lambda^*)\theta\sigma\eta d\mu+\left[\int_S(\lambda^{*2}-2\lambda^*)\theta^2d\mu+\int_S\theta^2d\mu+\epsilon^2\int_S\lambda^{*2}\sigma d\mu\right]\\&\hspace{4mm} -\int_S\theta^2d\mu+\epsilon^2\int_S(\lambda^{*2}-2\lambda^*)\sigma(\sigma\eta-1)d\mu=\epsilon^2\int_S(\lambda^{*2}-2\lambda^*)\sigma(\sigma\eta^2-1)d\mu\\
&\hspace{4mm}-\int_S\theta^2d\mu+2\epsilon\int_S(1-\lambda^*)^2\sigma\theta\eta d\mu -2\epsilon\int_S\sigma\theta\eta d\mu+\Psi(\lambda^*,\theta).
\end{split}
\end{displaymath}
A stąd mamy
\begin{displaymath}
\begin{split}
\mathbb{E}_{\theta}\psi[\lambda^*,X]&=\mathbb{E}_{\theta}\Psi(\lambda^*,\theta)-\int_S\theta ^2d\mu+2\epsilon\mathbb{E}_{\theta}\int_S(1-\lambda^*)^2\sigma \theta \eta d\mu\\
&+\epsilon^2\mathbb{E}_{\theta}\int_S(\lambda^{*2}-2\lambda^*)\sigma(\sigma\eta^2-1)d\mu.
\end{split}
\end{displaymath}
Korzystając z wprowadzonych wcześniej lematów, oszacujemy dwa ostatnie składniki tego wyrażenia. Zauważmy, że zachodzi
\begin{displaymath}
\begin{split}
\epsilon\mathbb{E}_{\theta}\int_S(1-\lambda^*)^2\sigma \theta \eta d\mu&=
\epsilon\mathbb{E}_{\theta}\int_S[(1-\lambda^*)^2-(1-\tilde{\lambda})^2]\sigma \theta \eta d\mu\\
&\geq -\epsilon\mathbb{E}_{\theta}\left|\int_S[(1-\lambda^*)^2-(1-\tilde{\lambda})^2]\sigma \theta \eta d\mu\right|.
\end{split}
\end{displaymath}
Korzystając z lematu \ref{lem4} z $K=S$ i $v=[(1-\lambda^*)^2-(1-\tilde{\lambda})^2]\sigma \theta $ dostajemy
\begin{displaymath}
\begin{split}
-\epsilon\mathbb{E}_{\theta}&\left|\int_S[(1-\lambda^*)^2-(1-\tilde{\lambda})^2]\sigma \theta \eta d\mu\right|\\
&\geq -\epsilon\norm{T}\sqrt{2\ln (NS)}\mathbb{E}_{\theta}\left(\int_S[(1-\lambda^*)^2-(1-\tilde{\lambda})^2]\sigma^2\theta ^2 d\mu\right)^{1/2}\\
&\hspace{4mm}-2\epsilon\norm{T}\sqrt{\ln (NS)/S}\left(\mathbb{E}_{\theta}\int_S[(1-\lambda^*)^2-(1-\tilde{\lambda})^2]\sigma^2\theta ^2 d\mu\right)^{1/2}\\
&\geq -2\epsilon\norm{T}\sqrt{2\ln (NS)}\mathbb{E}_{\theta}\left(\int_S[(1-\lambda^*)^2+(1-\tilde{\lambda})^2](\lambda^{*2}+\tilde{\lambda^2})\theta ^2\sigma^2d\mu\right)^{1/2}\\
&\hspace{4mm}-4\epsilon\norm{T}\sqrt{\ln (NS)/S}\left(\mathbb{E}_{\theta}\int_S[(1-\lambda^*)^2+(1-\tilde{\lambda})^2](\lambda^{*2}+\tilde{\lambda^2})\theta ^2\sigma^2 d\mu\right)^{1/2}.
\end{split}
\end{displaymath}
Korzystając  z nierówności $2ab\leq B^{-1}a^2+Bb^2$ zachodzącej dla dowolnego $B>0$ dla pierwszego składnika dostajemy
\begin{displaymath}
\begin{split}
2\epsilon\norm{T}&\sqrt{2\ln (NS)}\mathbb{E}_{\theta}\left(\int_S[(1-\lambda^*)^2+(1-\tilde{\lambda})^2](\lambda^{*2}+\tilde{\lambda^2})\theta ^2\sigma^2d\mu\right)^{1/2}\\
&\leq \mathbb{E}_{\theta}2\epsilon\norm{T}\sqrt{2\ln (NS)\norm{(\lambda^{*2}+\tilde{\lambda^2})\sigma^2}_{\infty}}\left(\int_S[(1-\lambda^*)^2+(1-\tilde{\lambda})^2]\theta ^2d\mu\right)^{1/2}\\
&\leq 2B\epsilon^2\norm{T}^2 \ln (NS)\mathbb{E}_{\theta}\norm{(\lambda^{*2}+\tilde{\lambda^2})\sigma^2}_{\infty}+B^{-1}\mathbb{E}_{\theta}\int_S[(1-\lambda^*)^2+(1-\tilde{\lambda})^2]\theta ^2d\mu\\
&\leq 2B\epsilon^2\norm{T}^2 \ln (NS)\mathbb{E}_{\theta}\left(\norm{\lambda^{*2}\sigma^2}_{\infty}+\norm{\tilde{\lambda^2}\sigma^2}_{\infty}\right)+B^{-1}\mathbb{E}_{\theta}\int_S[(1-\lambda^*)^2\\
&\hspace{4mm}+(1-\tilde{\lambda})^2]\theta ^2d\mu.
\end{split}
\end{displaymath}
Postępując podobnie z drugim wyrażeniem otrzymujemy
\begin{displaymath}
4\epsilon\norm{T}\sqrt{\ln (NS)/S}\left(\mathbb{E}_{\theta}\int_S[(1-\lambda^*)^2+(1-\tilde{\lambda})^2](\lambda^{*2}+\tilde{\lambda^2})\theta ^2\sigma^2 d\mu\right)^{1/2}\leq
\end{displaymath}
\begin{displaymath}
\leq 4B\epsilon^2\norm{T}^2\ln (NS)/S\max_{\lambda\in \Lambda}\norm{(\lambda^{2}+\tilde{\lambda^2})\sigma^2}_{\infty}+B^{-1}\mathbb{E}_{\theta}\int_S[(1-\lambda^*)^2+(1-\tilde{\lambda})^2]\theta ^2d\mu.
\end{displaymath}
Korzystając z definicji wielkości $S$ mamy
\begin{displaymath}
\frac{\max_{\lambda\in \Lambda}\norm{(\lambda^{2}+\tilde{\lambda^2})\sigma^2}_{\infty}}{S}\leq 
\norm{\lambda^{*2}\sigma^2}_{\infty}+\norm{\tilde{\lambda^2}\sigma^2}_{\infty}.
\end{displaymath}
A stąd mamy oszacowanie postaci
\begin{displaymath}
4\epsilon\norm{T}\sqrt{\ln (NS)/S}\left(\mathbb{E}_{\theta}\int_S[(1-\lambda^*)^2+(1-\tilde{\lambda})^2](\lambda^{*2}+\tilde{\lambda^2})\theta ^2\sigma^2 d\mu\right)^{1/2}\leq
\end{displaymath}
\begin{displaymath}
\leq 4B\epsilon^2\norm{T}^2 \ln (NS)\mathbb{E}_{\theta}\left(\norm{\lambda^{*2}\sigma^2}_{\infty}+\norm{\tilde{\lambda^2}\sigma^2}_{\infty}\right)+B^{-1}\mathbb{E}_{\theta}\int_S[(1-\lambda^*)^2+(1-\tilde{\lambda})^2]\theta ^2d\mu.
\end{displaymath}
Jako, że zachodzi 
$\ln (NS)\leq L_{\Lambda},$
to łącząc powyższe dwa oszacowania dostajemy 
\begin{displaymath}
\epsilon\mathbb{E}_{\theta}\int_S(1-\lambda^*)^2\sigma\theta \eta d\mu\geq 
\end{displaymath}
\begin{displaymath}
\geq -2B^{-1}\mathbb{E}_{\theta}\int_S(1-\lambda^*)^2d\mu-2B^{-1}\int_S(1-\tilde{\lambda})^2d\mu-6B\norm{T}^2\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]-6B\norm{T}^2\mathbb{E}_{\theta}\Delta^{\epsilon}[\tilde{\lambda}].
\end{displaymath}

Znajdziemy teraz oszacowanie dla składnika $\epsilon^2\mathbb{E}_{\theta}\left|\int_S(\lambda^{*2}-2\lambda^*)\sigma(\sigma\eta^2-1)d\mu\right|$. Zauważmy, że  dla dowolnego $\lambda\in \Lambda$ zachodzi $\lambda^2\leq (\lambda^2-2\lambda)^2\leq 9\lambda^2$ rozumiane jako nierówność funkcyjna zachodząca dla wszystkich argumentów funkcji $\lambda$. Posłużymy się teraz lematem \ref{lem5} z $K=S$, $q=3C_2$ i $v=(\lambda^{*2}-2\lambda^*)\sigma$. 
\begin{displaymath}
\epsilon^2\mathbb{E}_{\theta}\left|\int_S(\lambda^{*2}-2\lambda^*)\sigma^2(\eta^2-1)d\mu\right|\leq
\end{displaymath}
\begin{displaymath}
\leq \epsilon^2\norm{T}^2D\left(\sqrt{\ln (NS)}+m_V\ln (SM(3C_2))\right)\left(\mathbb{E}_{\theta}||v||+\sqrt{\mathbb{E}_{\theta}||v||^2/S}\right).
\end{displaymath}
Analogicznie jak w rozważanym wcześniej przypadku z operatorem zwartym mamy
\begin{displaymath}
\begin{split}
&m(v)=\frac{\norm{(\lambda^{*2}-2\lambda^*)\sigma}_{\infty}}{\sqrt{\int_S(\lambda^{*2}-2\lambda^*)^2\sigma^2d\mu}}\leq 3C_2\rho (\lambda),\\
& M(3C_2)\leq M,\ m_V\leq 3C_2\max_{\lambda\in \Lambda}\rho(\lambda)=3C_2\rho.
\end{split}
\end{displaymath}

Stąd dostajemy, że 
\begin{displaymath}
\sqrt{\ln (NS)}+m_V\ln (SM(3C_2))\leq C\sqrt{L_{\Lambda}},
\end{displaymath}
gdzie $C$ jest pewną stałą zależną tylko od $C_1$ i $C_2$. Zgodnie z twierdzeniem \ref{whitenoise} $\sqrt{\sigma}\eta$ jest białym szumem, więc jego operator kowariancji ma postać $I=II^*$. Możemy teraz kontynuować szacowanie analizowanego wyrażenia.
\begin{displaymath}
\begin{split}
\epsilon^2\mathbb{E}_{\theta}&\int_S(\lambda^{*2}-2\lambda^*)\sigma(\sigma\eta^2-1)d\mu\\
&\geq  -\epsilon^2D\left(\sqrt{\ln (NS)}+m_V\ln (SM(3C_2))\right)\left(\mathbb{E}_{\theta}||v||+\sqrt{\mathbb{E}_{\theta}||v||^2/S}\right)\\
&\geq -\epsilon^2C\sqrt{L_{\Lambda}}\mathbb{E}_{\theta}\left(\int_S(\lambda^{*2}-2\lambda^*)^2\sigma^4d\mu\right)^{1/2}
-\epsilon^2C\sqrt{L_{\Lambda}}S^{-1/2}\left(\mathbb{E}_{\theta}\int_S(\lambda^{*2}-2\lambda^*)^2\sigma^4 d\mu\right)^{1/2}\\
&\geq -\epsilon^2C\sqrt{L_{\Lambda}}\mathbb{E}_{\theta}\left(\int_S\lambda^{*4}\sigma^3d\mu\right)^{1/2}-\epsilon^2C\sqrt{L_{\Lambda}}S^{-1/2}\left(\mathbb{E}_{\theta}\int_S\lambda^{*4}\sigma^3d\mu\right)^{1/2}.
\end{split}
\end{displaymath}
Korzystając z faktu, że $\min_{\lambda\in \Lambda}\norm{\lambda^2\sigma^2}_{\infty}\leq \mathbb{E}_{\theta}\norm{\lambda^{*2}\sigma^2}_{\infty}$ mamy
\begin{displaymath}
S^{-1}\mathbb{E}_{\theta}\int_S\sigma^3\lambda^{*4}d\mu\leq 
 \mathbb{E}_{\theta}\norm{\sigma^2\lambda^{*2}}_{\infty}\mathbb{E}_{\theta}\int_S\sigma\lambda^{*2}d\mu.
\end{displaymath}
Podobnie dla drugiego wyrażenia
\begin{displaymath}
\mathbb{E}_{\theta}\left(\int_S\sigma^3\lambda^{*4}d\mu\right)^{1/2}\leq \mathbb{E}_{\theta}\left(\norm{\sigma^2\lambda^{*2}}_{\infty}\int_S\sigma\lambda^{*2}d\mu\right)^{1/2}.
\end{displaymath}
Ponownie korzystając z nierówności $2ab\leq B^{-1}a^2+Bb^2$ dostajemy
\begin{displaymath}
C\sqrt{L_{\Lambda}}\mathbb{E}_{\theta}\left(\norm{\sigma^2\lambda^{*2}}_{\infty}\int_S\sigma\lambda^{*2}d\mu\right)^{1/2}
\leq B\mathbb{E}_{\theta}C^2L_{\Lambda}\norm{\sigma^2\lambda^{*2}}_{\infty}+2B^{-1}\mathbb{E}_{\theta}\int_S\sigma\lambda^{*2}d\mu.
\end{displaymath}
Możemy także zapisać
\begin{displaymath}
C\sqrt{L_{\Lambda}}\left(\mathbb{E}_{\theta}\norm{\sigma^2\lambda^{*2}}_{\infty}\mathbb{E}_{\theta}\int_S\sigma\lambda^{*2}d\mu\right)^{1/2}
\leq B\mathbb{E}_{\theta}C^2L_{\Lambda}\norm{\sigma^2\lambda^{*2}}_{\infty}+2B^{-1}\mathbb{E}_{\theta}\int_S\sigma\lambda^{*2}d\mu.
\end{displaymath}
Łącząc oba te oszacowania dostajemy
\begin{displaymath}
\epsilon^2\mathbb{E}_{\theta}\int_S(\lambda^{*2}-2\lambda^*)\sigma(\sigma\eta^2-1)d\mu\geq
-CB\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]-4\epsilon^2B^{-1}\mathbb{E}_{\theta}\int_S\sigma\lambda^{*2}d\mu.
\end{displaymath}
Powyższe oszacowania pozwalają zapisać dalej następującą nierówność
\begin{displaymath}
\begin{split}
\mathbb{E}_{\theta}\psi[\lambda^*,X]=\mathbb{E}_{\theta}&\Psi(\lambda^*,\theta)-\int_S\theta ^2d\mu+2\epsilon\mathbb{E}_{\theta}\int_S(1-\lambda^*)^2\sigma \theta_i \eta d\mu\\
&+\epsilon^2\mathbb{E}_{\theta}\int_S(\lambda^{*2}-2\lambda^*)\sigma(\sigma\eta^2-1)d\mu \geq \mathbb{E}_{\theta}\Psi(\lambda^*,\theta)\\
&-\int_S\theta ^2d\mu-4B^{-1}\mathbb{E}_{\theta}\Psi(\lambda^*,\theta)-4B^{-1}\Psi(\tilde{\lambda},\theta)\\
&-CBC''\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]-CBC''\Delta^{\epsilon}[\tilde{\lambda}].
\end{split}
\end{displaymath}
Zatem zachodzi
\begin{displaymath}
\begin{split}
(1-4B^{-1})\mathbb{E}_{\theta}&\Psi(\lambda^*,\theta)\leq \mathbb{E}_{\theta}\psi[\lambda^*,X]+\int_S\theta^2d\mu\\
&+4B^{-1}\Psi(\tilde{\lambda},\theta)+CBC''\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]+CBC''\Delta^{\epsilon}[\tilde{\lambda}].
\end{split}
\end{displaymath}
Jednak, jako że filtr $\lambda^*$ był zdefiniowany jako argument minimalizujący wyrażenie $\psi$, zatem musi zachodzić
\begin{displaymath}
\mathbb{E}_{\theta}\psi[\lambda^*,X]\leq \mathbb{E}_{\theta}\psi[\tilde{\lambda},X]\leq \Psi(\tilde{\lambda},\theta)-\int_S\theta ^2d\mu.
\end{displaymath}
Otrzymujemy zatem
\begin{equation}\label{szacowanie5}
\begin{split}
(1-4B^{-1})\mathbb{E}_{\theta}\Psi(\lambda^*,\theta)&\leq (1+4B^{-1})\Psi(\tilde{\lambda},\theta) \\
&+CBC''\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]+CBC''\Delta^{\epsilon}[\tilde{\lambda}].
\end{split}
\end{equation}
Zauważmy, że dla dowolnego $x>0$ zachodzi następujące oszacowanie
\begin{displaymath}
\begin{split}
\norm{\sigma^2\lambda^2}_{\infty}&=\norm{\sigma^2\lambda^2\pmb{1}\left\{x\norm{\sigma^2\lambda^2}_{\infty}<\int_S\sigma\lambda^2 d\mu\right\}}_{\infty}+\norm{\sigma^2\lambda^2\pmb{1}\left\{x\norm{\sigma\lambda^2}_{\infty}\geq \int_S\sigma\lambda^2 d\mu\right\}}_{\infty}\\
&\leq \frac{1}{x}\int_S\sigma\lambda^2 d\mu+\max_{\lambda\in \Lambda}\norm{\sigma^2\lambda^2\pmb{1}\left\{x\norm{\sigma^2\lambda^2}_{\infty}\geq \int_S\sigma\lambda^2 d\mu\right\}}_{\infty}\\
&\leq \frac{1}{x}\int_S\sigma\lambda^2 d\mu+\omega (x)\leq \frac{1}{x\epsilon^2}\Psi(\lambda,\theta)+\omega (x)\ \forall_{\lambda\in \Lambda}.
\end{split}
\end{displaymath}
Stąd dostajemy 
\begin{displaymath}
\Delta^{\epsilon}[\lambda]=\epsilon^2 L_{\Lambda}\norm{\sigma^2\lambda^2}_{\infty}\leq \frac{L_{\Lambda}}{x}\Psi(\lambda,\theta)+\epsilon^2L_{\Lambda}\omega (x).
\end{displaymath}
Wykorzystamy teraz powyższe nierówności do wyrażenia (\ref{szacowanie5}).
\begin{displaymath}
\begin{split}
(1-4B^{-1})\mathbb{E}_{\theta}\Psi(\lambda^*,\theta)&\leq (1+4B^{-1})\Psi(\tilde{\lambda},\theta)+CBC''\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]+CBC''\Delta^{\epsilon}[\tilde{\lambda}]\\
&\leq CBC''\frac{L_{\Lambda}}{x}\mathbb{E}_{\theta}\Psi(\lambda^*,\theta)+CBC''\epsilon^2L_{\Lambda}\omega (x)\\&+\left(CBC''\frac{L_{\Lambda}}{x}+1+4B^{-1}\right)\Psi(\tilde{\lambda},\theta).
\end{split}
\end{displaymath}
Mamy stąd
\begin{displaymath}
\mathbb{E}_{\theta}\Psi(\lambda^*,\theta)\leq \frac{CBC''\epsilon^2L_{\Lambda}\omega (x)}{1-4B^{-1}-CBC''\frac{L_{\Lambda}}{x}}+\frac{CBC''\frac{L_{\Lambda}}{x}+1+4B^{-1}}{1-4B^{-1}-CBC''\frac{L_{\Lambda}}{x}}\Psi(\tilde{\lambda},\theta).
\end{displaymath}
Korzystając z lematu \ref{lem6} mamy ponadto
\begin{displaymath}
\begin{split}
\frac{1}{C'}\mathbb{E}_{\theta}&||\theta^*-\theta||^2\leq (1+4B^{-1}C'')\mathbb{E}_{\theta}\Psi(\lambda^*,\theta)+CB\norm{T}^2\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]\\
&\leq \left(1+4B^{-1}C''+CB\norm{T}^2\frac{L_{\Lambda}}{x}\right)\mathbb{E}_{\theta}\Psi(\lambda^*,\theta)+CB\norm{T}^2\epsilon^2L_{\Lambda}\omega (x)\\
&\leq \left(1+4B^{-1}C''+CBC''\frac{L_{\Lambda}}{x}\right)\mathbb{E}_{\theta}\Psi(\lambda^*,\theta)+CB\norm{T}^2\epsilon^2L_{\Lambda}\omega (x).
\end{split}
\end{displaymath}
Niech teraz $x=B^2L_{\Lambda}$ oraz $\gamma$ będzie stałą zależną tylko od $C$. Wtedy 
\begin{displaymath}
\begin{split}
\frac{1}{C'}\mathbb{E}_{\theta}&||\theta^*-\theta||^2\leq \frac{(1+\gamma B^{-1}C'')^2}{1-\gamma B^{-1}C''}\Psi(\tilde{\lambda},\theta)\\
&+ \frac{1+\gamma B^{-1}C''}{1-\gamma B^{-1}C''}CBC''\epsilon^2L_{\Lambda}\omega (B^2L_{\Lambda})+CB\norm{T}^2\epsilon^2L_{\Lambda}\omega (B^2L_{\Lambda}).
\end{split}
\end{displaymath}
Korzystając z faktu, że $\lim_{x\to \infty}\frac{x+\gamma}{x-\gamma}=1$, powyższe rozważania prowadzą nas do nierówności  
\begin{displaymath}
\frac{1}{C'}\mathbb{E}_{\theta}||\theta^*-\theta||^2\leq (1+\gamma_1B^{-1}C'')\Psi(\tilde{\lambda},\theta)+\gamma_2BC''\epsilon^2L_{\Lambda}\omega (B^2L_{\Lambda}),
\end{displaymath}
która kończy dowód twierdzenia \ref{glowny3}.
\end{proof}

\begin{proof}[Dowód twierdzenia \ref{glowny4}] 
Będziemy stosować te same oznaczenia na estymator, wyrocznię i stałe jak w dowodzie twierdzenia \ref{glowny3}. 
Wyrażenie $\frac{\norm{\sigma^2\lambda^2}_{\infty}}{\int_S\sigma^2\lambda^2 d\mu}$ możemy oszacować w następujący sposób
\begin{displaymath}
\frac{\norm{\sigma^2\lambda^2}_{\infty}}{\int_S\sigma^2\lambda^2 d\mu}\leq C_2\rho \frac{\left(\int_S\sigma^4\lambda^4 d\mu\right)^{1/2}}{\left(\int_S\sigma^4\lambda^4 d\mu\right)^{1/2}}\leq C_2\rho.
\end{displaymath}
Zauważmy ponadto, że dla dowolnego $\lambda\in \Lambda$ zachodzi
\begin{displaymath}
\Psi(\lambda,\theta)=\int_S(1-\lambda)^2\theta ^2 d\mu+\epsilon^2\int_S\sigma\lambda^2 d\mu\geq \epsilon^2\int_S\sigma\lambda^2 d\mu.
\end{displaymath}
Skąd dostajemy
\begin{displaymath}
\epsilon^2\norm{\sigma^2\lambda^2}_{\infty}\leq C_2^2 \rho\Psi(\lambda,\theta).
\end{displaymath}
Nierówność ta prowadzi nas do oszacowania
\begin{displaymath}
\Delta^{\epsilon}[\lambda]=\epsilon^2L_{\Lambda}\norm{\sigma^2\lambda^2}_{\infty}\leq C_2^2\rho L_{\Lambda}\Psi(\lambda,\theta).
\end{displaymath}
W dowodzie twierdzenia \ref{glowny3} uzyskaliśmy nierówność następującej postaci
\begin{displaymath}
\begin{split}
(1-4B^{-1})\mathbb{E}_{\theta}\Psi(\lambda^*,\theta)&\leq (1+4B^{-1})\Psi(\tilde{\lambda},\theta) \\
&+CBC''\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]+CBC''\Delta^{\epsilon}[\tilde{\lambda}].
\end{split}
\end{displaymath}
Wykorzystując wyprowadzone oszacowanie mamy 
\begin{displaymath}
\begin{split}
(1-4B^{-1})\mathbb{E}_{\theta}\Psi(\lambda^*,\theta)&\leq (1+4B^{-1})\Psi(\tilde{\lambda},\theta)+CBC_2^2C''\rho L_{\Lambda}\Psi(\tilde{\lambda},\theta)\\
&+CBC_2^2C''\rho L_{\Lambda}\mathbb{E}_{\theta}\Psi(\lambda^*,\theta),
\end{split}
\end{displaymath}
co prowadzi do
\begin{displaymath}
\mathbb{E}_{\theta}\Psi(\lambda^*,\theta)\leq\frac{1+4B^{-1}+CBC_2^2C''\rho L_{\Lambda}}{1-4B^{-1}-CBC_2^2C''\rho L_{\Lambda}}\Psi(\tilde{\lambda},\theta).
\end{displaymath}
Ponownie korzystając z lematu \ref{lem6} dostajemy
\begin{displaymath}
\begin{split}
\frac{1}{C'}\mathbb{E}_{\theta}||\theta^*-\theta||^2&\leq (1+4B^{-1}C'')\mathbb{E}_{\theta}\Psi(\lambda^*,\theta)+CB\norm{T}^2\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda^*]\\
&\leq (1+4B^{-1}C''+CB\norm{T}^2C_2^2\rho L_{\Lambda})\Psi(\tilde{\lambda},\theta).
\end{split}
\end{displaymath}
Łącząc te dwie nierówności mamy
\begin{displaymath}
\frac{1}{C'}\mathbb{E}_{\theta}||\theta^*-\theta||^2\leq \frac{\left(1+4B^{-1}C''+CBC_2^2C''\rho L_{\Lambda}\right)^2}{1-4B^{-1}C''-CBC_2^2C''\rho L_{\Lambda}}\Psi(\tilde{\lambda},\theta).
\end{displaymath}
Zauważmy teraz, że istnieje taka stała $\gamma_4>0$, że jeśli tylko zachodzi $C_2^2C''\rho L_{\Lambda}\leq \gamma_4$, to wybór $B$ jako $(C_2^2\rho L_{\Lambda})^{-1/2}$ prowadzi do nierówności $4B^{-1}C''+CBC_2^2C''\rho L_{\Lambda}\leq 1/2$, a stąd $1-4B^{-1}-CBC_2^2C''\rho L_{\Lambda}\geq 1/2$, czyli jest odcięte od zera. Wtedy wybór $B=(C_2^2\rho L_{\Lambda})^{-1/2}$ prowadzi do nierówności
\begin{displaymath}
\frac{1}{C'}\mathbb{E}_{\theta}||\theta^*-\theta||^2\leq \frac{(1+CC''\sqrt{\rho L_{\Lambda}})^2}{1-CC''\sqrt{\rho L_{\Lambda}}}\Psi(\tilde{\lambda},\theta),
\end{displaymath}
która z kolei prowadzi nas do postulowanej na początku nierówności
\begin{displaymath}
\frac{1}{C'}\mathbb{E}_{\theta}||\theta^*-\theta||^2\leq (1+\gamma_3C''\sqrt{\rho L_{\Lambda}})\Psi(\tilde{\lambda},\theta),
\end{displaymath}
która kończy dowód twierdzenia \ref{glowny4}.
\end{proof}


\begin{wn}
Niech będzie spełnione założenie \ref{assbig}, ponadto niech zachodzi\\ $\lim_{\epsilon\to 0}\rho\ln(NS)=0$. Wtedy istnieją stałe $\mathbb{C}_2>0,\mathbb{C}_3>0$ zależące tylko od stałej $C_2$ i operatora $T=UA^*$, takie że dla $\rho\ln(NS)<\mathbb{C}_2$ i dla dowolnego $\theta\in L_2(S,\mathbb{S},\mu)$ zachodzi
\begin{displaymath}
\mathbb{E}_{\theta}||\theta^*-\theta||^2\leq \max\{1,C_2\}\left(1+\mathbb{C}_3\max\{1,\norm{T}^2\}\sqrt{\rho \ln(NS)}\right)\min_{\lambda\in \Lambda}\Psi(\lambda,\theta),
\end{displaymath}
gdzie estymator $\tilde{\theta}$ i minimum rozumiane są jak poprzednio.
\end{wn}








\chapter{Przykład}\label{przyklad}
W tym rozdziale rozważymy problem dekonwolucji na prostej rzeczywistej. Pokażemy, że w tym przypadku można tak zdefiniować problem, by spełniał on narzucone warunki (\ref{warunki}) oraz korzystając z nierówności wyroczni wykazanych w twierdzeniach \ref{glowny3} i \ref{glowny4} udowodnimy, że estymator wybierany zaproponowaną metodą (\ref{estimator1}) może osiągać optymalne tempo zbieżności.\\
\indent Naszym celem jest estymacja gęstości $f$ zmiennej losowej $Z$ przyjmującej wartości na prostej rzeczywistej $\mathbb{R}$. Niech jednak dostępne obserwacje będą próbą prostą z rozkładu zmiennej losowej postaci
\begin{displaymath}
Y=Z+W,
\end{displaymath}
czyli są zaburzone przez pewną zmienną losową $W$. Niech zmienne $X$ i $W$ będą stochastycznie niezależne oraz niech $h$ oznacza gęstość zmiennej $W$. Wtedy gęstość $g$ zmiennej losowej $Y$ ma postać 
\begin{equation}\label{0}
g=\int_{\mathbb{R}}h(\cdot -x)f(x)dx=\colon Kf,
\end{equation}
gdzie $K$ jest operatorem konwolucji na prostej. Zakładać będziemy, że gęstość $h$, a co za tym idzie operator $K$, są znane, $h$ jest całkowalna z kwadratem, dodatnia prawie wszędzie oraz symetryczna względem zera. Niech $\mathcal{F}$ oznacza unitarny operator transformaty Fouriera, który będzie dokładniej opisany poniżej. Operator $K\colon L_2(\mathbb{R}) \to L_2(\mathbb{R})$ nie jest operatorem zwartym, ponieważ operator $K$ może być zwarty wtedy i tylko wtedy, gdy operator $\mathcal{F}K\mathcal{F}^{-1} = M_b$ jest zwarty, gdzie $b = \mathcal{F}h$,  ponieważ $\mathcal{F}$ jest operatorem unitarnym. Zatem operator $K$ jest zwarty wtedy i tylko wtedy, gdy operator mnożenia przez funkcją $b$ jest zwarty. Jednak operator $M_b$ nie jest zwarty, ponieważ można pokazać, że spektrum operatora mnożenia jest równe domknięciu obrazu całej przestrzeni przez funkcję, czyli w rozważanym przypadku będzie to zbiór nieprzeliczalny. Jednak operator zwarty może mieć co najwyżej przeliczalne spektrum. Zatem operator $M_h$ nie jest zwarty, a co za tym idzie również operator $K$.\\
\indent W rozdziale \ref{G2} dalsze rozważania poprzedzone były prekondycjonowaniem, zatem niech 
\begin{displaymath}
q=K^*g = \int_{\mathbb{R}}h(\cdot -x)g(x)dx
\end{displaymath}
z uwagi na fakt, że $h$ jest symetryczną funkcją rzeczywistą. Nieobciążonym estymatorem $q$ jest
\begin{equation}\label{1}
\hat{q}(y)=\frac{1}{n}\sum_{i=1}^nh\left(Y_i-y\right),
\end{equation}
gdzie $n$ jest wielkością próby, ponieważ
\begin{displaymath}
\begin{split}
\mathbb{E}\hat{q}(y)&=\mathbb{E}\frac{1}{n}\sum_{i=1}^nh\left(Y_i-y\right)=\int_{\mathbb{R}}h(z-y)g(z)dz = q(y).
\end{split}
\end{displaymath} 
By wpisać powyższe zagadnienie w ogólną postać problemu odwrotnego (\ref{Af}), potrzeba zdefiniować w odpowiedni sposób szum. W pracy \cite{bissantz}, str. 2621 pokazano, że szum $\tilde{\epsilon}\colon L_2(\mathbb{R})\to L_2(\Omega,\mathcal{F},\mathbb{P})$ zdefiniowany w następujący sposób 
\begin{equation}\label{2}
\forall\ \phi\in L_2(\mathbb{R})\ \langle \tilde{\epsilon},\phi \rangle=\frac{1}{n}\sum_{i=1}^n\phi(Y_i)-\langle g,\phi\rangle.
\end{equation}
pozwala rozważane zagadnienie zapisać w poszukiwanej postaci $\hat{q}= q+ K*\tilde{\epsilon}=K^*f +K^*\tilde{\epsilon}$, ponieważ
\begin{displaymath}
\langle K^*\tilde{\epsilon},\phi\rangle = \frac{1}{n}\sum_{i=1}^n\int_{\mathbb{R}}h(X_i-z)\phi(z)dz-\langle K^*q,\phi\rangle = \langle \hat{q}-q,\phi\rangle
\end{displaymath}
dla dowolnego $\phi \in L_2(\mathbb{R})$. Ponadto pokazano (w nieco ogólniejszej postaci) następujące twierdzenie
\begin{tw}
Niech operator zdefiniowany w (\ref{0}) będzie iniektywny oraz niech $\norm{K}_{2,2}<\infty$, $\norm{K}_{2,\infty}<\infty$, gdzie norma $\norm{K}_{p,q}$ rozumiana jest jako norma operatora $K\colon L_p(\mathbb{R})\to L_q(\mathbb{R})$. Niech ponadto $\hat{q}$ i $\tilde{\epsilon}$ będą zdefiniowane przez (\ref{1}) i (\ref{2}). Oznaczmy $\sigma=n^{-1/2}\left(\norm{g}_{\infty}+\norm{g}_2\right)^{1/2}$. Wtedy szum zdefiniowany jako
\begin{displaymath}
\epsilon=\tilde{\epsilon}/\sigma
\end{displaymath}
spełnia warunki (\ref{warunki}).
\end{tw}
Powyższe twierdzenie pokazuje, że do badanego problemu można zastosować metodologię z rozdziału \ref{G2}. Operatorem unitarnym. gwarantującym w tym przypadku zachodzenie warunku 
\begin{equation}\label{3}
\forall x\in \mathbb{R}\ \pmb{V}ar(UK^*\xi (x))\leq b(x)
\end{equation}
jest operator Fouriera  zdefiniowany jako ciągłe przedłużenie na $L_2(\mathbb{R})$ operatora określonego jako
\begin{displaymath}
(\mathcal{F}f)(x)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}\exp (itx)f(t)dt,
\end{displaymath}
z dziedziną $D(\mathcal{F}= L_1(\mathbb{R})\cap L_2(\mathbb{R})$ (\cite{mair}, str. 1435). Funkcją $b$ jest w tym przypadku kwadrat transformacji Fouriera $(\mathcal{F}h)^2$ funkcji $h$, ponieważ 
\begin{displaymath}
\left(\mathcal{F}K^*K\right)f =\mathcal{F}(h\ast f\ast h)=\mathcal{F}f\cdot \mathcal{F}h\cdot \mathcal{F}h =\left(\mathcal{F}h\right)^2\left(\mathcal{F}f\right),
\end{displaymath}
gdzie $\ast$ oznacza operację splotu.\\
Załóżmy teraz, że istnieją stałe $m,M>0$ takie, że zachodzi 
\begin{displaymath}
mx^{-2a}\leq (\mathcal{F}h)^2(x)\leq Mx^{-2a}.
\end{displaymath}
Wprowadźmy następującą klasę funkcji
\begin{displaymath}
\mathbb{H}_v=\left\{f\in L_2(\mathbb{R})\colon \int_{-\infty}^{\infty}(1+x^2)^v(\mathcal{F}f(x))^2dx<\infty\right\}\subset L_2(\mathbb{R}).
\end{displaymath}
Będziemy zakładać, że poszukiwany element $f\in \Theta_v\subset \mathbb{H}_v$, jednak żeby wskazać konkretne tempo zbieżności zawęzimy $f$ do podmodelu postaci
\begin{displaymath}
\Theta_s=\left\{f\in\Theta_v\colon \int_{-\infty}^{\infty}(1+x^2)^s(\mathcal{F}f(x))^2dx \leq C\right\}
\end{displaymath}
dla $s>v$ (\cite{mair}, str. 1427). Wtedy w \cite{mair}, str. 1438 pokazano, że dolne oszacowanie na tempo zbieżności jest postaci
\begin{displaymath}
\inf_{\hat{f}}\sup_{f\in\Theta_s}\ \mathbb{E}\norm{\hat{f}-f}_v^2\geq cn^{-2(s-v)/(2s+5)},
\end{displaymath}
czyli
\begin{displaymath}
\inf_{\hat{f}}\sup_{f\in\Theta_s}\ \Psi(\hat{\lambda},\theta)\geq cn^{-2(s-v)/(2s+5)},
\end{displaymath}
gdzie norma $\norm{\cdot}_v$ rozumiana jest jako norma implikowana przez iloczyn skalarny określony 
\begin{displaymath}
\langle f,g\rangle_v=\langle L^vf,L^vg\rangle
\end{displaymath}
z operatorem $L$ zdefiniowanym jako 
\begin{displaymath}
L=\mathcal{F}^{-1}M_l\mathcal{F},\ l(x)=(1+x^2)^{1/2}.
\end{displaymath}
\indent Rozważmy teraz rodzinę $\Lambda$ estymatorów rzutowych postaci $\lambda^i(x)=\pmb{1}\{|x|\leq w_i\},$ $w_i\in \{w_1,w_2,\dots, w_N\}$, $1\leq w_1<w_2<\dots w_N$ (\cite{cavalier2}, str. 399). Wtedy założenia (\ref{assbig}) są spełnione oraz możemy dokładniej oszacować poszczególne składniki występujące w twierdzeniu \ref{glowny3}. Przez $C$ będziemy rozumieć dodatnią stałą niezależącą od $\lambda,\theta	,\epsilon$
\begin{displaymath}
S=\frac{\max_{\lambda\in \Lambda}\norm{\sigma^2\lambda^2}_{\infty}}{\min_{\lambda\in \Lambda}\norm{\sigma^2\lambda^2}_{\infty}}\leq C\left(\frac{w_N}{w_1}\right)^{4a}
\end{displaymath}
\begin{displaymath}
\rho=\max_{\lambda\in \Lambda}\rho(\lambda)=\max_{\lambda\in \Lambda}\frac{\norm{\sigma\lambda}_{\infty}}{\left(\int_S\sigma^4\lambda^4d\mu\right)^{1/2}}\leq C\max_{\lambda\in \Lambda}w_{\lambda}^{-1/4}=Cw_1^{-1/4}
\end{displaymath}
\begin{displaymath}
M=\sum_{\lambda\in \Lambda}\exp(-1/\rho(\lambda))\leq N
\end{displaymath}
\begin{displaymath}
L_{\Lambda}=\ln(NS)+\rho^2\ln(MS)\leq C\ln\left(\frac{Nw_N}{w_1}\right)+Cw_1^{-1/2}\ln\left(\frac{Nw_N}{w_1}\right)\leq C\ln\left(\frac{Nw_N}{w_1}\right)
\end{displaymath}
\begin{displaymath}
\begin{split}
\omega(x)&=\max_{\lambda\in \Lambda}\norm{\sigma^2\lambda^2\pmb{1}\left\{\int_S\sigma\lambda^2d\mu\leq x\norm{\sigma^2\lambda^2}_{\infty}\right\}}_{\infty}\\ 
&\leq \max_{\lambda\in \Lambda}\norm{\sigma^2\lambda^2\pmb{1}\left\{\int_S\sigma^2\lambda d\mu\leq \frac{x}{C_2}\norm{\sigma^2\lambda^2}_{\infty}\right\}}_{\infty}\\
&\leq C\norm{s^{4a}\pmb{1}\left\{s^{4a+1}\leq Cxs^{4a}\right\}}_{\infty}\leq Cx^{4a}
\end{split}
\end{displaymath}
Załóżmy teraz, że $N\sim n^d$, $w_N/w_1\sim n^e$ oraz niech $\ln(n)/w_1\to 0$, gdy $n\to \infty$, gdzie przez $a\sim b$ rozumiemy, że $\lim_{n\to \infty}a/b=C>0$ (\cite{cavalier2}, str. 399). Ponadto niech $\epsilon\sim n^{-1/2}$. Wtedy z twierdzenia \ref{glowny3} dostajemy
\begin{displaymath}
\begin{split}
\sup_{f\in\Theta_s}\ \mathbb{E}\norm{f^*-f}_v^2&\leq \max \{1,C_2\}(1+\gamma_1B^{-1}\max\{1,\norm{A}^2\})\min_{\lambda\in \Lambda}\sup_{f\in\Theta_s}\Psi(\lambda,\theta)\\
& +\max \{1,C_2\}\gamma_2B\max \{1,\norm{A}^2\}\epsilon^2L_{\Lambda}\omega(B^2L_{\Lambda})\\
&\leq \max \{1,C_2\}\left((1+\gamma_3B^{-1})\min_{\lambda\in \Lambda}\sup_{f\in\Theta_s}\Psi(\lambda,\theta)\right)+CBn^{-1}\left(\ln n\right)^{4a+1}.
\end{split}
\end{displaymath}
Zauważmy, że człon $CBn^{-1}\left(\ln n\right)^{4a+1}$ jest zaniedbywalny przy $cn^{-2(s-v)/(2s+5)}$ dla $s>v$.
Niech teraz $B=\ln n$, wtedy powyższa nierówność redukuje się do postaci
\begin{displaymath}
\sup_{f\in\Theta_s}\ \mathbb{E}\norm{f^*-f}_v^2\leq C(1+o(1))\min_{\lambda\in \Lambda}\sup_{f\in\Theta_s}\Psi(\lambda,\theta).
\end{displaymath}
Zatem jeżeli w rodzinie $\Lambda$ istnieje estymator dla którego $\sup_{f\in\Theta_s}\Psi(\lambda,\theta)=O(n^{-2(s-v)/(2s+5)})$, to wtedy także 
\begin{displaymath}
\sup_{f\in\Theta_s}\ \mathbb{E}\norm{f^*-f}_v^2=O(n^{-2(s-v)/(2s+5)}).
\end{displaymath}

\chapter{Lematy pomocnicze}\label{lematy}
W rozdziale tym podamy dowody pomocniczych lematów użytych w pracy.
\begin{lm}\label{pierwsza}
Niech $\{X_i\}_{i=1}^{\infty}$ będzie ciągiem niezależnych zmiennych losowych o rozkładach odpowiednio $X_i\sim \mathcal{N}(0,s_i^2)$ i niech $\sum_{i=1}^{\infty}s_i^2=S<\infty$. Wtedy istnieje zmienna losowa $X\sim\mathcal{N}(0,S)$ taka, że $L_2- \lim_{n\to \infty}\sum_{i=1}^nX_i=X$.
\end{lm}
\begin{proof}
Przestrzeń $L_2(\Omega,\mathcal{F},\mathbb{P})$ jest przestrzenią zupełną, więc wystarczy pokazać, że ciąg $\left\{\sum_{i=1}^{\infty}X_i\right\}_{n=1}^{\infty}$ jest ciągiem Cauchy'ego i graniczna zmienna losowa ma odpowiedni rozkład. Niech $n>m$, wtedy
\begin{displaymath}
0\leq \norm{\sum_{i=1}^{n}X_i-\sum_{i=1}^{m}X_i}_2^2=\norm{\sum_{i=m+1}^{n}X_i}_2^2\leq \sum_{m+1}^ns_i^2\to 0,\ n,m\to \infty,
\end{displaymath}
bo $\sum_{m+1}^nX_i\sim \mathcal{N}\left(0,\sum_{m+1}^ns_i^2\right)$ i szereg $\sum_{i=1}^{\infty}s_i^2$ jest zbieżny. Zatem ciąg $\{X_i\}_{i=1}^{\infty}$ jest ciągiem Cauchy'ego, a zatem istnieje zmienna losowa $X$ taka, że $L_2- \lim_{n\to \infty}\sum_{i=1}^nX_i=X$ oraz z uwagi na niezależność zmiennych $X_i$, $\sum_{i=1}^nX_i\sim\mathcal{N}(0,\sum_{i=1}^ns_i^2)$, więc $\sum_{i=1}^nX_i\stackrel{d}{\to}\mathcal{N}\left(0,S\right)$, bo zbieżność w normie $L_2$ implikuje słabą zbieżność.
\end{proof}
\begin{lm}\label{druga}
Niech $\{X_i\}_{i=1}^{\infty}$ będzie ciągiem niezależnych zmiennych losowych o rozkładach odpowiednio $X_i\sim \mathcal{N}(\theta_i,\sigma_i^2)$ oraz niech szeregi $\sum_{i=1}^{\infty}\sigma_i^2$ i $\sum_{i=1}^{\infty}\theta_i^2$ będą zbieżne. Wtedy istnieje zmienna losowa $Y\in L_2(\Omega,\mathcal{F},\mathbb{P})$ taka, że $L_2- \lim_{n\to \infty}\sum_{i=1}^nX_i^2=Y$.
\end{lm}
\begin{proof}
Przestrzeń $L_2(\Omega,\mathcal{F},\mathbb{P})$ jest przestrzenią zupełną, więc wystarczy pokazać, że ciąg $\left\{\sum_{i=1}^{n}X_i^2\right\}_{n=1}^{\infty}$ jest ciągiem Cauchy'ego. Niech $n>m$, wtedy mamy
\begin{displaymath}
0\leq \norm{\sum_{i=1}^{n}X_i^2-\sum_{i=1}^{m}X_i^2}_2=\norm{\sum_{i=m+1}^{n}X_i^2}_2\leq \sum_{m+1}^n\norm{X_i^2}_2.
\end{displaymath}
Zauważmy teraz, że $\norm{X_i^2}_2^2=\mathbb{E}X_i^4=\mathbb{E}\left((X_i-\mathbb{E}X_i)+\mathbb{E}X_i\right)^4=3\sigma_i^4+6\theta_i^2\sigma_i^2+\theta_i^4\leq (\theta_i^2+3\sigma_i^2)^2$, więc $\norm{X_i^2}\leq \theta_i^2+3\sigma_i^2$. Założenie o zbieżności szeregów $\sum_{i=1}^{\infty}\sigma_i^2$ i $\sum_{i=1}^{\infty}\theta_i^2$ implikuje, że ciąg $\left\{\sum_{i=1}^{\infty}X_i^2\right\}_{n=1}^{\infty}$ jest ciągiem Cauchy'ego, co na mocy zupełności $L_2(\Omega,\mathcal{F},\mathbb{P})$ implikuje istnienie żądanej zmiennej losowej $Y$.
\end{proof}
\begin{lm}\label{szacowanie}
Niech $\eta\colon H\to L_2(T,\mathbb{T},\tau)$ będzie gaussowskim szumem o skończonym silnym drugim momencie oraz niech $v$ będzie pewnym elementem z przestrzeni $H$ takim, że $\norm{v}_{\infty}<\infty$. Załóżmy, że zachodzi $\langle \eta, v\rangle\sim \mathcal{N}(0,1)$. Wtedy dla dowolnego $t>0$ zachodzi
\begin{displaymath}
\ln\mathbb{E}\exp\left(t\langle \eta^2 -1,v\rangle\right)\leq \frac{t^2\norm{v}^2_2}{1-t\norm{v}_{\infty}}.
\end{displaymath}
\end{lm}
\begin{proof}
Zachodzenie powyższego lematu pokazano, gdy $v$ jest funkcją prostą w \cite{laurent}, str. 1325. Jako że $\eta$ ma skończone drugie momenty i $v$ jest ograniczona, możemy zastosować metodę komplikacji by uzyskać żądaną tezę.
\end{proof}
Przejdziemy teraz do dowodów lematów użytych do dowodzenia głównych rezultatów pracy.
\begin{proof} [Dowód lematu \ref{lem1}]
Na początek zauważmy pewien użyteczny fakt. Niech $X\sim \mathcal{N}(0,1)$ będzie zmienną losową. Wtedy zachodzi oszacowanie
\begin{displaymath}
\mathbb{E}X^2\pmb{1}_{\{|X|>a\}}\leq \frac{2}{\sqrt{2\pi}}(a+a^{-1})e^{-a^2/2}\ \forall_{a>0}.
\end{displaymath}
Istotnie, możemy napisać, że
\begin{displaymath}
\mathbb{E}X^2\pmb{1}_{\{|X|>a\}}=2\int_{a}^{\infty}\frac{1}{\sqrt{2\pi}}x^2e^{-x^2/2}dx=\frac{2}{\sqrt{2\pi}}\left[-xe^{-x^2/2}|_a^{\infty}+\int_a^{\infty}e^{-x^2/2}dx\right]
\end{displaymath}
\begin{displaymath}
\leq \frac{2}{\sqrt{2\pi}}\left[ae^{-a^2/2}+\frac{1}{a}e^{-a^2/2}\right],
\end{displaymath}
gdzie skorzystaliśmy z nierówności $1-\Phi(x)\leq x^{-1}\phi(x)$ zachodzącej dla dowolnego $x>0$, gdzie $\Phi,\phi$ oznaczają odpowiednio dystrybuantę i gęstość standardowego rozkładu normalnego (\cite{feller}, str. 175).
Przejdziemy teraz do dowodu właściwej części lematu.\\
Zauważmy, że jeżeli $\norm{v}=0$, to $\mathbb{E}\left|\sum_{k=1}^{\infty}v_k\xi_k\right|= 0$ oraz $\sqrt{2\ln (NK)}\mathbb{E}\norm{v}\\+\sqrt{2\ln (NK)}\left(\mathbb{E}\norm{v}^2\cdot \frac{1}{K}\right)^{1/2}= 0$ dla dowolnych $N,K>0$, czyli teza lematu jest spełniona. Możemy zatem założyć, że $\norm{v}\neq 0$. Oznaczmy przez $\zeta_v=\frac{1}{\norm{v}}\sum_{k=1}^{\infty}v_k\xi_k$. Szereg ten jest zbieżny w normie $L_2$, gdyż ciąg sum częściowych szeregu $\sum_{k=1}^{\infty}v_k\xi_k$ jest ciągiem Cauchy'ego w przestrzeni zupełnej, ponieważ gdy $n>m>0$, to
\begin{displaymath}
\begin{split}
&\norm{\sum_{k=1}^{n}v_k\xi_k-\sum_{k=1}^{m}v_k\xi_k}_2^2=\norm{\sum_{k=m+1}^{n}v_k\xi_k}_2^2=\sum_{i=1}^N\mathbb{E}\left[\pmb{1}_{\{v=v^i\}}\left(\sum_{k=m+1}^{n}v_k\xi_k\right)^2\right]\\
&=\sum_{i=1}^N\mathbb{E}\left[\pmb{1}_{\{v=v^i\}}\left(\sum_{k=m+1}^{n}v^i_k\xi_k\right)^2\right]\leq \sum_{i=1}^N\mathbb{E}\left(\sum_{k=m+1}^{n}v^i_k\xi_k\right)^2\to 0,\ gdy\ n,m\to\infty,
\end{split}
\end{displaymath}
z uwagi na lemat \ref{pierwsza} i fakt, że dla dowolnego $1\leq i\leq N$ $v^i\in l^2$ i szereg $\sum_{k=1}^{\infty}v_k^2$ jest zbieżny także w normie $L_2$.

Zachodzi oczywiście, że $|\zeta_v|\norm{v}=\left|\sum_{k=1}^{\infty}v_k\xi_k\right|$. Możemy zatem zapisać, że
\begin{displaymath}
\begin{split}
\mathbb{E}\left|\sum_{k=1}^{\infty}v_k\xi_k\right|&=\mathbb{E}|\zeta_v|\norm{v}\leq \mathbb{E}\norm{v}\max_{u\in V}|\zeta_u|
\mathbb{E}\norm{v}\max_{u\in V}|\zeta_u|\pmb{1}_{\{\max_{u\in V}|\zeta_u|\leq \sqrt{2\ln (NK)}\}}\\
&\hspace{4mm}+\mathbb{E}\norm{v}\max_{u\in V}|\zeta_u|\pmb{1}_{\{\max_{u\in V}|\zeta_u|> \sqrt{2\ln (NK)}\}}
\leq \sqrt{2\ln (NK)}\mathbb{E}\norm{v}\\
&\hspace{4mm}+\mathbb{E}\norm{v}\max_{u\in V}|\zeta_u|\pmb{1}_{\{\max_{u\in V}|\zeta_u|> \sqrt{2\ln (NK)}\}}\\
&\leq \sqrt{2\ln (NK)}\mathbb{E}\norm{v}+\left(\mathbb{E}\norm{v}^2\right)^{1/2}\left(\mathbb{E}\max_{u\in V}|\zeta_u|^2\pmb{1}_{\{\max_{u\in V}|\zeta_u|> \sqrt{2\ln (NK)}\}}\right)^{1/2},
\end{split}
\end{displaymath}
gdzie w ostatniej nierówności skorzystaliśmy z nierówności Cauchy'ego--Schwarza.
Rozważmy teraz funkcję $F(t)=t^2\pmb{1}_{\{t> \sqrt{2\ln (NK)}\}}$. Z uwagi na monotoniczność funkcji kwadratowej dla dodatnich argumentów zachodzi
\begin{displaymath}
F(\max_{u\in V}|\zeta_u|)= \max_{u\in V}F(|\zeta_u|)\leq \sum_{u\in V}F(|\zeta_u|).
\end{displaymath}
Ponownie na mocy lematu \ref{pierwsza} i niezależności zmiennych losowych $\{\xi_i\}$ mamy, że zmienne losowe $\zeta_u$ mają takie same rozkłady normalne $\mathcal{N}(0,1)$ dla każdego $u\in V$. Zatem możemy napisać
\begin{displaymath}
\begin{split}
\mathbb{E}\left|\sum_{k=1}^{\infty}v_k\xi_k\right|&
\leq \sqrt{2\ln (NK)}\mathbb{E}\norm{v}+\left(\mathbb{E}\norm{v}^2\right)^{1/2}\left(\sum_{u\in V}\mathbb{E}|\zeta_u|^2\pmb{1}_{\{|\zeta_u|> \sqrt{2\ln (NK)}\}}\right)^{1/2}\\
&=\sqrt{2\ln (NK)}\mathbb{E}\norm{v}+\left(\mathbb{E}\norm{v}^2\right)^{1/2}\left(N\mathbb{E}|\zeta_v^1|^2\pmb{1}_{\{|\zeta_v^1|> \sqrt{2\ln (NK)}\}}\right)^{1/2},
\end{split}
\end{displaymath}
gdzie $v^1$ jest dowolnym ustalonym elementem $V$.
Następnie korzystając z oszacowania pokazanego na początku dowodu z $a=\sqrt{2\ln (NK)}$ dostajemy
\begin{displaymath}
N\mathbb{E}|\zeta_v^1|^2\pmb{1}_{\{|\zeta_v^1|> \sqrt{2\ln (NK)}\}}\leq \frac{2N}{\sqrt{2\pi}}\left(\sqrt{2\ln (NK)}+\frac{1}{\sqrt{2\ln (NK)}}\right)\frac{1}{NK}
\end{displaymath}
\begin{displaymath}
\leq  \frac{1}{K}\left(\sqrt{2\ln (NK)}+\frac{1}{\sqrt{2\ln (NK)}}\right)\leq  \frac{1}{K}\cdot 2\ln (NK),
\end{displaymath}
o ile tylko zachodzi, że $NK\geq 2$. Przy założeniu na $K$ jest to spełnione dla każdego nietrywialnego problemu z licznością $V>1$. Łącząc te nierówności dostajemy, że
\begin{displaymath}
\sqrt{2\ln (NK)}\mathbb{E}\norm{v}+\left(\mathbb{E}\norm{v}^2\right)^{1/2}\left(N\mathbb{E}|\zeta_v^1|^2\pmb{1}_{\{|\zeta_v^1|> \sqrt{2\ln (NK)}\}}\right)^{1/2}
\end{displaymath}
\begin{displaymath}
\leq \sqrt{2\ln (NK)}\mathbb{E}\norm{v}+\sqrt{2\ln (NK)}\left(\mathbb{E}\norm{v}^2\cdot \frac{1}{K}\right)^{1/2}
\end{displaymath}
co kończy dowód.
\end{proof}


\begin{proof}[Dowód lematu \ref{lem2}]
Zauważmy na początek, że z nierówności Markowa dostajemy, że dla dowolnego $t>0$ zachodzi, że $P(X>\epsilon)\leq e^{-t\epsilon}\mathbb{E}e^{tX}$. Policzymy pomocniczo następującą wartość oczekiwaną, dla dowolnego $a\in (0,1/2)$
\begin{displaymath}
\mathbb{E}\exp (a\xi_i^2)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{ax^2}e^{-x^2/2}dx=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\frac{x^2}{2}(1-2a)}dx=\sqrt{\frac{1}{1-2a}}.
\end{displaymath}
Niech teraz $\eta_v=\frac{1}{\sqrt{2}\norm{v}}\sum_{i=1}^{\infty}v_i(\xi_i^2-1)$. Szereg ten jest zbieżny w normie $L_2$, gdyż ciąg sum częściowych szeregu $\sum_{i=1}^{\infty}v_i(\xi^2_i-1)$ jest ciągiem Cauchy'ego w przestrzeni zupełnej, ponieważ gdy $n>m>0$, to
\begin{displaymath}
\begin{split}
&\norm{\sum_{i=1}^{n}v_i(\xi^2_i-1)-\sum_{i=1}^{m}v_i(\xi^2_i-1)}_2^2
=\sum_{k=1}^N\mathbb{E}\left[\pmb{1}_{\{v=v^k\}}\left(\sum_{i=m+1}^{n}v_i(\xi^2_i-1)\right)^2\right]\\
&=\sum_{k=1}^N\mathbb{E}\left[\pmb{1}_{\{v=v^k\}}\left(\sum_{i=m+1}^{n}v^k_i(\xi^2_i-1)\right)^2\right]\leq \sum_{k=1}^N\mathbb{E}\left(\sum_{i=m+1}^{n}v^k_i(\xi^2_i-1)\right)^2\stackrel{n,m\to \infty}{\to} 0
\end{split}
\end{displaymath}
korzystając z lematu \ref{druga} i faktu, że dla dowolnego $1\leq k\leq N$ $v^k\in l^2$ i szereg $\sum_{k=1}^{\infty}v_k^2$ jest zbieżny w normie $L_2$. 
 Korzystając z powyższych faktów możemy napisać dla dowolnego $t>0$ i dla ustalonego $u\in V$
\begin{displaymath}
\begin{split}
P(\eta_u>x)&\leq \exp(-tx)\mathbb{E}\exp(t\eta_u)\\
&=\exp(-tx)\mathbb{E}\exp\left(t\frac{1}{\sqrt{2}\norm{u}}\sum_{i=1}^{\infty}u_i(\xi_i^2-1)\right)\\
&=\exp(-tx)\prod_{i=1}^{\infty}\mathbb{E}\exp\left(t\frac{1}{\sqrt{2}\norm{u}}u_i(\xi_i^2-1)\right)\\
&=\exp(-tx)\prod_{i=1}^{\infty}\exp\left(-\frac{tu_i}{\sqrt{2}\norm{u}}\right)\mathbb{E}\exp\left(\frac{t}{\sqrt{2}\norm{u}}u_i\xi_i^2\right)\\
&=\exp(-tx)\prod_{i=1}^{\infty}\exp\left(-\frac{tu_i}{\sqrt{2}\norm{u}}\right)\sqrt{\frac{\norm{u}}{\norm{u}-\sqrt{2}tu_i}}\\
&=\exp(-tx)\prod_{i=1}^{\infty}\exp\left(-\frac{tu_i}{\sqrt{2}\norm{u}}-\frac{1}{2}\ln\left(1-\frac{\sqrt{2}tu_i}{\norm{u}}\right)\right).
\end{split}
\end{displaymath}
W powyższym wyrażeniu skorzystać będziemy chcieli z następującego rozwinięcia $-\ln (1-x)=\sum_{k=1}^{\infty}\frac{x^k}{k}$ dla $|x|<1$. Zatem musimy założyć dodatkowo, że $t<\frac{1}{\sqrt{2}m(u)}$. Stąd
\begin{displaymath}
\begin{split}
\exp(-tx)&\prod_{i=1}^{\infty}\exp\left(-\frac{tu_i}{\sqrt{2}\norm{u}}-\frac{1}{2}\ln\left(1-\frac{\sqrt{2}tu_i}{\norm{u}}\right)\right)\\
&=\exp(-tx)\prod_{i=1}^{\infty}\exp\left(-\frac{tu_i}{\sqrt{2}\norm{u}}+\frac{1}{2}\sum_{k=1}^{\infty}\frac{1}{k}\left(\frac{\sqrt{2}tu_i}{\norm{u}}\right)^k\right)\\
&=\exp(-tx)\exp \left(\sum_{i=1}^{\infty}\sum_{k=2}^{\infty}\frac{1}{2k}\left(\frac{\sqrt{2}tu_i}{\norm{u}}\right)^k\right)\\
&=\exp(-tx)\exp \left(\sum_{k=2}^{\infty}\sum_{i=1}^{\infty}\frac{1}{2k}\left(\frac{\sqrt{2}tu_i}{\norm{u}}\right)^k\right)\\
&=\exp(-tx)\exp \left(\sum_{k=2}^{\infty}\frac{(\sqrt{2}t)^k}{2k}\sum_{i=1}^{\infty}\left(\frac{u_i}{\norm{u}}\right)^2\left(\frac{u_i}{\norm{u}}\right)^{k-2}\right)\\
&\leq \exp(-tx)\exp \left(\sum_{k=2}^{\infty}\frac{(\sqrt{2}t)^k}{2k}(m(u))^{k-2}\frac{\sum_{i=1}^{\infty}u_i^2}{\norm{u}^2}\right)\\
&=\exp(-tx)\exp \left(\frac{1}{2m^2(u)}\sum_{k=2}^{\infty}\frac{1}{k}\left(\sqrt{2}tm(u)\right)^k\right)\\
&=\exp(-tx)\exp \left(-\frac{1}{2m^2(u)}\ln \left(1-\sqrt{2}tm(u)\right)-\frac{t}{\sqrt{2}m(u)}\right).
\end{split}
\end{displaymath}
Minimalizując ostatnie wyrażenie względem $t$ dostajemy, że w punkcie $t=\frac{1}{\sqrt{2}m(u)}-\frac{1}{2m^2(u)x+\sqrt{2}m(u)}$ osiągane jest minimum o wartości\\ $\exp\left(\frac{1}{2m^2(u)}\ln \left(1+\sqrt{2}m(u)x\right)-\frac{x}{\sqrt{2}m(u)}\right)$. Możemy zatem zapisać, że
\begin{displaymath}
\begin{split}
P(\eta_u>x)&\leq \exp\left(\frac{1}{2m^2(u)}\ln \left(1+\sqrt{2}m(u)x\right)-\frac{x}{\sqrt{2}m(u)}\right)\\
&=\exp\left(\frac{1}{2m^2(u)}\left(\ln \left(1+\sqrt{2}m(u)x\right)-\sqrt{2}m(u)x\right)\right).
\end{split}
\end{displaymath}
Zauważmy następnie, że zachodzi następująca zależność
\begin{displaymath}
\ln(1+z)-z=z\int_0^1\left(-\frac{tz}{1+tz}\right)dt\leq -\int_0^1\frac{tz^2}{1+z}dt=-\frac{z^2}{2(1+z)}.
\end{displaymath}Zatem powyższe oszacowanie sprowadza się do postaci 
\begin{displaymath}
P(\eta_u>x)\leq \exp\left(-\frac{x^2}{2(1+\sqrt{2}m(u)x)}\right).
\end{displaymath}
Zauważmy, że zachodzi również $P(\eta_u <-x)=P(-\eta_u>x)=P(\eta_{-u}>x)$ i powyższe rozumowanie przenosi się na ten przypadek, a stąd dostajemy oszacowanie 
\begin{displaymath}
P(|\eta_u|>x)\leq 2\exp\left(-\frac{x^2}{2(1+\sqrt{2}m(u)x)}\right).
\end{displaymath}
Wyrażenie $-\frac{x^2}{2(1+\sqrt{2}m(u)x)}$ możemy ograniczyć w następujący sposób
\begin{displaymath}
-\frac{x^2}{2(1+\sqrt{2}m(u)x)}\leq \left\{{-\frac{x^2}{4},\ \sqrt{2}m(u)x<1}\atop{-\frac{x}{\sqrt{32}m(u)},\ \sqrt{2}m(u)x\geq  1}\right. .
\end{displaymath}
Zauważmy następnie, że dla nieujemnej zmiennej losowej $X$ zachodzi, że $\mathbb{E}X^2=2\int_0^{\infty}tP(X>t)dt$. Zatem dla dowolnego $ Q>0$ mamy, że
\begin{displaymath}
\begin{split}
\mathbb{E}\eta_u^2\pmb{1}\{|\eta_u|>Q\}&=2\int_Q^{\infty}tP(|\eta_u|>t)dt\leq 4\int_Q^{\infty}t\exp\left(-\frac{t^2}{2(1+\sqrt{2}m(u)t)}\right)dt\\
&\leq 4\int_Q^{\frac{1}{\sqrt{2}m(u)}}t\exp\left(-\frac{t^2}{4}\right)dt+4\int_Q^{\infty}t\exp \left(\frac{-t}{\sqrt{32}m(u)}\right)dt\\
&\leq C\exp\left(-\frac{Q^2}{4}\right)+CQ\exp\left(-\frac{Q}{\sqrt{32}m(u)}\right),
\end{split}
\end{displaymath}
gdy $Q\leq \frac{1}{\sqrt{2}m(u)}$. Natomiast gdy $Q>\frac{1}{\sqrt{2}m(u)}$ całkę $4\int_Q^{\infty}t\exp\left(-\frac{t^2}{2(1+\sqrt{2}m(u)t)}\right)dt$ można oszacować przez $CQ\exp\left(-\frac{Q}{\sqrt{32}m(u)}\right)$, co z uwagi na to, że $C\exp\left(-\frac{Q^2}{4}\right)\geq 0$ prowadzi do tego samego oszacowania.
Następnie możemy zapisać, że
\begin{displaymath}
\sum_{u\in V}\exp\left(-\frac{Q}{\sqrt{32}m(u)}\right)=\sum_{u\in V}\exp\left(-\frac{q}{m(u)}\right)\exp \left(-\frac{Q/\sqrt{32}-q}{m(u)}\right)
\end{displaymath}
\begin{displaymath}
\leq M(q)\exp \left(-\frac{Q/\sqrt{32}-q}{m_V}\right),
\end{displaymath}
o ile $Q>q\sqrt{32}$. Będziemy teraz postępować analogicznie jak w dowodzie poprzedniego lematu dla dowolnego $Q>q\sqrt{32}$.
\begin{displaymath}
\begin{split}
\mathbb{E}&\left|\sum_{i=1}^{\infty}v_i(\xi_i^2-1)\right|=\mathbb{E}\left|\sqrt{2}\norm{v}|\eta_v|\right|\leq \sqrt{2}\mathbb{E}\norm{v}\max_{v\in V}|\eta_v|
\leq \sqrt{2}\mathbb{E}\norm{v}\max_{u\in V}|\eta_u|\pmb{1}\{\max_{u\in V}|\eta_u|\leq Q\}\\
&+\sqrt{2}\mathbb{E}\norm{v}\max_{u\in V}|\eta_u|\pmb{1}\{\max_{u\in V}|\eta_u|> Q\}
\leq \sqrt{2}Q\mathbb{E}\norm{v}+\sqrt{2}\mathbb{E}\norm{v}\max_{u\in V}|\eta_u|\pmb{1}\{\max_{u\in V}|\eta_u|> Q\}\\
&\leq \sqrt{2}Q\mathbb{E}\norm{v}+\left(2\mathbb{E}\norm{v}^2\right)^{1/2}\left(\mathbb{E}\max_{u\in V}|\eta_u|^2\pmb{1}\{\max_{u\in V}|\eta_u|> Q\}\right)^{1/2}\\
&\leq \sqrt{2}Q\mathbb{E}\norm{v}+\left(2\mathbb{E}\norm{v}^2\right)^{1/2}\left(\sum_{u\in V}\mathbb{E}|\eta_u|^2\pmb{1}\{\max_{u\in V}|\eta_u|> Q\}\right)^{1/2}\\
&\leq \sqrt{2}Q\mathbb{E}\norm{v}+\left(2\mathbb{E}\norm{v}^2\right)^{1/2}\left(\sum_{u\in V}\left(C\exp\left(-\frac{Q^2}{4}\right)+CQ\exp \left(-\frac{Q}{\sqrt{32}m(u)}\right)\right)\right)^{1/2} \\
&\leq \sqrt{2}Q\mathbb{E}\norm{v}+\left(2\mathbb{E}\norm{v}^2\right)^{1/2}\left(NC\exp\left(-\frac{Q^2}{4}\right)+CQM(q)\exp \left(-\frac{Q/\sqrt{32}-q}{m_V}\right)\right)^{1/2}.
\end{split}
\end{displaymath}
Przyjmując teraz $Q=2\sqrt{\ln (NK)}+\sqrt{32}m_V\ln (M(q)K)+q\sqrt{32}$ dostajemy, że powyższe oszacowanie sprowadza się do następującej postaci
\begin{displaymath}
\left(2\sqrt{2}\sqrt{\ln (NK)}+8m_V\ln (M(q)K)+8q\right)\mathbb{E}\norm{v}+\left(2\mathbb{E}\norm{v}^2\right)^{1/2}\cdot
\end{displaymath}
\begin{displaymath}
\left(NC\exp\left(-\ln (NK)\right)\exp\left(-8m^2_V\ln^2 (M(q)K)-8q-8\sqrt{2}q\sqrt{\ln (NK)}-32qm_V\ln (M(q)K)-\right.\right.
\end{displaymath}
\begin{displaymath}
\left.\left.-8\sqrt{2}\sqrt{\ln (NK)}m_V\ln (M(q)K)\right)+CM(q)\left(2\sqrt{\ln (NK)}+\sqrt{32}m_V\ln (M(q)K)+q\sqrt{32}\right)\right.
\end{displaymath}
\begin{displaymath}
\left. \exp\left(-\ln (M(q)K)\right)\exp \left(-\frac{\sqrt{\ln (NK)}}{2\sqrt{2}m_V}\right)\right)^{1/2}
\end{displaymath}
\begin{displaymath}
\leq D\left(\sqrt{\ln (NK)}+m_V\ln (M(q)K)\right)\left(\mathbb{E}\norm{v}+\left(\frac{1}{K}\mathbb{E}\norm{v}^2\right)^{1/2}\right),
\end{displaymath}
dla pewnej stałej $D$ zależnej tylko od $q$. Nierówność ta kończy dowód lematu.
\end{proof}


\begin{proof}[Dowód lematu \ref{lem3}]
Przypomnijmy, że w naszym modelu (\ref{ssm}) mamy $x_i=\theta_i+\epsilon\sigma_i\xi_i$, a stąd $x_i^2=\theta^2_i+\epsilon^2\sigma^2_i\xi_i^2+2\epsilon\theta_i\sigma_i\xi_i$. Zgodnie z definicją możemy zapisać
\begin{displaymath}
\begin{split}
\mathbb{E}_{\theta}\norm{\hat{\theta}-\theta}^2&=\mathbb{E}_{\theta}\left[\sum_{i=1}^{\infty}\left(\lambda_i(X)x_i-\theta_i\right)^2\right]=\mathbb{E}_{\theta}\left[\sum_{i=1}^{\infty}\lambda_i^2(X)x_i^2+\sum_{i=1}^{\infty}\theta_i^2-2\sum_{i=1}^{\infty}\lambda_i(X)x_i\theta_i\right]\\
&=\mathbb{E}_{\theta}\left[\sum_{i=1}^{\infty}\lambda_i^2(X)\left(\theta^2_i+\epsilon^2\sigma^2_i\xi_i^2+2\epsilon\theta_i\sigma_i\xi_i\right)+\sum_{i=1}^{\infty}\theta_i^2-2\sum_{i=1}^{\infty}\lambda_i(X)\theta_i\left(\theta_i+\epsilon\sigma_i\xi_i\right)\right]\\
&=\mathbb{E}_{\theta}\left[\sum_{i=1}^{\infty}(1-\lambda_i(X))^2\theta_i^2-2\epsilon\sum_{i=1}^{\infty}(1-\lambda_i(X))\theta_i\lambda_i(X)\sigma_i\xi_i\right.\\
&\hspace{4mm}+\epsilon^2\left.\sum_{i=1}^{\infty}\lambda_i^2(X)\sigma_i^2(\xi^2_i-1)+\epsilon^2\sum_{i=1}^{\infty}\lambda_i^2(X)\sigma_i^2\right]\\
&=\mathbb{E}_{\theta}\mathcal{R}(\hat{\theta},\theta)-2\epsilon\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(1-\lambda_i(X))\theta_i\lambda_i(X)\sigma_i\xi_i+\epsilon^2\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\lambda_i^2(X)\sigma_i^2(\xi^2_i-1).
\end{split}
\end{displaymath}
Następnie korzystając z pierwszego z lematów z $K=S$ oszacujemy wyrażenie \\$\epsilon\mathbb{E}_{\theta}\left|\sum_{i=1}^{\infty}(1-\lambda_i(X))\theta_i\lambda_i(X)\sigma_i\xi_i\right|$. Ciągiem $v_i$ jest tym razem ciąg $(1-\lambda_i(X))\theta_i\lambda_i(X)\sigma_i$.
\begin{displaymath}
\begin{split}
\epsilon\mathbb{E}_{\theta}&\left|\sum_{i=1}^{\infty}(1-\lambda_i(X))\theta_i\lambda_i(X)\sigma_i\xi_i\right|\leq
\epsilon\sqrt{2\ln (NS)}\mathbb{E}_{\theta}\left(\sum_{i=1}^{\infty}(1-\lambda_i(X))^2\theta_i^2\lambda_i^2(X)\sigma_i^2\right)^{1/2}\\
&\hspace{4mm}+2\epsilon\sqrt{\ln (NS)}S^{-1/2}\left(\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(1-\lambda_i(X))^2\theta_i^2\lambda_i^2(X)\sigma_i^2\right)^{1/2}\\
&\leq \epsilon\sqrt{2\ln (NS)}\mathbb{E}_{\theta}\sup_i\sigma_i|\lambda_i(X)|\left(\sum_{i=1}^{\infty}(1-\lambda_i(X))^2\theta_i^2\right)^{1/2}\\
&\hspace{4mm}+2\epsilon\sqrt{\ln (NS)}S^{-1/2}\max_{\lambda\in \Lambda}\sup_i\sigma_i|\lambda_i|\left(\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(1-\lambda_i(X))^2\theta_i^2\right)^{1/2}\\
&\leq \frac{1}{2}\epsilon^2B\ln (NS)\mathbb{E}_{\theta}\sup_i\sigma_i^2\lambda_i^2(X)+B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(1-\lambda_i(X))^2\theta_i^2\\
&\hspace{4mm}+\epsilon^2B\ln (NS)\frac{\max_{\lambda\in \Lambda}\sup_i\sigma_i^2\lambda_i^2}{S}+B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(1-\lambda_i(X))^2\theta_i^2,
\end{split}
\end{displaymath}
gdzie skorzystaliśmy z nierówności $2ab\leq Ba^2+B^{-1}b^2$ spełnionej dla dowolnego $B>0$.
Zauważmy, że skoro $S=\frac{\max_{\lambda\in \Lambda}\sup_i\sigma_i^2\lambda_i^2}{\min_{\lambda\in \Lambda}\sup_i\sigma_i^2\lambda_i^2}$ to $\frac{\max_{\lambda\in \Lambda}\sup_i\sigma_i^2\lambda_i^2}{S}=\min_{\lambda\in \Lambda}\sup_i\sigma_i^2\lambda_i^2$, a stąd powyższe wyrażenie redukuje się do postaci
\begin{displaymath}
\begin{split}
2B^{-1}\mathbb{E}_{\theta}&\sum_{i=1}^{\infty}(1-\lambda_i(X))^2\theta_i^2+\frac{1}{2}\epsilon^2B\ln (NS)\mathbb{E}_{\theta}\sup_i\sigma_i^2\lambda_i^2(X)+\epsilon^2B\ln (NS)\min_{\lambda\in \Lambda}\sup_i\sigma_i^2\lambda_i^2\\
&\leq 2B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(1-\lambda_i(X))^2\theta_i^2+\frac{1}{2}B\mathbb{E}_{\theta}\left(\epsilon^2\ln (NS)\sup_i\sigma_i^2\lambda_i^2(X)\right)\\
&\hspace{4mm}+B\mathbb{E}_{\theta}\left(\epsilon^2\ln (NS)\sup_i\sigma_i^2\lambda_i^2(X)\right)\\
&\leq 2B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(1-\lambda_i(X))^2\theta_i^2+\frac{3}{2}B\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda(X)].
\end{split}
\end{displaymath}
Następnie będziemy szacować wyrażenie $\epsilon^2\mathbb{E}_{\theta}\left|\sum_{i=1}^{\infty}\lambda_i^2(X)\sigma_i^2(\xi^2_i-1)\right|$ korzystając z drugiego z lematów z $K=S$, $q=1$ i ciągu $v_i=\lambda_i^2(X)\sigma_i^2$. Ponadto zachodzi 
\begin{displaymath}
m(v)=\sup_i\frac{|v_i|}{\norm{v}}=\sup_i\lambda_i^2(X)\sigma_i^2\left(\sum_{k=1}^{\infty}\lambda_k^4(X)\sigma_k^4\right)^{-1/2}\leq \rho (\lambda(X)),
\end{displaymath}
a stąd $m_V\leq \rho$ oraz $M(1)\leq M$ i możemy szacować wyrażenie $\sqrt{\ln (NS)}+m_V\ln (M(1)S)$ przez $\sqrt{2L_{\Lambda}}$. Możemy zatem zapisać
\begin{displaymath}
\begin{split}
\epsilon^2\mathbb{E}_{\theta}&\left|\sum_{i=1}^{\infty}\lambda_i^2(X)\sigma_i^2(\xi^2_i-1)\right|\\
&\leq \epsilon^2D\left(\sqrt{\ln (NS)}+m_V\ln (M(1)S)\right)\mathbb{E}_{\theta}\left(\sum_{i=1}^{\infty}\lambda_i^4(X)\sigma_i^4\right)^{1/2}\\
&\hspace{4mm}+\epsilon^2D\left(\sqrt{\ln (NS)}+m_V\ln (M(1)S)\right)\left(\frac{1}{S}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\lambda_i^4(X)\sigma_i^4\right)^{1/2}\\
&\leq \epsilon^2D\sqrt{2L_{\Lambda}}\mathbb{E}_{\theta}\left(\sum_{i=1}^{\infty}\lambda_i^4(X)\sigma_i^4\right)^{1/2}+\frac{\epsilon^2D\sqrt{2L_{\Lambda}}}{\sqrt{S}}\left(\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\lambda_i^4(X)\sigma_i^4\right)^{1/2}.
\end{split}
\end{displaymath}
Zauważmy, że zachodzi następujący związek
\begin{displaymath}
\begin{split}
S^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\sigma_i^4\lambda_i^4(X)&\leq \frac{\min_{\lambda\in \Lambda}\sup_i \lambda_i^2\sigma_i^2}{\max_{\lambda\in \Lambda}\sup_i \lambda_i^2\sigma_i^2}\mathbb{E}_{\theta}\sup_i\sigma_i^2\lambda_i^2(X)\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^2(X)\\
&\leq \frac{\min_{\lambda\in \Lambda}\sup_i \lambda_i^2\sigma_i^2}{\max_{\lambda\in \Lambda}\sup_i \lambda_i^2\sigma_i^2}\max_{\lambda\in \Lambda}\sup_i \lambda_i^2\sigma_i^2\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^2(X)\\
&\leq \mathbb{E}_{\theta}\sup_i\sigma_i^2\lambda_i^2(X)\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^2(X).
\end{split}
\end{displaymath}
Korzystając z tego faktu i ponownie z nierówności $2ab\leq Ba^2+B^{-1}b^2$ z $B>0$ dostajemy
\begin{displaymath}
\begin{split}
\epsilon^2D\sqrt{2L_{\Lambda}}&\mathbb{E}_{\theta}\left(\sum_{i=1}^{\infty}\lambda_i^4(X)\sigma_i^4\right)^{1/2}+\frac{\epsilon^2D\sqrt{2L_{\Lambda}}}{\sqrt{S}}\left(\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\lambda_i^4(X)\sigma_i^4\right)^{1/2}\\
&\leq \epsilon^2D\sqrt{2L_{\Lambda}}\mathbb{E}_{\theta}\left(\sum_{i=1}^{\infty}\lambda_i^4(X)\sigma_i^4\right)^{1/2}\\
&\hspace{4mm}+\epsilon^2D\sqrt{2L_{\Lambda}}\left(\mathbb{E}_{\theta}\sup_i\sigma_i^2\lambda_i^2(X)\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^2(X)\right)^{1/2}\\
&\leq \mathbb{E}_{\theta}\frac{\epsilon^2BD^2L_{\Lambda}}{4}\sup_i\sigma_i^2\lambda_i^2(X)+2\epsilon^2B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^2(X)\\
&\hspace{4mm}+\mathbb{E}_{\theta}\frac{\epsilon^2BD^2L_{\Lambda}}{4}\sup_i\sigma_i^2\lambda_i^2(X)+2\epsilon^2B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^2(X)\\
&=4\epsilon^2B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^2(X)+\frac{\epsilon^2BD^2}{2}\mathbb{E}_{\theta}L_{\Lambda}\sup_i\sigma_i^2\lambda_i^2(X)\\
&\leq 4\epsilon^2B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^2(X)+\frac{BD^2}{2}\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda(X)].
\end{split}
\end{displaymath}
Łącząc te oszacowania dostajemy, że
\begin{displaymath}
\begin{split}
\mathbb{E}_{\theta}\norm{\hat{\theta}-\theta}^2&\leq \mathbb{E}_{\theta}\mathcal{R}(\hat{\theta},\theta)-2\epsilon\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(1-\lambda_i(X))\theta_i\lambda_i(X)\sigma_i\xi_i+\epsilon^2\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\lambda_i^2(X)\sigma_i^2(\xi^2_i-1)\\
&\leq \mathbb{E}_{\theta}\mathcal{R}(\hat{\theta},\theta)+4B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}(1-\lambda_i(X))^2\theta_i^2+\frac{3}{2}B\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda(X)]\\
&\hspace{4mm}+4\epsilon^2B^{-1}\mathbb{E}_{\theta}\sum_{i=1}^{\infty}\sigma_i^2\lambda_i^2(X)+\frac{BD^2}{2}\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda(X)]\\
&=(1+4B^{-1})\mathbb{E}_{\theta}\mathcal{R}(\hat{\theta},\theta)+CB\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda (X)],
\end{split}
\end{displaymath}
co kończy dowód lematu.
\end{proof}







\begin{proof}[Dowód lematu \ref{lem4}]
W dowodzie lematu ponownie skorzystamy z oszacowania 
\begin{displaymath}
\mathbb{E}X^2\pmb{1}_{\{|X|>a\}}\leq \frac{2}{\sqrt{2\pi}}(a+a^{-1})e^{-a^2/2}\ \forall_{a>0}
\end{displaymath}
zachodzącego dla zmiennych losowych o standardowym rozkładzie normalnym oraz z własności
\begin{displaymath}
F(\max_{v\in V}|\zeta_v|)\leq \sum_{v\in V}F(|\zeta_v|)
\end{displaymath}
dla funkcji postaci $F(t)=t^2\pmb{1}_{\{t> \sqrt{2\ln (NK)}\}}$.\\
Oznaczmy przez $\zeta_v=\frac{\langle \eta ,v\rangle}{\norm{T^*v}_2}$. Zauważmy, że z faktu, że $\eta$ jest gaussowskim  szumem  z operatorem kowariancji postaci $TT^*$, może być przedstawiona jako $T\xi$, gdzie $\xi$ jest gaussowskim białym szumem. Wynika stąd, że $\zeta_v$ ma standardowy rozkład normalny $\mathcal{N}(0,1)$. Możemy teraz napisać
\begin{displaymath}
\begin{split}
\mathbb{E}\left|\langle \eta , v\rangle\right|&=\mathbb{E}|\zeta |\norm{T^*v}_2\leq\mathbb{E}|\zeta |\norm{T^*}\norm{v}_2\leq \norm{T^*} \mathbb{E}\norm{v}_2\max_{v\in V}|\zeta_v|\\
&=\norm{T^*}\mathbb{E}\norm{v}_2\max_{v\in V}|\zeta_v|\pmb{1}_{\{\max_{v\in V}|\zeta_v|\leq \norm{T^*}\sqrt{2\ln (NK)}\}}\\
&\hspace{4mm}+\norm{T^*}\mathbb{E}\norm{v}_2\max_{v\in V}|\zeta_v|\pmb{1}_{\{\max_{v\in V}|\zeta_v|> \sqrt{2\ln (NK)}\}}\\
&\leq \norm{T^*}\sqrt{2\ln (NK)}\mathbb{E}\norm{v}_2+\norm{T^*}\mathbb{E}\norm{v}_2\max_{v\in V}|\zeta_v|\pmb{1}_{\{\max_{v\in V}|\zeta_v|> \sqrt{2\ln (NK)}\}}\\
&\leq \norm{T^*}\left(\sqrt{2\ln (NK)}\mathbb{E}\norm{v}_2+\left(\mathbb{E}\norm{v}_2^2\right)^{1/2}\left(\mathbb{E}\max_{v\in V}|\zeta_v|^2\pmb{1}_{\{\max_{v\in V}|\zeta_v|> \sqrt{2\ln (NK)}\}}\right)^{1/2}\right)\\
&\leq \norm{T^*}\sqrt{2\ln (NK)}\mathbb{E}\norm{v}_2+\norm{T^*}\left(\mathbb{E}\norm{v}_2^2\right)^{1/2}\left(\sum_{v\in V}\mathbb{E}|\zeta_v|^2\pmb{1}_{\{|\zeta_v|> \sqrt{2\ln (NK)}\}}\right)^{1/2}\\
&=\norm{T^*}\sqrt{2\ln (NK)}\mathbb{E}\norm{v}_2+\norm{T^*}\left(\mathbb{E}\norm{v}_2^2\right)^{1/2}\left(N\mathbb{E}|\zeta_v^1|^2\pmb{1}_{\{|\zeta_v^1|> \sqrt{2\ln (NK)}\}}\right)^{1/2},
\end{split}
\end{displaymath}
gdzie $v^1$ jest dowolnym ustalonym elementem $V$.
Korzystając ze wspomnianego na początku oszacowania z $a=\sqrt{2\ln (NK)}$ dostajemy
\begin{displaymath}
\norm{T^*}\sqrt{2\ln (NK)}\mathbb{E}\norm{v}_2+\norm{T^*}\left(\mathbb{E}\norm{v}_2^2\right)^{1/2}\left(N\mathbb{E}|\zeta_v^1|^2\pmb{1}_{\{|\zeta_v^1|> \sqrt{2\ln (NK)}\}}\right)^{1/2}
\end{displaymath}
\begin{displaymath}
\leq \norm{T^*}\sqrt{2\ln (NK)}\left(\mathbb{E}||v||_2+\sqrt{2\mathbb{E}||v||_2^2/K}\right)=\norm{T}\sqrt{2\ln (NK)}\left(\mathbb{E}||v||_2+\sqrt{2\mathbb{E}||v||_2^2/K}\right),
\end{displaymath}
 gdyż $\norm{T^*}=\norm{T}$, co kończy dowód.
\end{proof}


\begin{proof}[Dowód lematu \ref{lem5}]
Jeżeli $\eta$ jest gaussowskim szumem z operatorem kowariancji $TT^*$ to można go przedstawić w postaci $T\xi$, gdzie $\xi$ jest gaussowskim białym szumem. Oznaczmy $\zeta_v=\frac{1}{\norm{T^*v}_2^2}\langle \eta^2-1,v\rangle$. Zauważmy, że tak zdefiniowana zmienna losowa spełnia założenia lematu \ref{szacowanie} z $v=\frac{v}{\norm{T^*v}_2}$. Z nierówności Markowa dostajemy, że dla dowolnego $t>0$ i $x>0$ zachodzi i ustalonego $u\in V$
\begin{displaymath}
\ln P(\zeta_u>x)\leq -tx+\ln\mathbb{E}\exp\left(\frac{t}{\norm{T^*u}_2^2}\langle \eta^2-1,u\rangle\right)
\end{displaymath}
\begin{displaymath}
\leq -tx+\frac{\left(\frac{t}{\norm{T^*u}}\right)^2\norm{u}_2^2}{1-\frac{t}{\norm{T^*u}_2}\norm{u}_{\infty}}\leq -tx+\frac{\left(\frac{t}{\norm{T^*u}_2}\right)^2\norm{u}_2^2}{1-\frac{t}{\norm{T^*u}_2}\norm{u}_{2}m(u)}.
\end{displaymath}
Zauważmy następnie, że dla dowolnego $a>0$ i $t\in [0,\frac{1}{\sqrt{2}a})$ zachodzi nierówność
\begin{displaymath}
\frac{t^2}{1-at}\leq \frac{-1}{a^2}\ln(1-\sqrt{2}at)-\frac{\sqrt{2}t}{a}.
\end{displaymath}
Dostajemy zatem następującą nierówność
\begin{displaymath}
P(\zeta_u>x)\leq \exp(-tx)\exp\left(-\frac{1}{m^2(u)}\ln\left(1-\frac{\sqrt{2}m(u)\norm{u}_2}{\norm{T^*u}_2}t\right)-\frac{\sqrt{2}\norm{u}_2}{\norm{T^*u}_2m(u)}t\right),
\end{displaymath}
o ile $t<\frac{\norm{T^*u}}{\sqrt{2}m(u)\norm{u}_2}.$ Zauważmy, że nierówność ta sprowadza się do analogicznej nierówności z dowodu lematu \ref{lem2}, gdy operator $T$ jest operatorem identycznościowym, jak w przypadku białego szumu.
Minimalizując prawą stronę powyższego wyrażenia względem $t$ dostajemy, że w punkcie $t_{min}=\frac{\norm{T^*u}}{\sqrt{2}m(u)\norm{u}_2}-\frac{1}{m^2(u)x+\frac{\sqrt{2}m(u)\norm{u}_2}{\norm{T^*u}}} $ osiągane jest minimum o wartości 
\begin{equation}
\begin{split}\label{sukces}
\exp&\left(-\frac{\norm{T^*u}_2x}{\sqrt{2}m(u)\norm{u}_2}+\frac{1}{m^2(u)}\ln\left(1+\frac{\norm{T^*u}_2m(u)x}{\sqrt{2}\norm{u}}\right) \right)\\
&=\exp\left(\frac{1}{m^2(u)}\left(\ln \left(1+\frac{\norm{T^*u}_2m(u)}{\sqrt{2}\norm{u}_2}x\right)-\frac{\norm{T^*u}_2m(u)}{\sqrt{2}\norm{u}_2}\right)\right)\\
&\leq \exp\left(\frac{-\frac{\norm{T^*u}_2^2}{\norm{u}^2_2}x^2}{1+\frac{\norm{T^*u}m(u)}{\sqrt{2}\norm{u}_2}x}\right),
\end{split}
\end{equation}
gdzie ponownie skorzystaliśmy z nierówności $\ln (1+z)-z\leq -\frac{z^2}{2(1+z)}$ zachodzącej dla dodatnich $z$.
Powyższe rozważania będą wykorzystane tylko w przypadku, gdy operator $T^*$ jest operatorem ograniczonym i odwracalnym, co gwarantuje istnienie stałych $c,C>0$ takich, że dla dowolnego $v$ zachodzi (\cite{sobolev}, str. 216)
\begin{displaymath}
c\norm{u}_2\leq \norm{Tu}_2\leq C\norm{u}_2.
\end{displaymath}
W dalszym ciągu rozważań największą ze stałych $c$ dla których zachodzi powyższa nierówność będzie oznaczać przez $\norm{t}$, natomiast najmniejszą ze stałych $C$ przez $\norm{T}$. Oczywiście stała $\norm{T}$ jest normą operatora $T$. Przy takich oznaczeniach oszacowanie (\ref{sukces}) przyjmuje postać 
\begin{displaymath}
\exp\left(\frac{-\norm{t}^2x^2}{1+2^{-1/2}\norm{T}m(u)x}\right).
\end{displaymath}
Zauważmy, że powyższe wyrażenie można oszacować następująco w zależności od wielkości $x$.
\begin{displaymath}
\exp\left(\frac{-\norm{t}^2x^2}{1+2^{-1/2}\norm{T}m(u)x}\right)\leq \left\{{\exp\left(\frac{-\norm{t}^2x^2}{2}\right),\ gdy\ 2^{-1/2}\norm{T}m(u)x<1,}\atop {\exp\left(\frac{-\norm{t}^2x}{\sqrt{2}\norm{T}m(u)}\right)},\ gdy\ 2^{-1/2}\norm{T}m(u)x\geq 1.\right.
\end{displaymath}
Ostatecznie prowadzi nas to do następującego oszacowania
\begin{displaymath}
P(\zeta_u>x)\leq \left\{{\exp\left(\frac{-\norm{t}^2x^2}{2}\right),\ gdy\ 2^{-1/2}\norm{T}m(u)x<1,}\atop {\exp\left(\frac{-\norm{t}^2x}{\sqrt{2}\norm{T}m(u)}\right)},\ gdy\ 2^{-1/2}\norm{T}m(u)x\geq 1.\right.
\end{displaymath}
Zauważmy, że zachodzi również $P(\zeta_u <-x)=P(-\zeta_u>x)=P(\zeta_{-u}>x)$ i powyższe rozumowanie przenosi się na ten przypadek, a stąd dostajemy oszacowanie 
\begin{displaymath}
P(|\zeta_u|>x)\leq 2\left\{{\exp\left(\frac{-\norm{t}^2x^2}{2}\right),\ gdy\ 2^{-1/2}\norm{T}m(u)x<1,}\atop {\exp\left(\frac{-\norm{t}^2x}{\sqrt{2}\norm{T}m(u)}\right)},\ gdy\ 2^{-1/2}\norm{T}m(u)x\geq 1.\right.
\end{displaymath}
Następnie korzystając z uzyskanego oszacowania możemy zapisać dla dowolnego\\ $\frac{\sqrt{2}}{\norm{T}m(u)}\geq Q>0$
\begin{displaymath}
\begin{split}
\mathbb{E}\zeta_u^2\pmb{1}\{|\zeta_u|>Q\}&=2\int_Q^{\infty}zP\left(|\zeta_u|>z\right)dz\leq 4\int_Q^{\infty}z\exp\left(\frac{-\norm{t}^2z^2}{1+2^{-1/2}\norm{T}m(u)z}\right)dt\\ 
&\leq 4\int_Q^{\frac{\sqrt{2}}{\norm{T}m(u)}}z\exp \left(\frac{-\norm{t}^2z^2}{2}\right)dz+4\int_Q^{\infty}z\exp\left(\frac{-\norm{t}^2z}{\sqrt{2}\norm{T}m(u)}\right)dz\\\
&\leq C \exp \left(\frac{-\norm{t}^2Q^2}{2}\right)+CQ\exp\left(\frac{-\norm{t}^2Q}{\sqrt{2}\norm{T}m(u)}\right).
\end{split}
\end{displaymath}
Podobnie jak w dowodzie lematu \ref{lem2} nierówność tą możemy uogólnić dla dowolnego $Q>0$.
Zauważmy następnie, że zachodzi
\begin{displaymath}
\sum_{u\in V}\exp\left(\frac{-\norm{t}^2Q}{\sqrt{2}\norm{T}m(u)}\right)=\sum_{u\in V}\exp\left(-\frac{q}{m(u)}\right)\exp\left(-\frac{\norm{t}Q/(\sqrt{2}\norm{T})-q}{m(u)}\right)
\end{displaymath}
\begin{displaymath}
\leq M(q)\exp\left(-\frac{\norm{t}Q/(\sqrt{2}\norm{T})-q}{m_V}\right),
\end{displaymath}
o ile $Q>\frac{\sqrt{2}q\norm{T}}{\norm{t}}$. Niech zatem $Q>\frac{\sqrt{2}q\norm{T}}{\norm{t}}$, wtedy 
\begin{displaymath}
\begin{split}
\mathbb{E}\left| \langle \eta^2-1, u\rangle\right|&=\mathbb{E}\norm{T^*u}^2_2|\zeta_u|\leq \norm{T}^2\mathbb{E}\norm{u}^2_2|\zeta_u| \leq \norm{T}^2\mathbb{E}\norm{u}^2_2\max_{u\in V}|\zeta_u|\\
&\leq \norm{T}^2\mathbb{E}\norm{u}^2_2\max_{u\in V}|\zeta_u|\pmb{1}\{\max_{u\in V}|\zeta_u|\leq Q\}\\&\hspace{4mm}+\norm{T}^2\mathbb{E}\norm{u}^2_2\max_{u\in V}|\zeta_u|\pmb{1}\{\max_{u\in V}|\zeta_u|> Q\}\\
&\leq \norm{T}^2\mathbb{E}\norm{u}^2_2Q+\norm{T}^2\left(\mathbb{E}\norm{v}^4_2\right)^{1/2}\left(\mathbb{E}\max_{u\in V}|\zeta_u|^2\pmb{1}\{\max_{u\in V}|\zeta_u|> Q\}\right)^{1/2}\\
&\leq  \norm{T}^2\mathbb{E}\norm{u}^2_2Q+\norm{T}^2\left(\mathbb{E}\norm{v}^4_2\right)^{1/2}\left(\sum_{u\in V}\mathbb{E}|\zeta_u|^2\pmb{1}\{\max_{u\in V}|\zeta_u|> Q\}\right)^{1/2}\\
&\leq \norm{T}^2\mathbb{E}\norm{u}^2_2Q+\norm{T}^2\left(\mathbb{E}\norm{v}^4_2\right)^{1/2}\cdot\\
&\hspace{4mm}\cdot\left(\sum_{u\in V}\left(C \exp \left(\frac{-\norm{t}^2Q^2}{2}\right)+CQ\exp\left(\frac{-\norm{t}^2Q}{\sqrt{2}\norm{T}m(u)}\right)\right)\right)^{1/2}\\
&\leq \norm{T}^2\mathbb{E}\norm{u}^2_2Q+\norm{T}^2\left(\mathbb{E}\norm{v}^4_2\right)^{1/2}\cdot\\
&\hspace{4mm}\cdot\left(NC \exp \left(\frac{-\norm{t}^2Q^2}{2}\right)+CQM(q)\exp\left(-\frac{\norm{t}Q/(\sqrt{2}\norm{T})-q}{m_V}\right)\right)^{1/2}
\end{split}
\end{displaymath}
Przyjmując teraz $Q=\frac{1}{\norm{v}}\left(\frac{\sqrt{2}}{\norm{t}^2}\sqrt{\ln (NK)}+\frac{\sqrt{2}\norm{T}}{\norm{t}}m_V\ln(M(q)K)\right)+\frac{\sqrt{2}q\norm{T}}{\norm{t}}$ dostajemy tezę.
\end{proof}






















\begin{proof}[Dowód lematu \ref{lem6}]
Oznaczmy przez $C'=\max\{1,C_2\}$. Przypomnijmy, że w naszym modelu (\ref{ssmg}) mamy, że $X=\theta+\epsilon\sigma\eta$, a stąd $X^2=\theta^2+\epsilon^2\sigma^2\eta^2+2\epsilon\theta\sigma\eta$.
\begin{displaymath}
\begin{split}
\mathbb{E}_{\theta}&\norm{\hat{\theta}-\theta}^2=\mathbb{E}_{\theta}\left[\int_S\left(\lambda(X)X-\theta\right)^2d\mu\right]
\\&=\mathbb{E}_{\theta}\left[\int_S\lambda^2(X)X^2d\mu+\int_S\theta^2d\mu-2\int_S\lambda(X)X\theta d\mu\right]\\
&=\mathbb{E}_{\theta}\left[\int_S\lambda^2(X)\left(\theta^2+\epsilon^2\sigma^2\eta^2+2\epsilon\theta\sigma\eta\right)d\mu+\int_S\theta^2d\mu-2\int_S\lambda(X)\theta\left(\theta+\epsilon\sigma\eta\right)d\mu\right]\\
&=\mathbb{E}_{\theta}\left[\int_S(1-\lambda(X))^2\theta^2d\mu-2\epsilon\int_S(1-\lambda(X))\theta\lambda(X)\sigma\eta d\mu+\right.\\
&\hspace{4mm}+\left.\epsilon^2\int_S\lambda^2(X)\sigma^2(\eta^2-1)d\mu+\epsilon^2\int_S\lambda^2(X)\sigma^2d\mu\right]\\
&\leq \mathbb{E}_{\theta}C'\Psi(\lambda,\theta)-2\epsilon\mathbb{E}_{\theta}\int_S(1-\lambda(X))\theta\lambda(X)\sigma\eta d\mu+\epsilon^2\mathbb{E}_{\theta}\int_S\lambda^2(X)\sigma^2(\eta^2-1)d\mu.
\end{split}
\end{displaymath}
Następnie korzystając z pierwszego z lematów z $K=S$ oszacujemy wyrażenie \\$\epsilon\mathbb{E}_{\theta}\left|\int_S(1-\lambda (X))\theta \lambda (X)\sigma\eta d\mu\right|$. 
\begin{displaymath}
\begin{split}
\epsilon\mathbb{E}_{\theta}&\left|\int_S(1-\lambda (X))\theta \lambda (X)\sigma\eta d\mu\right|\\
&\leq \epsilon\norm{T}\sqrt{2\ln (NS)}\mathbb{E}_{\theta}\left(\int_S(1-\lambda(X))^2\theta ^2\lambda^2(X)\sigma^2d\mu\right)^{1/2}\\
&\hspace{4mm}+2\epsilon\norm{T}\sqrt{\ln (NS)}S^{-1/2}\left(\mathbb{E}_{\theta}\int_S(1-\lambda(X))^2\theta ^2\lambda^2(X)\sigma^2d\mu\right)^{1/2}\\
&\leq \epsilon\norm{T}\sqrt{2\ln (NS)}\mathbb{E}_{\theta}\norm{\sigma^2\lambda^2(X)}_{\infty}\left(\int_S(1-\lambda(X))^2\theta ^2d\mu\right)^{1/2}\\
&\hspace{4mm}+2\epsilon\norm{T}\sqrt{\ln (NS)}S^{-1/2}\max_{\lambda\in \Lambda}\norm{\sigma^2\lambda^2(X)}_{\infty}\left(\mathbb{E}_{\theta}\int_S(1-\lambda(X))^2\theta ^2d\mu\right)^{1/2}\\
&\leq \frac{1}{2C'}\epsilon^2\norm{T}^2B\ln (NS)\mathbb{E}_{\theta}\norm{\sigma^2\lambda^2(X)}_{\infty}+B^{-1}C'\mathbb{E}_{\theta}\int_S(1-\lambda(X))^2\theta ^2d\mu\\
&\hspace{4mm}+\epsilon^2\frac{1}{C'}\norm{T}^2B\ln (NS)\frac{\max_{\lambda\in \Lambda}\norm{\sigma^2\lambda^2(X)}_{\infty}}{S}+B^{-1}C'\mathbb{E}_{\theta}\int_S(1-\lambda(X))^2\theta ^2d\mu,
\end{split}
\end{displaymath}
gdzie korzystaliśmy z nierówności $2ab\leq C'B^{-1}a^2+BC'^{-1}b^2$ zachodzącej dla dowolnego $B>0$.\\
Ponownie możemy zauważyć, że skoro $S=\frac{\max_{\lambda\in \Lambda}\norm{\sigma^2\lambda^2(X)}_{\infty}}{\min_{\lambda\in \Lambda}\norm{\sigma^2\lambda^2(X)}_{\infty}}$ to $\frac{\max_{\lambda\in \Lambda}\norm{\sigma^2\lambda^2(X)}_{\infty}}{S}=\min_{\lambda\in \Lambda}\norm{\sigma^2\lambda^2(X)}_{\infty}$, a stąd powyższe wyrażenie redukuje się do postaci
\begin{displaymath}
\begin{split}
2B^{-1}C'\mathbb{E}_{\theta}\int_S&(1-\lambda(X))^2\theta ^2d\mu+\frac{1}{2C'}\epsilon^2\norm{T}^2B\ln (NS)\mathbb{E}_{\theta}\norm{\sigma^2\lambda^2(X)}_{\infty}\\
&\hspace{4mm}+\epsilon^2B\frac{1}{C'}\norm{T}^2\ln (NS)\min_{\lambda\in \Lambda}\norm{\sigma^2\lambda^2(X)}_{\infty}\\
&\leq 2B^{-1}C'\mathbb{E}_{\theta}\int_S(1-\lambda(X))^2\theta ^2d\mu+\frac{3}{2C'}B\norm{T}^2\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda(X)].
\end{split}
\end{displaymath}
Następnie będziemy szacować drugie z  wyrażeń, czyli $\epsilon^2\mathbb{E}_{\theta}\left|\int_S\lambda^2(X)\sigma^2(\eta^2-1)d\mu\right|$ korzystając z lematu \ref{lem5}.  Zauważmy na początek 
\begin{displaymath}
m(v)=\frac{\norm{v}_{\infty}}{\norm{v}_2}\leq C_2\rho (\lambda),
\end{displaymath}
a stąd $m_V\leq C_2\rho$ oraz $M(C_2)\leq M$ i możemy szacować wyrażenie $\sqrt{\ln (NS)}+m_V\ln (M(C_2)S)$ przez $\sqrt{2L_{\Lambda}}$. Zachodzi zatem
\begin{displaymath}
\epsilon^2\mathbb{E}_{\theta}\left|\int_S\lambda^2(X)\sigma^2(\eta^2-1)d\mu\right|
\end{displaymath}
\begin{displaymath}
\leq \epsilon^2D\sqrt{C_2}\norm{T}^2\sqrt{2L_{\Lambda}}\mathbb{E}_{\theta}\left(\int_S\lambda^4(X)\sigma^3d\mu\right)^{1/2}+\frac{\epsilon^2D\sqrt{C_2}\norm{T}^2\sqrt{2L_{\Lambda}}}{\sqrt{S}}\left(\mathbb{E}_{\theta}\int_S\lambda^4(X)\sigma^3\mu\right)^{1/2}.
\end{displaymath}
Analogicznie do poprzednich rozważań zachodzi
\begin{displaymath}
S^{-1}\mathbb{E}_{\theta}\int_S\sigma^3\lambda^4(X)d\mu\leq 
\mathbb{E}_{\theta}\norm{\sigma^2\lambda^2(X)}_{\infty}\mathbb{E}_{\theta}\int_S\sigma\lambda^2(X)d\mu.
\end{displaymath}
Dostajemy stąd następujące oszacowanie
\begin{displaymath}
\begin{split}
\epsilon^2D\sqrt{C_2}\norm{T}^2&\sqrt{2L_{\Lambda}}\mathbb{E}_{\theta}\left(\int_S\lambda^4(X)\sigma^3d\mu\right)^{1/2}+\frac{\epsilon^2D\sqrt{C_2}\norm{T}^2\sqrt{2L_{\Lambda}}}{\sqrt{S}}\left(\mathbb{E}_{\theta}\int_S\lambda^4(X)\sigma^3\mu\right)^{1/2} \\
&\leq \epsilon^2D\sqrt{C_2}\norm{T}^2\sqrt{2L_{\Lambda}}\mathbb{E}_{\theta}\left(\int_S\lambda^4(X)\sigma^3d\mu\right)^{1/2}\\
&\hspace{4mm}+\epsilon^2D\sqrt{C_2}\norm{T}^2\sqrt{2L_{\Lambda}}\left(\mathbb{E}_{\theta}\norm{\sigma^2\lambda^2(X)}_{\infty}\mathbb{E}_{\theta}\int_S\sigma\lambda^2(X)d\mu\right)^{1/2}\\
&\leq \mathbb{E}_{\theta}\frac{\epsilon^2BD^2C_2\norm{T}^4L_{\Lambda}}{4C'}\norm{\sigma^2\lambda^2(X)}_{\infty}+2\epsilon^2B^{-1}C'\norm{T}^2\mathbb{E}_{\theta}\int_S\sigma\lambda^2(X)d\mu\\
&\hspace{4mm}+\mathbb{E}_{\theta}\frac{\epsilon^2BD^2C_2\norm{T}^4L_{\Lambda}}{4C'}\norm{\sigma^2\lambda^2(X)}_{\infty}+2\epsilon^2B^{-1}C'\norm{T}^2\mathbb{E}_{\theta}\int_S\sigma\lambda^2(X)d\mu\\
&=4\epsilon^2B^{-1}C'\norm{T}^2\mathbb{E}_{\theta}\int_S\sigma\lambda^2(X)d\mu+\frac{\epsilon^2BD^2C_2\norm{T}^2}{2C'}\mathbb{E}_{\theta}L_{\Lambda}\norm{\sigma^2\lambda^2(X)}_{\infty}\\
&\leq 4\epsilon^2B^{-1}C'\norm{T}^2\mathbb{E}_{\theta}\int_S\sigma\lambda^2(X)d\mu+\frac{BD^2C_2\norm{T}^2}{2C'}\mathbb{E}_{\theta}\Delta^{\epsilon}[\lambda(X)].
\end{split}
\end{displaymath}
Łącząc te oszacowania dostajemy tezę lematu.
\end{proof}

\begin{zakonczenie}
W pracy zaprezentowano metodę wyboru estymatora ze skończonego zbioru naśladującego ryzyko najlepszego estymatora w tej rodzinie w stochastycznym problemie odwrotnym postaci 
\begin{displaymath}
Y =  Af+\epsilon\xi.
\end{displaymath}
Głównym rezultatem jest zaprezentowanie odpowiednich nieasymptotycznych nierówności wyroczni ujętych w twierdzeniach \ref{glowny1},\ref{glowny2}, \ref{glowny3} i \ref{glowny4} pozwalających kontrolować ryzyko wybranego estymatora przez ryzyko najlepszego estymatora w danej rodzinie.\\
\indent Rozważania zostały podzielone na przypadek, gdy operator $A$ jest operatorem zwartym oraz przypadek ogólny dla dowolnego operatora liniowego i ograniczonego.  Pierwsza część rozważań została zawarta w rozdziale \ref{G1} i jest prezentacją wyników uzyskanych w pracy \cite{cavalier1}. Dodatkowo w pracy sformułowano w sposób jawny założenie \ref{ass3}, poprawiono stałą (\ref{blad}) występującą w dowodzie twierdzeń \ref{glowny1} i \ref{glowny2} oraz uzasadniono zbieżność pojawiających się szeregów. Druga część rozważań została ujęta w rozdziale \ref{G2}. Zaprezentowane tam rezultaty są istotonymi modyfikacjami wyników uzyskanych w \cite{cavalier2}. W artykule tym pracowano przy założeniu, że obserwacje zaburzone są przez błąd pochodzący z białego szumu, co prowadziło jednak do tego, że rozpatrywany proces $Y$ nie miał trajektorii w rozważanej przestrzeni. Dlatego w rozdziale \ref{G2} wprowadzono odpowiednie modyfikacje gwarantujące skończoność drugich momentów rozwiązania. Wprowadzone zmiany wymagały głębokich zmian w dowodach twierdzeń \ref{glowny3} i \ref{glowny4}, a także lematów \ref{lem4}, \ref{lem6} i szczególnie \ref{lem5}, uwzględniających fakt, że źródłem zaburzenia stał się szum kolorowy. W rezultacie niemożliwa stała się praca z nieobciążonym estymatorem ryzyka, a jedynie z pewnym oszacowaniem ryzyka. Dodatkowo w dowodzie lematu \ref{lem5} zastosowano odmienną technikę do uzyskania odpowiedniej nierówności koncentracyjnej. \\
\indent W rozdziale \ref{przyklad} zaprezentowano ponadto autorski przykład zastosowania wyników z rozdziału \ref{G2} w problemie dokonwolucji na prostej. Pokazano w nim, że zaproponowana metoda pozwala wybrać estymator z optymalnym tempem zbieżności na pewnej klasie funkcji pod warunkiem, że rozważana rodzina estymatorów zawiera taki element.
\end{zakonczenie}



\begin{thebibliography}{100}
\bibitem{iphde} P. Alquier,	E. Gautier, G. Stoltz, \emph{Inverse Problems and High-Dimensional Estimation}	Springer-Verlag, 2011, wydanie zbiorowe,
\bibitem{barron} A. Barron, L. Birge, P. Massart, \emph{Risk bounds for model selection via penalization}, Probab. Theory Relat. Fields, 113, 1999, pp. 301--413,
\bibitem{birge} L. Birge, \emph{Model selection via testing: an alternative to (penalized) maximum likelihood estimators}, Ann. I. H. Poincaré, PR 42, 2006, pp. 273–-325,
\bibitem{birge2} L. Birge, \emph{Statistical estimation with model selection}, arXiv, 2006, The Brouwer Lecture, 2005,
\bibitem{bissantz} N. Bissantz, T. Hohange, A. Munk, F. Ruymgaart, \emph{Convergence rates of general regularization methods for statistical inverse problems and applications}, SIAM J. Numer. Anal., Vol. 45, No. 6, 2007, pp. 2610--2636,
\bibitem{cavalier2}  L. Cavalier, \emph{Inverse problems with non-compact operators}, Journal of Statistical Planning and
Inference, 136, 2006, pp. 390--400,
\bibitem{cavalier1} L. Cavalier, G. K. Golubev, D. Picard, A.B. Tsybakov, \emph{Oracle inequalities for inverse problems}, The Annals of Statistics, Vol. 30, No. 3, 2002, pp. 843–-874,	
\bibitem{cavalier3} L. Cavalier, G. K. Golubev, \emph{Risk hull method and regularization by projections of ill-- posed inverse problems}, The Annals of Statistics, Vol. 34, No. 4, 2006, pp. 1653--1677,
\bibitem{engl} H. Engl,	M. Hanke,	A. Neubauer	\emph{Regularization of Inverse Problems}, Kluwer Academic Publishing,	1996,
\bibitem{feller} W. Feller, \emph{An Introduction to Probability Theory and Its Applications. Volume 1}, John Wiley and Sons, 1968,
\bibitem{giraud} C. Giraud, \emph{Introduction to High--Dimensional Statistics}, CRC Press, 2015,
\bibitem{halmos}  P. R. Halmos, \emph{What does the spectral theorem say?}, The American Mathematical Monthly, Vol. 70, No. 3, 1963, pp. 241--247,
\bibitem{hida} T. Hida, \emph{Brownian Motion}, Springer, 1980,
\bibitem{laurent} B.Laurent, P. Massart, \emph{Adaptive estimation of a quadratic functional by model selection}, The Annals of Statistics, Vol. 28, No. 5, 2000, pp. 1302--1338,
\bibitem{loubes} J.--M. Loubes, C. Ludena, \emph{Penalized estimators for non linear inverse problems}, ESAIM: PS Vol. 14, 2010, pp. 173--191,
\bibitem{loubes1} J.--M. Loubes, C. Ludena, \emph{Adaptive complexity regularization for linear inverse problems}, Electronic Journal of Statistics, Vol. 2, 2008, pp. 661--677, 
\bibitem{sobolev} L. A. Lusternik, V. J. Sobolew, \emph{Elements of functional analysis}, John Wiley and Sons, 1974,
\bibitem{mair} B. A. Mair, F. H. Ruymgaart, \emph{Statistical inverse estimation in Hilbert scales}, SIAM J. Appl. Math, Vol. 56, No. 5, 1996, pp. 1424--1444,
\bibitem{kaipo}
J. Kaipio, E. Somersalo, \emph{Statistical and Computational Inverse Problems}, Springer, 2004,
\bibitem{wloch} Manigilia S., Ruandi A., \emph{Gaussian measures on Hilbert spaces}, Quaderni dal Dipartimento di Matematica dell' Universita del Salento, 1(1), 2004, pp. 1--24,
\bibitem{mitchell} C. Mitchell, S. van de Geer, \emph{ General oracle inequalities for model selection}, Electron. J. Statist, 3 (2009), pp. 176--204,
\bibitem{silverman} B. W. Silverman, \emph{Density Estimation for Statistics and Data Analysis}, Springer-Science+Business Media, B.Y., 1986,
\bibitem{szkutnik}
Z. Szkutnik, \emph{Statystyczne problemy odwrotne}, nieopublikowane notatki do wykładu wygłoszonego podczas XXXII Konferencji Statystyka Matematyczna, Wisła, 2006,
\bibitem{taylor} M. E. Taylor, \emph{Partial Differential Equations II. Qualitative Studies of Linear Equations}, Springer Science+Business Media, 2011,
\bibitem{typek} N. N. Vakhania, V. I. Tarieladze, \emph{Probability Distributions on Banach Spaces}, D. Reidel Publishing Company, 1987,
\bibitem{hindus}
H. Lal Vasudeva, \emph{Elements of Hilbert Spaces and Operator Theory}, Springer Verlag, 2017,
\bibitem{wasserman}
L. Wasserman, \emph{All of Nonparametric Statistics},	Springer Science+Business Media, Inc.,	2006,

\end{thebibliography}







\end{document}
